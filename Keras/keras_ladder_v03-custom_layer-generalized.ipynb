{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Ladder Network for Semi-supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current status\n",
    "### missing elements\n",
    "1. Reconstruction cost: the decoder is not normalized before inserting into the MSE. Reason: normalization destroyed the reconstruction learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.4.0',\n",
       " sys.version_info(major=3, minor=6, micro=3, releaselevel='final', serial=0))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# additional imports of python modules\n",
    "# python module imports needed in customized functions:\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imgplot\n",
    "import time\n",
    "#import pandas as pd\n",
    "#tf.set_random_seed(1)\n",
    "#np.random.seed(1)\n",
    "import sys\n",
    "tf.__version__, sys.version_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras import initializers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data from keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test_num) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We normalize all values between 0 and 1 and we flatten the 28x28 images into vectors of size 784."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test_num, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ladder network: defining the graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, GaussianNoise, BatchNormalization, Activation, Layer, Merge\n",
    "from keras.models import Model\n",
    "\n",
    "stddev = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports for graph plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## custom normalization layer\n",
    "Define a layer that performs normalization (=standardization) of a layer using the mean and the var of the inputs to the layer\n",
    "The normalization is required before acting with relu:\n",
    "\n",
    "from https://theneuralperspective.com/2016/10/27/gradient-topics/:\n",
    "\n",
    "There are several types of normalization techniques but the idea behind all of them is the same, which is shifting our inputs to a zero mean and unit variance. We normalize the inputs before applying the non-linearity. We do this because we do not want the inputs to saturate the non-linearities at the extremes. (Checkout SNNs/SELU for some recent updates on this subject).\n",
    "\n",
    "Remark about the difference from batch norm:  Batch normalization is very nice but it is based on minibatch size and so it’s a bit difficult to use with recurrent architectures. With layer normalization, we instead compute the mean and variance using ALL of the summed inputs to the neurons in a layer for EVERY single training case. This removes the dependency on a minibatch size. Unlike batch normalization, the normalization operation for layer norm is same for training and inference. More details can be found on Hinton’s paper here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomLayer_Normalization(Layer):\n",
    "    \"\"\"Apply layer normalization.\n",
    "       shifting our inputs to a zero mean and unit variance. \n",
    "       We normalize the inputs before applying the non-linearity. \n",
    "       We do this because we do not want the inputs to saturate the non-linearities at the extremes. \n",
    "       (Checkout SNNs/SELU for some recent updates on this subject).\n",
    "       \n",
    "       no need for build -- no trainable weights. \n",
    "        # Arguments\n",
    "            epsilon: regularizer for zero division\n",
    "        # Input shape\n",
    "            Arbitrary. Use the keyword argument `input_shape`\n",
    "            (tuple of integers, does not include the samples axis)\n",
    "            when using this layer as the first layer in a model.\n",
    "        # Output shape\n",
    "            Same shape as input.\n",
    "    \"\"\"\n",
    "    def __init__(self, epsilon = 1e-6, **kwargs):\n",
    "        super(CustomLayer_Normalization, self).__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return (inputs - K.mean(inputs,axis=-1,keepdims=True))/(K.std(inputs,axis=-1,keepdims=True)+self.epsilon) # change axis for conv2D\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining encoder and decoder channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions that build a generic encoder and decoder layer\n",
    "Each encoder or decoder layer is composed of sublayers (e.g linear transformation, normalization, activation sublayers). Here we first build the generic structure of the sublayers without defining their input or output dimensions and linking them to each other. In the next step we define the linking functions that specify how the sublayers are connected to each other and what output is delivered. Note that the output of the building functions is sublayers = a dictionary of the (unlinked) sublayers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_encoder_layer(encoding_dim_,layer_id,stddev_=0.05):\n",
    "    \"\"\"\n",
    "    Create the layers\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    \n",
    "    encoding_dim_:int\n",
    "        number of perceptons \n",
    "    layer_id: string\n",
    "        part of the name\n",
    "    stddev: double\n",
    "        standard deviation of the Gaussion noise layer\n",
    "        \n",
    "    Returns\n",
    "    =======\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    sublayers={}\n",
    "    s_id = 'encoder_' + layer_id + '/'\n",
    "    sublayers['lin_trans'] = Dense(encoding_dim_,activation = None,name=s_id + 'lt')\n",
    "    sublayers['norm'] = CustomLayer_Normalization(name=s_id + 'norm')\n",
    "    sublayers['noise_add'] = GaussianNoise(stddev_,name=s_id + 'noise')\n",
    "    sublayers['batch_norm'] = BatchNormalization(name=s_id + 'bn')\n",
    "    sublayers['activation'] = Activation('relu',name=s_id + 'output')\n",
    "    return sublayers\n",
    "\n",
    "def build_decoder_layer(decoding_dim_,layer_id,activation_name):\n",
    "    sublayers={}\n",
    "    s_id = 'decoder' + layer_id + '/'\n",
    "    sublayers['lin_trans']  = Dense(decoding_dim_,activation = None,name = s_id + 'lt')\n",
    "    sublayers['norm'] = CustomLayer_Normalization(name=s_id + 'norm')\n",
    "    sublayers['activation'] = Activation(activation_name,name=s_id + 'output')\n",
    "    return sublayers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions that link the sublayers within the encoder and the decoder\n",
    "Here we define functions that specify how the sublayers within each encoder/decoder layer should be linked to each other. Note that the encoder linking functions return two outputs: the final one and an intermediate one that is required for the combinator function of the ladder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def link_sublayer_corr_encoder(x,sublayers):\n",
    "    \"\"\"\n",
    "    Link the sublayers for the autoencoder\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    x: input for the first sublayer\n",
    "    sublayers: dict containing the sublayers\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "     x,y: layer output (after nonlin transformation), and intermediate output (after noise addition)\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        x=sublayers['lin_trans'](x)\n",
    "        x=sublayers['norm'](x)\n",
    "        y=sublayers['noise_add'](x)\n",
    "        x=sublayers['batch_norm'](y)\n",
    "        x=sublayers['activation'](x)\n",
    "    except:\n",
    "        print(\"Something failed\")\n",
    "    return x,y\n",
    "\n",
    "def link_sublayer_clean_encoder(x,sublayers):\n",
    "    \"\"\"\n",
    "    Link the sublayers for the supervised approach\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    x: input for the first sublayer\n",
    "    sublayers: dict containing the sublayers\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    x,y: layer output (after nonlin transformation), and intermediate output (after normalization)\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        x=sublayers['lin_trans'](x)\n",
    "        y=sublayers['norm'](x)\n",
    "        x=sublayers['batch_norm'](y)\n",
    "        x=sublayers['activation'](x)\n",
    "    except:\n",
    "        print(\"Something failed\")\n",
    "    return x,y\n",
    "\n",
    "def link_sublayer_decoder(x,sublayers,do_activation=True):\n",
    "    \"\"\"\n",
    "    Link the sublayers \n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    x: input for the first sublayer\n",
    "    sublayers: dict containing the sublayers\n",
    "    do_activation: boolean to turn on non linear transformation\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    x: layer output \n",
    "    \"\"\"\n",
    "    try:\n",
    "        x=sublayers['lin_trans'](x)\n",
    "        x=sublayers['norm'](x)\n",
    "        if do_activation is True:\n",
    "            x=sublayers['activation'](x)\n",
    "    except:\n",
    "        print(\"Something failed\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinator custom layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinatorLayer(Layer):\n",
    "\n",
    "    #def __init__(self, output_dim, **kwargs):\n",
    "    #    self.output_dim = output_dim\n",
    "    #    super(CombinatorLayer, self).__init__(**kwargs)\n",
    "    def __init__(self, combinator, **kwargs):\n",
    "        self.combinator = combinator\n",
    "        super(CombinatorLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        #print(input_shape)\n",
    "        #print(input_shape[0][1])\n",
    "        self.len_layer = input_shape[0][1]\n",
    "        self.b0 = self.add_weight(name='b0', \n",
    "                                      shape=(1,self.len_layer),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "        self.w_0z = self.add_weight(name='w_0z_lat', \n",
    "                                      shape=(1,self.len_layer),\n",
    "                                      initializer='ones',\n",
    "                                      trainable=True)\n",
    "        self.w_0u = self.add_weight(name='w_0u_ver', \n",
    "                                      shape=(1,self.len_layer),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "        self.w_0zu = self.add_weight(name='w_0zu', \n",
    "                                      shape=(1,self.len_layer),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "        self.b1 = self.add_weight(name='b1', \n",
    "                                      shape=(1,self.len_layer),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "        self.w_1z = self.add_weight(name='w_1z_lat', \n",
    "                                      shape=(1,self.len_layer),\n",
    "                                      initializer='ones',\n",
    "                                      trainable=True)\n",
    "        self.w_1u = self.add_weight(name='w_1u_ver', \n",
    "                                      shape=(1,self.len_layer),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "        self.w_1zu = self.add_weight(name='w_1zu', \n",
    "                                      shape=(1,self.len_layer),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "        self.w_sig = self.add_weight(name='w_sig', \n",
    "                                      shape=(1,self.len_layer),\n",
    "                                      initializer='ones',\n",
    "                                      trainable=True)\n",
    "        super(CombinatorLayer, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        #print(inputs[0])\n",
    "        # inputs is a concatination of two layer, each of length self.len_layer\n",
    "        lat = inputs[0]\n",
    "        ver = inputs[1]\n",
    "        if combinator=='linear':\n",
    "            return lat * self.w_0z + ver * self.w_0u + self.b0 # assuming broadcasting on the batch size\n",
    "        elif combinator=='vanilla':\n",
    "            return self.b0+self.w_0z*lat+self.w_0u*ver+self.w_0zu*lat*ver+ \\\n",
    "                   self.w_sig*K.sigmoid(self.b1+self.w_1z*lat+self.w_1u*ver+self.w_1zu*lat*ver)\n",
    "        else:\n",
    "            raise ValueError('Invalid combinator name')\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        #return (input_shape[0], self.output_dim)\n",
    "        return (1,self.len_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nlat = sidepath_corr[depth-1]\\nver = decoded[depth-1] \\n\\ncomb = CombinatorLayer()([lat,ver] )\\n\\nlat = sidepath_corr[depth-1]\\nver = decoded[depth-1] \\n#temp0 = CombinatorLayer()(lat )\\n#CombinatorLayer()([sidepath_corr[depth-1],decoded[depth-1] ])\\n#laylist = [lat,ver]\\n#laylist.append(lat)\\n#laylist.append(ver)\\n#laylist[0].shape\\n\\nlay_concat = K.concatenate([lat, ver], axis=-1)\\nprint(lay_concat.shape)\\nll = lay_concat.shape[1]//2\\nprint(ll)\\nlat_1 = lay_concat[:,:ll]\\nver_1 = lay_concat[:,ll:]\\nprint('lat:',lat_1.shape)\\nprint('ver:',ver_1.shape)\\n\\nCombinatorLayer()(lay_concat)\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "lat = sidepath_corr[depth-1]\n",
    "ver = decoded[depth-1] \n",
    "\n",
    "comb = CombinatorLayer()([lat,ver] )\n",
    "\n",
    "lat = sidepath_corr[depth-1]\n",
    "ver = decoded[depth-1] \n",
    "#temp0 = CombinatorLayer()(lat )\n",
    "#CombinatorLayer()([sidepath_corr[depth-1],decoded[depth-1] ])\n",
    "#laylist = [lat,ver]\n",
    "#laylist.append(lat)\n",
    "#laylist.append(ver)\n",
    "#laylist[0].shape\n",
    "\n",
    "lay_concat = K.concatenate([lat, ver], axis=-1)\n",
    "print(lay_concat.shape)\n",
    "ll = lay_concat.shape[1]//2\n",
    "print(ll)\n",
    "lat_1 = lay_concat[:,:ll]\n",
    "ver_1 = lay_concat[:,ll:]\n",
    "print('lat:',lat_1.shape)\n",
    "print('ver:',ver_1.shape)\n",
    "\n",
    "CombinatorLayer()(lay_concat)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting the ladder network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## turn combinator on and off \n",
    "combinator = 'vanilla'\n",
    "\n",
    "## Define the architecture\n",
    "##########################################\n",
    "Layer_dim = [784,128,32]\n",
    "depth = len(Layer_dim)\n",
    "\n",
    "\n",
    "## Create the clean and corrupted encoders\n",
    "##########################################\n",
    "# Input layer: define a generic input image \n",
    "input_img = Input(shape=(Layer_dim[0],),name = 'input_img')\n",
    "\n",
    "# Build encoder sublayers: generic for clean and noisy encoder\n",
    "encoder_layers = {} # a dictionary of dictionaries. The dictionary keys are the layer numbers (as in paper)\n",
    "for i in range(1,depth): # loop over all encoder levels (not including the input image)\n",
    "    encoder_layers[i] = build_encoder_layer(Layer_dim[i],str(i))\n",
    "\n",
    "# NOTE:  \n",
    "# Building the encoder layers only once but linking them twice ensures that the same weights are used by the AE and the clean encoder\n",
    "\n",
    "# Corrupt input and link noisy encoder (for DAE)\n",
    "corrupted_img  = GaussianNoise(stddev,name='corrupt_img')(input_img)\n",
    "\n",
    "encoded_corr = {} #  a dictionary holding all corrupted encoder levels. each level contains sublayers as specified by the linking function.\n",
    "encoded_corr[0] = corrupted_img\n",
    "sidepath_corr = {}\n",
    "sidepath_corr[0] = corrupted_img\n",
    "for key in sorted(encoder_layers.keys()):\n",
    "    encoded_corr[key],sidepath_corr[key] = link_sublayer_corr_encoder(encoded_corr[key-1],encoder_layers[key])\n",
    "    \n",
    "# Link the clean encoder (for supervised channel)\n",
    "encoded_clean={} #  a dictionary holding all clean encoder levels. each level contains sublayers as specified by the linking function.\n",
    "encoded_clean[0]=input_img\n",
    "sidepath_clean={}\n",
    "sidepath_clean[0]=input_img\n",
    "for key in sorted(encoder_layers.keys()):\n",
    "    encoded_clean[key],sidepath_clean[key] =  link_sublayer_clean_encoder(encoded_clean[key-1],encoder_layers[key])\n",
    "    \n",
    "# channel the output of the clean encoder into the classifier\n",
    "predicted_labels = Dense(10,activation='sigmoid',name='predictor')(encoded_clean[depth-1])\n",
    "\n",
    "## Create the decoder\n",
    "##########################################\n",
    "\n",
    "# Build a decoder\n",
    "decoder_layers = {} # a dictionary of dictionaries. The dictionary keys are the layer numbers (as in paper)\n",
    "for i in range(0,depth-1): # loop over all encoder levels\n",
    "    decoder_layers[i] = build_decoder_layer(Layer_dim[i],str(i),activation_name = 'sigmoid')\n",
    "    \n",
    "# Link the decoder to the corrupted encoder\n",
    "decoded = {} #  a dictionary holding all decoded levels. each level contains sublayers as specified by the linking function. \n",
    "decoded[depth-1] = CustomLayer_Normalization(name='decoded' + str(depth-1) + '/norm')(encoded_corr[depth-1]) # upper decoder layer is normalized upper corrupted encoder layer\n",
    "if combinator == 'none': # do not use combiner, but turn on non linearity using activations in the decoder channel\n",
    "    for i in range(depth-1)[::-1]: # gives the series depth-2,depth-3...,0\n",
    "        decoded[i] = link_sublayer_decoder(decoded[i+1],decoder_layers[i])\n",
    "    decoded_combined = decoded\n",
    "else:                # use combiner: decoded is the output of linking w/o activation, then combine with corr encoder and pass on\n",
    "    decoded_combined = {}\n",
    "    decoded_combined[depth-1] = CombinatorLayer(combinator=combinator,name='decoded' + str(depth-1) + '/combined')([sidepath_corr[depth-1],decoded[depth-1] ])\n",
    "    for i in range(depth-1)[::-1]: # gives the series depth-1,depth-2,depth-3...,0\n",
    "        decoded[i] = link_sublayer_decoder(decoded_combined[i+1],decoder_layers[i],do_activation = False)\n",
    "        decoded_combined[i] = CombinatorLayer(combinator=combinator,name='decoded' + str(i) + '/combined')([sidepath_corr[i],decoded[i] ])\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <tf.Tensor 'decoded0/combined/add_6:0' shape=(?, 784) dtype=float32>,\n",
       " 1: <tf.Tensor 'decoded1/combined/add_6:0' shape=(?, 128) dtype=float32>,\n",
       " 2: <tf.Tensor 'decoded2/combined/add_6:0' shape=(?, 32) dtype=float32>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'activation': <keras.layers.core.Activation at 0x19d2deb2e10>,\n",
       "  'batch_norm': <keras.layers.normalization.BatchNormalization at 0x19d2deb2a20>,\n",
       "  'lin_trans': <keras.layers.core.Dense at 0x19d2deb2828>,\n",
       "  'noise_add': <keras.layers.noise.GaussianNoise at 0x19d2deb29b0>,\n",
       "  'norm': <__main__.CustomLayer_Normalization at 0x19d2deb2b00>},\n",
       " 2: {'activation': <keras.layers.core.Activation at 0x19d2dede630>,\n",
       "  'batch_norm': <keras.layers.normalization.BatchNormalization at 0x19d2dede518>,\n",
       "  'lin_trans': <keras.layers.core.Dense at 0x19d2deb2be0>,\n",
       "  'noise_add': <keras.layers.noise.GaussianNoise at 0x19d2de65240>,\n",
       "  'norm': <__main__.CustomLayer_Normalization at 0x19d2de65160>}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a custom layer for the recon-loss\n",
    "The goal of the custom layer is to enable the addition of a loss function that depends not only on the model outputs but also on intermediate layers' outputs. For the ladder network these would be the reconstruction losses, which depend on the decoder and clean encoder layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Tensor(\"custom_layer__recon_loss_1/add:0\", shape=(), dtype=float32)\n",
      "1 Tensor(\"custom_layer__recon_loss_1/add_1:0\", shape=(), dtype=float32)\n",
      "2 Tensor(\"custom_layer__recon_loss_1/add_2:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## Define the custom layer\n",
    "#################################################\n",
    "# reconstruction loss weights\n",
    "w_rl = [1.0, 1.0, 1.0]\n",
    "\n",
    "class CustomLayer_ReconLoss(Layer):\n",
    "    def __init__(self, epsilon = 1e-6,combinator = False, **kwargs):\n",
    "        # class constructor\n",
    "        #self.loss_info = loss_info\n",
    "        self.is_placeholder = True\n",
    "        self.output_dim = 10\n",
    "        self.epsilon = epsilon\n",
    "        self.combinator = combinator\n",
    "        super(CustomLayer_ReconLoss, self).__init__(**kwargs)\n",
    "\n",
    "    def reconstruction_loss(self, encoder_list,decoder_list):\n",
    "        # add all reconstruction losses weighted by recon_weights\n",
    "        # note: the binary_crossentropy metric does not automatically average over the batch, \n",
    "        # this is done here by K.mean\n",
    "        \n",
    "        loss = 0\n",
    "        for i in range(len(encoder_list)):\n",
    "            # take decoder mean if no combinator is used, encoder mean if combining\n",
    "            # mean is in any case over the 0 axis = each pixel is averaged over the images in the mini-batch\n",
    "            '''\n",
    "            if self.combinator != 'none':\n",
    "                mean = K.mean(encoder_list[i],axis=0,keepdims=True)\n",
    "                std  = K.std(encoder_list[i],axis=0,keepdims=True)\n",
    "            else:\n",
    "                mean = K.mean(decoder_list[i],axis=0,keepdims=True)\n",
    "                std  = K.std(decoder_list[i],axis=0,keepdims=True)\n",
    "            print(encoder_list[i].shape)\n",
    "            '''\n",
    "            mean = 0\n",
    "            std = 1\n",
    "            #mean = K.mean(decoder_list[i],axis=0,keepdims=True)\n",
    "            #std  = K.std(decoder_list[i],axis=0,keepdims=True)\n",
    "            #mean_enc = K.mean(encoder_list[i],axis=0,keepdims=True)\n",
    "            #std_enc  = K.std(encoder_list[i],axis=0,keepdims=True)\n",
    "            #enc_norm = (encoder_list[i] - mean_enc)/(std_enc + self.epsilon)\n",
    "            dec_norm = (decoder_list[i] - mean)/(std + self.epsilon)\n",
    "            #loss += w_rl[i]*K.mean(K.square(dec_norm - enc_norm))\n",
    "            loss += w_rl[i]*K.mean(K.square(dec_norm - encoder_list[i]))\n",
    "            print(i,loss)    \n",
    "        return loss\n",
    "   \n",
    "    def call(self, inputs):\n",
    "        # inputs is a list of layers needed for the calculation of the reconstruction loss.\n",
    "        # The first layer in the list is the predicted labels.\n",
    "        # The rest of the list must contain pairs of clean encoder and decoder layers, \n",
    "        # that are needed for the reconstruction loss calculation.\n",
    "        # returns: predicted_labels, needed in order to calculate the supervised loss later on. \n",
    "        predicted_labels = inputs[0]   # predicted labels by clean encoder:  the return variable of the call\n",
    "        # call the loss function of the class as it is defined above\n",
    "        loss = self.reconstruction_loss(inputs[1::2],inputs[2::2]) # odd entries are encoder layers, even are decoder.\n",
    "        # add the custom loss to the model loss (defined in the compiler)\n",
    "        self.add_loss(loss, inputs=inputs) \n",
    "        return predicted_labels    \n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0]\n",
    "\n",
    "## Construct the inputs to CustomLayer_ReconLoss\n",
    "#################################################\n",
    "collection=[] # empty list of layers (see above in \"call\")\n",
    "collection.append(predicted_labels) # first layer in the list: predicted labels of clean encoder\n",
    "if combinator != 'none':\n",
    "    imax = depth\n",
    "else:\n",
    "    imax = depth - 1\n",
    "for i in range(imax): # later on collect from range(depth) :makes sense only after combining the AE legs\n",
    "    # append an encoder and a decoder layer for each ladder level\n",
    "    #collection.append(encoded_clean[i])\n",
    "    collection.append(sidepath_clean[i])  # from clean encoder, before BN and non lin\n",
    "    #collection.append(decoded[i])\n",
    "    collection.append(decoded_combined[i])\n",
    "    \n",
    "## Call the custom layer\n",
    "#################################################\n",
    "# when calling the CustomLayer_ReconLoss, the returned value of \"call(self, inputs)\" is returned\n",
    "# when building a model with y as an output, the custom loss is automatically added to the loss defined in the compiler\n",
    "y = CustomLayer_ReconLoss(combinator=combinator)(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'predictor/Sigmoid:0' shape=(?, 10) dtype=float32>,\n",
       " <tf.Tensor 'input_img:0' shape=(?, 784) dtype=float32>,\n",
       " <tf.Tensor 'decoded0/combined/add_6:0' shape=(?, 784) dtype=float32>,\n",
       " <tf.Tensor 'encoder_1/norm_1/truediv:0' shape=(?, 128) dtype=float32>,\n",
       " <tf.Tensor 'decoded1/combined/add_6:0' shape=(?, 128) dtype=float32>,\n",
       " <tf.Tensor 'encoder_2/norm_1/truediv:0' shape=(?, 32) dtype=float32>,\n",
       " <tf.Tensor 'decoded2/combined/add_6:0' shape=(?, 32) dtype=float32>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the model\n",
    "Construct a model with input_img as the input and y (the custom layer) as an output. when building a model with y as an output, the custom loss is automatically added to the loss defined in the compiler. This enables us to define a custom loss function and also to return the value y which are the predicted labels transferred to the model using the custom layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A model with custom layer with an added loss\n",
    "Important note: the need for a custom layer is only because we would like to add a loss that depends on internal parts of the networks and not only on the network output. In a previous version of the ladder the loss was a sum of supervised and unsupervised losses, where the unsupervised loss was a standard denoising autoencoder loss, without summing over all the internal reconstruction losses. There it was enough to define a model with a single input (input_img) and two outputs (decoded_img and predicted_labels) and assign a loss function per output. No custom layer was needed. However, if the loss depends on layers which are not the output layers of the network, we must define a custom layer just in order to construct the loss and add it to the supervised loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ladder_custom = Model(input_img,y) # if you replace y with predicted_labels you get a simple feed forward predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"1715pt\" viewBox=\"0.00 0.00 1473.00 1715.00\" width=\"1473pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 1711)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-1711 1469,-1711 1469,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 1774591879152 -->\n",
       "<g class=\"node\" id=\"node1\"><title>1774591879152</title>\n",
       "<polygon fill=\"none\" points=\"0,-1660.5 0,-1706.5 279,-1706.5 279,-1660.5 0,-1660.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"70\" y=\"-1679.8\">input_img: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"140,-1660.5 140,-1706.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"168\" y=\"-1691.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"140,-1683.5 196,-1683.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"168\" y=\"-1668.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"196,-1660.5 196,-1706.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"237.5\" y=\"-1691.3\">(None, 784)</text>\n",
       "<polyline fill=\"none\" points=\"196,-1683.5 279,-1683.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"237.5\" y=\"-1668.3\">(None, 784)</text>\n",
       "</g>\n",
       "<!-- 1774591879320 -->\n",
       "<g class=\"node\" id=\"node2\"><title>1774591879320</title>\n",
       "<polygon fill=\"none\" points=\"75,-1577.5 75,-1623.5 390,-1623.5 390,-1577.5 75,-1577.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-1596.8\">corrupt_img: GaussianNoise</text>\n",
       "<polyline fill=\"none\" points=\"251,-1577.5 251,-1623.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279\" y=\"-1608.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"251,-1600.5 307,-1600.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279\" y=\"-1585.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"307,-1577.5 307,-1623.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"348.5\" y=\"-1608.3\">(None, 784)</text>\n",
       "<polyline fill=\"none\" points=\"307,-1600.5 390,-1600.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"348.5\" y=\"-1585.3\">(None, 784)</text>\n",
       "</g>\n",
       "<!-- 1774591879152&#45;&gt;1774591879320 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>1774591879152-&gt;1774591879320</title>\n",
       "<path d=\"M164.913,-1660.37C175.575,-1651.08 188.113,-1640.16 199.476,-1630.26\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"201.876,-1632.81 207.118,-1623.61 197.278,-1627.54 201.876,-1632.81\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774591879208 -->\n",
       "<g class=\"node\" id=\"node3\"><title>1774591879208</title>\n",
       "<polygon fill=\"none\" points=\"87,-1494.5 87,-1540.5 354,-1540.5 354,-1494.5 87,-1494.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"151\" y=\"-1513.8\">encoder_1/lt: Dense</text>\n",
       "<polyline fill=\"none\" points=\"215,-1494.5 215,-1540.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"243\" y=\"-1525.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"215,-1517.5 271,-1517.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"243\" y=\"-1502.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"271,-1494.5 271,-1540.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"312.5\" y=\"-1525.3\">(None, 784)</text>\n",
       "<polyline fill=\"none\" points=\"271,-1517.5 354,-1517.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"312.5\" y=\"-1502.3\">(None, 128)</text>\n",
       "</g>\n",
       "<!-- 1774591879152&#45;&gt;1774591879208 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>1774591879152-&gt;1774591879208</title>\n",
       "<path d=\"M46.5,-1599.5C46.084,-1574.46 60.9051,-1557.15 82.0538,-1545.17\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"83.8279,-1548.2 91.1323,-1540.52 80.6364,-1541.97 83.8279,-1548.2\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774592017576 -->\n",
       "<g class=\"node\" id=\"node22\"><title>1774592017576</title>\n",
       "<polygon fill=\"none\" points=\"624,-0.5 624,-46.5 1465,-46.5 1465,-0.5 624,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"792.5\" y=\"-19.8\">custom_layer__recon_loss_1: CustomLayer_ReconLoss</text>\n",
       "<polyline fill=\"none\" points=\"961,-0.5 961,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"989\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"961,-23.5 1017,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"989\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1017,-0.5 1017,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1241\" y=\"-31.3\">[(None, 10), (None, 784), (1, 784), (None, 128), (1, 128), (None, 32), (1, 32)]</text>\n",
       "<polyline fill=\"none\" points=\"1017,-23.5 1465,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1241\" y=\"-8.3\">(None, 10)</text>\n",
       "</g>\n",
       "<!-- 1774591879152&#45;&gt;1774592017576 -->\n",
       "<g class=\"edge\" id=\"edge33\"><title>1774591879152-&gt;1774592017576</title>\n",
       "<path d=\"M675.5,-354.5C687.807,-350.045 683.417,-338.962 694.5,-332 782.723,-276.581 872.597,-365.495 921.5,-273.5\" fill=\"none\" stroke=\"black\"/>\n",
       "<path d=\"M84.5,-1267.5C92.6841,-1195.07 84.5,-1176.39 84.5,-1103.5 84.5,-1103.5 84.5,-1103.5 84.5,-686.5 84.5,-638.857 74.174,-618.548 103.5,-581 142.499,-531.067 255.452,-581.934 233.5,-522.5\" fill=\"none\" stroke=\"black\"/>\n",
       "<path d=\"M921.5,-271.5C961.023,-197.15 894.395,-153.458 940.5,-83 948.921,-70.1311 961.204,-59.8063 974.401,-51.6324\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"976.264,-54.5982 983.173,-46.5665 972.763,-48.5363 976.264,-54.5982\" stroke=\"black\"/>\n",
       "<path d=\"M46.5,-1599.5C44.4873,-1478.38 51.0173,-1447.56 70.5,-1328 74.7997,-1301.61 81.0189,-1296.01 84.5,-1269.5\" fill=\"none\" stroke=\"black\"/>\n",
       "<path d=\"M89.7882,-1660.46C67.8637,-1647.08 46.895,-1627.51 46.5,-1601.5\" fill=\"none\" stroke=\"black\"/>\n",
       "<path d=\"M233.5,-520.5C216.535,-475.98 218.132,-447.995 252.5,-415 389.408,-283.561 497.042,-421.097 675.5,-356.5\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774591879320&#45;&gt;1774591879208 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>1774591879320-&gt;1774591879208</title>\n",
       "<path d=\"M229.221,-1577.37C228.004,-1569.15 226.597,-1559.66 225.274,-1550.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"228.703,-1549.99 223.775,-1540.61 221.778,-1551.01 228.703,-1549.99\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774679116656 -->\n",
       "<g class=\"node\" id=\"node21\"><title>1774679116656</title>\n",
       "<polygon fill=\"none\" points=\"950,-83.5 950,-129.5 1385,-129.5 1385,-83.5 950,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1068\" y=\"-102.8\">decoded0/combined: CombinatorLayer</text>\n",
       "<polyline fill=\"none\" points=\"1186,-83.5 1186,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1214\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1186,-106.5 1242,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1214\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1242,-83.5 1242,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1313.5\" y=\"-114.3\">[(None, 784), (1, 784)]</text>\n",
       "<polyline fill=\"none\" points=\"1242,-106.5 1385,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1313.5\" y=\"-91.3\">(1, 784)</text>\n",
       "</g>\n",
       "<!-- 1774591879320&#45;&gt;1774679116656 -->\n",
       "<g class=\"edge\" id=\"edge30\"><title>1774591879320-&gt;1774679116656</title>\n",
       "<path d=\"M390.058,-1592.7C700.951,-1577.18 1363.5,-1532.69 1363.5,-1435.5 1363.5,-1435.5 1363.5,-1435.5 1363.5,-271.5 1363.5,-223.857 1375.73,-201.979 1344.5,-166 1332.69,-152.39 1317.64,-141.933 1301.32,-133.901\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1302.68,-130.676 1292.13,-129.684 1299.76,-137.037 1302.68,-130.676\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774591879936 -->\n",
       "<g class=\"node\" id=\"node4\"><title>1774591879936</title>\n",
       "<polygon fill=\"none\" points=\"75,-1411.5 75,-1457.5 490,-1457.5 490,-1411.5 75,-1411.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213\" y=\"-1430.8\">encoder_1/norm: CustomLayer_Normalization</text>\n",
       "<polyline fill=\"none\" points=\"351,-1411.5 351,-1457.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"379\" y=\"-1442.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"351,-1434.5 407,-1434.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"379\" y=\"-1419.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"407,-1411.5 407,-1457.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"448.5\" y=\"-1442.3\">(None, 128)</text>\n",
       "<polyline fill=\"none\" points=\"407,-1434.5 490,-1434.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"448.5\" y=\"-1419.3\">(None, 128)</text>\n",
       "</g>\n",
       "<!-- 1774591879208&#45;&gt;1774591879936 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>1774591879208-&gt;1774591879936</title>\n",
       "<path d=\"M237.442,-1494.37C244.208,-1485.53 252.108,-1475.21 259.386,-1465.7\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"262.28,-1467.68 265.579,-1457.61 256.721,-1463.42 262.28,-1467.68\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774591879600 -->\n",
       "<g class=\"node\" id=\"node5\"><title>1774591879600</title>\n",
       "<polygon fill=\"none\" points=\"118.5,-1328.5 118.5,-1374.5 456.5,-1374.5 456.5,-1328.5 118.5,-1328.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-1347.8\">encoder_1/noise: GaussianNoise</text>\n",
       "<polyline fill=\"none\" points=\"317.5,-1328.5 317.5,-1374.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"345.5\" y=\"-1359.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"317.5,-1351.5 373.5,-1351.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"345.5\" y=\"-1336.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"373.5,-1328.5 373.5,-1374.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"415\" y=\"-1359.3\">(None, 128)</text>\n",
       "<polyline fill=\"none\" points=\"373.5,-1351.5 456.5,-1351.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"415\" y=\"-1336.3\">(None, 128)</text>\n",
       "</g>\n",
       "<!-- 1774591879936&#45;&gt;1774591879600 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>1774591879936-&gt;1774591879600</title>\n",
       "<path d=\"M283.866,-1411.37C284.373,-1403.15 284.959,-1393.66 285.511,-1384.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"289.013,-1384.8 286.135,-1374.61 282.026,-1384.37 289.013,-1384.8\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774591879712 -->\n",
       "<g class=\"node\" id=\"node6\"><title>1774591879712</title>\n",
       "<polygon fill=\"none\" points=\"113,-1245.5 113,-1291.5 462,-1291.5 462,-1245.5 113,-1245.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-1264.8\">encoder_1/bn: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"323,-1245.5 323,-1291.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"351\" y=\"-1276.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"323,-1268.5 379,-1268.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"351\" y=\"-1253.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"379,-1245.5 379,-1291.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"420.5\" y=\"-1276.3\">(None, 128)</text>\n",
       "<polyline fill=\"none\" points=\"379,-1268.5 462,-1268.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"420.5\" y=\"-1253.3\">(None, 128)</text>\n",
       "</g>\n",
       "<!-- 1774591879936&#45;&gt;1774591879712 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>1774591879936-&gt;1774591879712</title>\n",
       "<path d=\"M84.5,-1350.5C80.9599,-1326.13 92.2601,-1308.91 111.104,-1296.78\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"113,-1299.73 119.942,-1291.73 109.524,-1293.66 113,-1299.73\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774591879936&#45;&gt;1774592017576 -->\n",
       "<g class=\"edge\" id=\"edge35\"><title>1774591879936-&gt;1774592017576</title>\n",
       "<path d=\"M84.5,-1350.5C79.3246,-1314.87 80.4579,-1305.27 84.5,-1269.5\" fill=\"none\" stroke=\"black\"/>\n",
       "<path d=\"M133,-1411.35C107.909,-1399.16 88.5846,-1380.62 84.5,-1352.5\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774591879600&#45;&gt;1774591879712 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>1774591879600-&gt;1774591879712</title>\n",
       "<path d=\"M287.5,-1328.37C287.5,-1320.15 287.5,-1310.66 287.5,-1301.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"291,-1301.61 287.5,-1291.61 284,-1301.61 291,-1301.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774678080424 -->\n",
       "<g class=\"node\" id=\"node17\"><title>1774678080424</title>\n",
       "<polygon fill=\"none\" points=\"704,-332.5 704,-378.5 1139,-378.5 1139,-332.5 704,-332.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"822\" y=\"-351.8\">decoded1/combined: CombinatorLayer</text>\n",
       "<polyline fill=\"none\" points=\"940,-332.5 940,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"968\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"940,-355.5 996,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"968\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"996,-332.5 996,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1067.5\" y=\"-363.3\">[(None, 128), (1, 128)]</text>\n",
       "<polyline fill=\"none\" points=\"996,-355.5 1139,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1067.5\" y=\"-340.3\">(1, 128)</text>\n",
       "</g>\n",
       "<!-- 1774591879600&#45;&gt;1774678080424 -->\n",
       "<g class=\"edge\" id=\"edge25\"><title>1774591879600-&gt;1774678080424</title>\n",
       "<path d=\"M456.772,-1338.47C638.823,-1320.76 902.5,-1279.11 902.5,-1186.5 902.5,-1186.5 902.5,-1186.5 902.5,-520.5 902.5,-474.463 909.979,-421.636 915.553,-388.662\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"919.022,-389.139 917.283,-378.688 912.125,-387.942 919.022,-389.139\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774591880720 -->\n",
       "<g class=\"node\" id=\"node7\"><title>1774591880720</title>\n",
       "<polygon fill=\"none\" points=\"261.5,-1162.5 261.5,-1208.5 579.5,-1208.5 579.5,-1162.5 261.5,-1162.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"351\" y=\"-1181.8\">encoder_1/output: Activation</text>\n",
       "<polyline fill=\"none\" points=\"440.5,-1162.5 440.5,-1208.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"468.5\" y=\"-1193.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"440.5,-1185.5 496.5,-1185.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"468.5\" y=\"-1170.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"496.5,-1162.5 496.5,-1208.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"538\" y=\"-1193.3\">(None, 128)</text>\n",
       "<polyline fill=\"none\" points=\"496.5,-1185.5 579.5,-1185.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"538\" y=\"-1170.3\">(None, 128)</text>\n",
       "</g>\n",
       "<!-- 1774591879712&#45;&gt;1774591880720 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>1774591879712-&gt;1774591880720</title>\n",
       "<path d=\"M323.843,-1245.37C339.824,-1235.63 358.752,-1224.11 375.604,-1213.84\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"377.481,-1216.8 384.201,-1208.61 373.84,-1210.82 377.481,-1216.8\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774591880160 -->\n",
       "<g class=\"node\" id=\"node8\"><title>1774591880160</title>\n",
       "<polygon fill=\"none\" points=\"354,-1079.5 354,-1125.5 621,-1125.5 621,-1079.5 354,-1079.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"418\" y=\"-1098.8\">encoder_2/lt: Dense</text>\n",
       "<polyline fill=\"none\" points=\"482,-1079.5 482,-1125.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"510\" y=\"-1110.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"482,-1102.5 538,-1102.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"510\" y=\"-1087.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"538,-1079.5 538,-1125.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"579.5\" y=\"-1110.3\">(None, 128)</text>\n",
       "<polyline fill=\"none\" points=\"538,-1102.5 621,-1102.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"579.5\" y=\"-1087.3\">(None, 32)</text>\n",
       "</g>\n",
       "<!-- 1774591880720&#45;&gt;1774591880160 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>1774591880720-&gt;1774591880160</title>\n",
       "<path d=\"M438.808,-1162.37C446.194,-1153.44 454.83,-1143 462.761,-1133.41\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"465.537,-1135.54 469.214,-1125.61 460.143,-1131.08 465.537,-1135.54\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774591562080 -->\n",
       "<g class=\"node\" id=\"node9\"><title>1774591562080</title>\n",
       "<polygon fill=\"none\" points=\"350,-996.5 350,-1042.5 759,-1042.5 759,-996.5 350,-996.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"488\" y=\"-1015.8\">encoder_2/norm: CustomLayer_Normalization</text>\n",
       "<polyline fill=\"none\" points=\"626,-996.5 626,-1042.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"654\" y=\"-1027.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"626,-1019.5 682,-1019.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"654\" y=\"-1004.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"682,-996.5 682,-1042.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"720.5\" y=\"-1027.3\">(None, 32)</text>\n",
       "<polyline fill=\"none\" points=\"682,-1019.5 759,-1019.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"720.5\" y=\"-1004.3\">(None, 32)</text>\n",
       "</g>\n",
       "<!-- 1774591880160&#45;&gt;1774591562080 -->\n",
       "<g class=\"edge\" id=\"edge13\"><title>1774591880160-&gt;1774591562080</title>\n",
       "<path d=\"M505.808,-1079.37C513.194,-1070.44 521.83,-1060 529.761,-1050.41\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"532.537,-1052.54 536.214,-1042.61 527.143,-1048.08 532.537,-1052.54\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774591562304 -->\n",
       "<g class=\"node\" id=\"node10\"><title>1774591562304</title>\n",
       "<polygon fill=\"none\" points=\"486.5,-913.5 486.5,-959.5 818.5,-959.5 818.5,-913.5 486.5,-913.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"586\" y=\"-932.8\">encoder_2/noise: GaussianNoise</text>\n",
       "<polyline fill=\"none\" points=\"685.5,-913.5 685.5,-959.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"713.5\" y=\"-944.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"685.5,-936.5 741.5,-936.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"713.5\" y=\"-921.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"741.5,-913.5 741.5,-959.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"780\" y=\"-944.3\">(None, 32)</text>\n",
       "<polyline fill=\"none\" points=\"741.5,-936.5 818.5,-936.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"780\" y=\"-921.3\">(None, 32)</text>\n",
       "</g>\n",
       "<!-- 1774591562080&#45;&gt;1774591562304 -->\n",
       "<g class=\"edge\" id=\"edge15\"><title>1774591562080-&gt;1774591562304</title>\n",
       "<path d=\"M581.279,-996.366C592.514,-987.08 605.727,-976.16 617.701,-966.262\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"620.275,-968.676 625.753,-959.607 615.816,-963.28 620.275,-968.676\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774592058648 -->\n",
       "<g class=\"node\" id=\"node11\"><title>1774592058648</title>\n",
       "<polygon fill=\"none\" points=\"288,-830.5 288,-876.5 631,-876.5 631,-830.5 288,-830.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"393\" y=\"-849.8\">encoder_2/bn: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"498,-830.5 498,-876.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"526\" y=\"-861.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"498,-853.5 554,-853.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"526\" y=\"-838.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"554,-830.5 554,-876.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"592.5\" y=\"-861.3\">(None, 32)</text>\n",
       "<polyline fill=\"none\" points=\"554,-853.5 631,-853.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"592.5\" y=\"-838.3\">(None, 32)</text>\n",
       "</g>\n",
       "<!-- 1774591562080&#45;&gt;1774592058648 -->\n",
       "<g class=\"edge\" id=\"edge17\"><title>1774591562080-&gt;1774592058648</title>\n",
       "<path d=\"M514.069,-996.357C500.405,-986.904 486.378,-974.643 477.5,-960 464.172,-938.017 459.992,-908.979 458.966,-886.934\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"462.459,-886.636 458.689,-876.734 455.462,-886.826 462.459,-886.636\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774591562080&#45;&gt;1774592017576 -->\n",
       "<g class=\"edge\" id=\"edge37\"><title>1774591562080-&gt;1774592017576</title>\n",
       "<path d=\"M730.506,-996.454C773.875,-987.625 812.29,-975.719 827.5,-960 860.63,-925.761 846.5,-902.143 846.5,-854.5 846.5,-854.5 846.5,-854.5 846.5,-686.5 846.5,-638.776 844.632,-625.145 826.5,-581 780.814,-469.769 562.23,-396.866 675.5,-356.5\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774591562304&#45;&gt;1774592058648 -->\n",
       "<g class=\"edge\" id=\"edge16\"><title>1774591562304-&gt;1774592058648</title>\n",
       "<path d=\"M600.017,-913.473C575.767,-903.296 546.798,-891.138 521.48,-880.512\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"522.548,-877.165 511.973,-876.522 519.839,-883.619 522.548,-877.165\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774678081208 -->\n",
       "<g class=\"node\" id=\"node14\"><title>1774678081208</title>\n",
       "<polygon fill=\"none\" points=\"373,-581.5 373,-627.5 818,-627.5 818,-581.5 373,-581.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"491\" y=\"-600.8\">decoded2/combined: CombinatorLayer</text>\n",
       "<polyline fill=\"none\" points=\"609,-581.5 609,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"637\" y=\"-612.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"609,-604.5 665,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"637\" y=\"-589.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"665,-581.5 665,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"741.5\" y=\"-612.3\">[(None, 32), (None, 32)]</text>\n",
       "<polyline fill=\"none\" points=\"665,-604.5 818,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"741.5\" y=\"-589.3\">(1, 32)</text>\n",
       "</g>\n",
       "<!-- 1774591562304&#45;&gt;1774678081208 -->\n",
       "<g class=\"edge\" id=\"edge21\"><title>1774591562304-&gt;1774678081208</title>\n",
       "<path d=\"M661.554,-913.265C679.727,-864.94 715.468,-747.936 673.5,-664 667.528,-652.056 657.829,-641.918 647.268,-633.607\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"649.208,-630.689 639.071,-627.608 645.074,-636.338 649.208,-630.689\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774592058928 -->\n",
       "<g class=\"node\" id=\"node12\"><title>1774592058928</title>\n",
       "<polygon fill=\"none\" points=\"303.5,-747.5 303.5,-793.5 615.5,-793.5 615.5,-747.5 303.5,-747.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"393\" y=\"-766.8\">encoder_2/output: Activation</text>\n",
       "<polyline fill=\"none\" points=\"482.5,-747.5 482.5,-793.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"510.5\" y=\"-778.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"482.5,-770.5 538.5,-770.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"510.5\" y=\"-755.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"538.5,-747.5 538.5,-793.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"577\" y=\"-778.3\">(None, 32)</text>\n",
       "<polyline fill=\"none\" points=\"538.5,-770.5 615.5,-770.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"577\" y=\"-755.3\">(None, 32)</text>\n",
       "</g>\n",
       "<!-- 1774592058648&#45;&gt;1774592058928 -->\n",
       "<g class=\"edge\" id=\"edge18\"><title>1774592058648-&gt;1774592058928</title>\n",
       "<path d=\"M459.5,-830.366C459.5,-822.152 459.5,-812.658 459.5,-803.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"463,-803.607 459.5,-793.607 456,-803.607 463,-803.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774666710824 -->\n",
       "<g class=\"node\" id=\"node13\"><title>1774666710824</title>\n",
       "<polygon fill=\"none\" points=\"260,-664.5 260,-710.5 665,-710.5 665,-664.5 260,-664.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"396\" y=\"-683.8\">decoded2/norm: CustomLayer_Normalization</text>\n",
       "<polyline fill=\"none\" points=\"532,-664.5 532,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"560\" y=\"-695.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"532,-687.5 588,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"560\" y=\"-672.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"588,-664.5 588,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"626.5\" y=\"-695.3\">(None, 32)</text>\n",
       "<polyline fill=\"none\" points=\"588,-687.5 665,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"626.5\" y=\"-672.3\">(None, 32)</text>\n",
       "</g>\n",
       "<!-- 1774592058928&#45;&gt;1774666710824 -->\n",
       "<g class=\"edge\" id=\"edge20\"><title>1774592058928-&gt;1774666710824</title>\n",
       "<path d=\"M460.32,-747.366C460.624,-739.152 460.976,-729.658 461.306,-720.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"464.809,-720.73 461.681,-710.607 457.813,-720.47 464.809,-720.73\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774591880048 -->\n",
       "<g class=\"node\" id=\"node20\"><title>1774591880048</title>\n",
       "<polygon fill=\"none\" points=\"112.5,-581.5 112.5,-627.5 354.5,-627.5 354.5,-581.5 112.5,-581.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"167\" y=\"-600.8\">predictor: Dense</text>\n",
       "<polyline fill=\"none\" points=\"221.5,-581.5 221.5,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249.5\" y=\"-612.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"221.5,-604.5 277.5,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249.5\" y=\"-589.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"277.5,-581.5 277.5,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"316\" y=\"-612.3\">(None, 32)</text>\n",
       "<polyline fill=\"none\" points=\"277.5,-604.5 354.5,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"316\" y=\"-589.3\">(None, 10)</text>\n",
       "</g>\n",
       "<!-- 1774592058928&#45;&gt;1774591880048 -->\n",
       "<g class=\"edge\" id=\"edge29\"><title>1774592058928-&gt;1774591880048</title>\n",
       "<path d=\"M303.421,-747.679C283.42,-739.015 264.929,-727.162 250.5,-711 232.928,-691.318 229.633,-660.944 230.176,-637.833\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"233.674,-637.945 230.658,-627.789 226.682,-637.61 233.674,-637.945\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774666710824&#45;&gt;1774678081208 -->\n",
       "<g class=\"edge\" id=\"edge22\"><title>1774666710824-&gt;1774678081208</title>\n",
       "<path d=\"M498.843,-664.366C514.824,-654.634 533.752,-643.106 550.604,-632.842\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"552.481,-635.798 559.201,-627.607 548.84,-629.819 552.481,-635.798\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774678005408 -->\n",
       "<g class=\"node\" id=\"node15\"><title>1774678005408</title>\n",
       "<polygon fill=\"none\" points=\"406,-498.5 406,-544.5 643,-544.5 643,-498.5 406,-498.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"466.5\" y=\"-517.8\">decoder1/lt: Dense</text>\n",
       "<polyline fill=\"none\" points=\"527,-498.5 527,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"555\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"527,-521.5 583,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"555\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"583,-498.5 583,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"613\" y=\"-529.3\">(1, 32)</text>\n",
       "<polyline fill=\"none\" points=\"583,-521.5 643,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"613\" y=\"-506.3\">(1, 128)</text>\n",
       "</g>\n",
       "<!-- 1774678081208&#45;&gt;1774678005408 -->\n",
       "<g class=\"edge\" id=\"edge23\"><title>1774678081208-&gt;1774678005408</title>\n",
       "<path d=\"M576.099,-581.366C568.272,-572.437 559.121,-561.997 550.716,-552.409\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"553.101,-549.82 543.878,-544.607 547.837,-554.434 553.101,-549.82\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774678081208&#45;&gt;1774592017576 -->\n",
       "<g class=\"edge\" id=\"edge38\"><title>1774678081208-&gt;1774592017576</title>\n",
       "<path d=\"M443.405,-581.491C347.884,-565.688 241.275,-543.55 233.5,-522.5\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774678080760 -->\n",
       "<g class=\"node\" id=\"node16\"><title>1774678080760</title>\n",
       "<polygon fill=\"none\" points=\"262,-415.5 262,-461.5 647,-461.5 647,-415.5 262,-415.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"396.5\" y=\"-434.8\">decoder1/norm: CustomLayer_Normalization</text>\n",
       "<polyline fill=\"none\" points=\"531,-415.5 531,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"559\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"531,-438.5 587,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"559\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"587,-415.5 587,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"617\" y=\"-446.3\">(1, 128)</text>\n",
       "<polyline fill=\"none\" points=\"587,-438.5 647,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"617\" y=\"-423.3\">(1, 128)</text>\n",
       "</g>\n",
       "<!-- 1774678005408&#45;&gt;1774678080760 -->\n",
       "<g class=\"edge\" id=\"edge24\"><title>1774678005408-&gt;1774678080760</title>\n",
       "<path d=\"M505.372,-498.366C497.656,-489.437 488.633,-478.997 480.347,-469.409\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"482.791,-466.884 473.605,-461.607 477.495,-471.462 482.791,-466.884\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774678080760&#45;&gt;1774678080424 -->\n",
       "<g class=\"edge\" id=\"edge26\"><title>1774678080760-&gt;1774678080424</title>\n",
       "<path d=\"M581.493,-415.473C644.306,-404.579 720.205,-391.414 784.343,-380.289\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"785.278,-383.68 794.532,-378.522 784.081,-376.783 785.278,-383.68\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774593857184 -->\n",
       "<g class=\"node\" id=\"node18\"><title>1774593857184</title>\n",
       "<polygon fill=\"none\" points=\"987,-249.5 987,-295.5 1224,-295.5 1224,-249.5 987,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1047.5\" y=\"-268.8\">decoder0/lt: Dense</text>\n",
       "<polyline fill=\"none\" points=\"1108,-249.5 1108,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1136\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1108,-272.5 1164,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1136\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1164,-249.5 1164,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1194\" y=\"-280.3\">(1, 128)</text>\n",
       "<polyline fill=\"none\" points=\"1164,-272.5 1224,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1194\" y=\"-257.3\">(1, 784)</text>\n",
       "</g>\n",
       "<!-- 1774678080424&#45;&gt;1774593857184 -->\n",
       "<g class=\"edge\" id=\"edge27\"><title>1774678080424-&gt;1774593857184</title>\n",
       "<path d=\"M971.779,-332.366C994.699,-322.277 1022,-310.257 1045.94,-299.718\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1047.54,-302.839 1055.28,-295.607 1044.72,-296.433 1047.54,-302.839\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774678080424&#45;&gt;1774592017576 -->\n",
       "<g class=\"edge\" id=\"edge36\"><title>1774678080424-&gt;1774592017576</title>\n",
       "<path d=\"M916.102,-332.176C913.2,-315.1 911.929,-291.505 921.5,-273.5\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774677926128 -->\n",
       "<g class=\"node\" id=\"node19\"><title>1774677926128</title>\n",
       "<polygon fill=\"none\" points=\"950,-166.5 950,-212.5 1335,-212.5 1335,-166.5 950,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1084.5\" y=\"-185.8\">decoder0/norm: CustomLayer_Normalization</text>\n",
       "<polyline fill=\"none\" points=\"1219,-166.5 1219,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1247\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1219,-189.5 1275,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1247\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1275,-166.5 1275,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1305\" y=\"-197.3\">(1, 784)</text>\n",
       "<polyline fill=\"none\" points=\"1275,-189.5 1335,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1305\" y=\"-174.3\">(1, 784)</text>\n",
       "</g>\n",
       "<!-- 1774593857184&#45;&gt;1774677926128 -->\n",
       "<g class=\"edge\" id=\"edge28\"><title>1774593857184-&gt;1774677926128</title>\n",
       "<path d=\"M1115.61,-249.366C1119.49,-240.884 1123.98,-231.037 1128.18,-221.853\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1131.43,-223.157 1132.4,-212.607 1125.06,-220.249 1131.43,-223.157\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774677926128&#45;&gt;1774679116656 -->\n",
       "<g class=\"edge\" id=\"edge31\"><title>1774677926128-&gt;1774679116656</title>\n",
       "<path d=\"M1149.33,-166.366C1151.89,-158.062 1154.86,-148.451 1157.64,-139.434\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1161.07,-140.194 1160.68,-129.607 1154.38,-138.13 1161.07,-140.194\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774591880048&#45;&gt;1774592017576 -->\n",
       "<g class=\"edge\" id=\"edge32\"><title>1774591880048-&gt;1774592017576</title>\n",
       "<path d=\"M237.529,-581.462C239.639,-564.75 240.516,-541.496 233.5,-522.5\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1774679116656&#45;&gt;1774592017576 -->\n",
       "<g class=\"edge\" id=\"edge34\"><title>1774679116656-&gt;1774592017576</title>\n",
       "<path d=\"M1133.89,-83.3664C1119.25,-73.723 1101.93,-62.3171 1086.45,-52.1252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1088.35,-49.1837 1078.07,-46.6068 1084.5,-55.0299 1088.35,-49.1837\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ladder_custom.summary()\n",
    "SVG(model_to_dot(ladder_custom,show_shapes=True).create(prog='dot',format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the model\n",
    "In the compiler, supply the loss of the supervised part. The reconstruction loss is added automatically by the model due to the custom layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ladder_custom.compile(optimizer='adadelta', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_img (InputLayer)          (None, 784)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "corrupt_img (GaussianNoise)     (None, 784)          0           input_img[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1/lt (Dense)            (None, 128)          100480      corrupt_img[0][0]                \n",
      "                                                                 input_img[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1/norm (CustomLayer_Nor (None, 128)          0           encoder_1/lt[0][0]               \n",
      "                                                                 encoder_1/lt[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1/noise (GaussianNoise) (None, 128)          0           encoder_1/norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1/bn (BatchNormalizatio (None, 128)          512         encoder_1/noise[0][0]            \n",
      "                                                                 encoder_1/norm[1][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1/output (Activation)   (None, 128)          0           encoder_1/bn[0][0]               \n",
      "                                                                 encoder_1/bn[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2/lt (Dense)            (None, 32)           4128        encoder_1/output[0][0]           \n",
      "                                                                 encoder_1/output[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2/norm (CustomLayer_Nor (None, 32)           0           encoder_2/lt[0][0]               \n",
      "                                                                 encoder_2/lt[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2/noise (GaussianNoise) (None, 32)           0           encoder_2/norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2/bn (BatchNormalizatio (None, 32)           128         encoder_2/noise[0][0]            \n",
      "                                                                 encoder_2/norm[1][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2/output (Activation)   (None, 32)           0           encoder_2/bn[0][0]               \n",
      "                                                                 encoder_2/bn[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoded2/norm (CustomLayer_Norm (None, 32)           0           encoder_2/output[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoded2/combined (CombinatorLa (1, 32)              288         encoder_2/noise[0][0]            \n",
      "                                                                 decoded2/norm[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1/lt (Dense)             (1, 128)             4224        decoded2/combined[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder1/norm (CustomLayer_Norm (1, 128)             0           decoder1/lt[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoded1/combined (CombinatorLa (1, 128)             1152        encoder_1/noise[0][0]            \n",
      "                                                                 decoder1/norm[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder0/lt (Dense)             (1, 784)             101136      decoded1/combined[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder0/norm (CustomLayer_Norm (1, 784)             0           decoder0/lt[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "predictor (Dense)               (None, 10)           330         encoder_2/output[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoded0/combined (CombinatorLa (1, 784)             7056        corrupt_img[0][0]                \n",
      "                                                                 decoder0/norm[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "custom_layer__recon_loss_1 (Cus (None, 10)           0           predictor[0][0]                  \n",
      "                                                                 input_img[0][0]                  \n",
      "                                                                 decoded0/combined[0][0]          \n",
      "                                                                 encoder_1/norm[1][0]             \n",
      "                                                                 decoded1/combined[0][0]          \n",
      "                                                                 encoder_2/norm[1][0]             \n",
      "                                                                 decoded2/combined[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 219,434\n",
      "Trainable params: 219,114\n",
      "Non-trainable params: 320\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ladder_custom.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "The model output y are the predicted labels. The loss function, however, containes contributions from the autoencoder. This is why the network is trained to reconstruct (DAE) and classify (clean encoder) simultaneously, even though this cannot be seen from the arguments of the fit below ( (train_x, train_y) looks like a supervised classification only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 26s 427us/step - loss: 0.5256 - val_loss: 0.1216\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 24s 394us/step - loss: 0.1150 - val_loss: 0.0861\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 24s 393us/step - loss: 0.0814 - val_loss: 0.0760\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 24s 396us/step - loss: 0.0647 - val_loss: 0.0737\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 24s 397us/step - loss: 0.0519 - val_loss: 0.0694\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 25s 422us/step - loss: 0.0442 - val_loss: 0.0749\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 25s 414us/step - loss: 0.0384 - val_loss: 0.0698\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 24s 407us/step - loss: 0.0323 - val_loss: 0.0649\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 24s 407us/step - loss: 0.0295 - val_loss: 0.0726\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 24s 402us/step - loss: 0.0264 - val_loss: 0.0759\n"
     ]
    }
   ],
   "source": [
    "infoLadder=ladder_custom.fit(x_train,y_train,\n",
    "                epochs=10,\n",
    "                batch_size=100,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting and plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encode and decode some digits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A layer is an object which has a well defined number of outputs. The input is not specified upon definition of the layer, but only upon \"linking\", i.e when the layer received a specific input. Only after linking, the weight tensor is defined and can then be trained. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predicting\n",
    "After training the network we obtain a set of linked layers that already contain the trained weights. For example, \"decoded[0]\" stands for the output of the autoencoder which is linked to the input input_img, via a set of specific weights. We can now construct a new model that uses the weights for prediction. \n",
    "\n",
    "After constructing the model we can perform a prediction giving it x_test as an input, and obtaining the decoded image as an output. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ladder_for_prediction = Model(input_img,[decoded[0],predicted_labels])\n",
    "ladder_for_prediction = Model(input_img,[decoded_combined[0],predicted_labels])\n",
    "\n",
    "# Thenext two lines are for thesimple feed forawrd without the aouteconde\n",
    "#ladder_for_prediction = Model(input_img,predicted_labels)\n",
    "#encoder_output=ladder_for_prediction.predict(x_test)\n",
    "[decoded_imgs,pred_labels] = ladder_for_prediction.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and std of decoded : 0.133, 0.302\n",
      "Mean and std of original: 0.131, 0.301\n",
      "Accuracy: 97.63 %\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABZYAAACLCAYAAADyHszlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzsnXeYVOX1xz+zfVm60kQFUUGKFVRC\nVBREEVHB3og1EjVGyc+KLYrBhtgbatRIrCiKFdFYEoUo0YhRsAQrUgXpbL2/P+6ee995587szDJ3\np+z5PM8+uztz5973nnnvW7/nnIjjOCiKoiiKoiiKoiiKoiiKoihKshRkugCKoiiKoiiKoiiKoiiK\noihKbqELy4qiKIqiKIqiKIqiKIqiKEpK6MKyoiiKoiiKoiiKoiiKoiiKkhK6sKwoiqIoiqIoiqIo\niqIoiqKkhC4sK4qiKIqiKIqiKIqiKIqiKCmhC8uKoiiKoiiKoiiKoiiKoihKSujCsqIoiqIoiqIo\niqIoiqIoipISurCsKIqiKIqiKIqiKIqiKIqipIQuLCuKoiiKoiiKoiiKoiiKoigpUZTKwZFIxAmr\nIJnAcZxIus6ltkmM2ic+apvEqH3io7aJT77ZBljhOE6HdJ0s3+yjdSchWncSoHUnIVp3EqB1JyFa\ndxKgdSc+Oo9IjNad+GjdSYzWnfiobRKSVH+uimVFURRFyX6+y3QBlJxF647SWLTuKI1F646iKIqi\n5D5J9ee6sKwoiqIoiqIoiqIoiqIoiqKkhC4sK4qiKIqiKIqiKIqiKIqiKCmRUoxlRVEURVEURWkq\n3nrrLQDeeecdAP70pz9lsDSKoiiKoiiKklmKi4sBuOaaawDo3LkzAFdffTU//PBDk5dHFcuKoiiK\noiiKoiiKoiiKoihKSqhiWVEURVEURckq9t9//8DfgwcP5oADDshMoRRFURRFURQlw7zyyisADB06\nNOr18vJyTjjhhCYvT1YtLFdUVACw1157AfDqq68CUFpaCsCzzz7rGam6ujoDJcxehg0b5rmHDho0\nCADHcQCYNGkSAOPHjwegpqam6QuoKErOUVJSAsDMmTMBOPXUUwH47jtN9q5EI+5YJ554IuAPcsaM\nGZP0OU4++WQAnnrqKSB/+ioJ5bDffvsB0KNHD0Cfo3jIArLYLd77iqLEp1WrVgB069YNgN/85jcA\nnHLKKQBsueWWABQUuM6rdXV1Xpsk84Unn3yy6QqcJWy11VYADBkyBIDdd9896c/eeuutAPz444/p\nL1gWsdNOOwHw3HPPAe5884orrgBg+vTpGStXUyPP2IsvvgjAv//9bwCeeOIJAP7zn/8A+TOWUcLj\nzjvvBOCcc84B/NAG1157bcbKlG1ImIc999wTgGnTpvHGG28AMGHCBACWLVsGQFVVFZB/bXFRkbt0\n27dvXwB69uwJ+Ouia9euBeD666/PQOk0FIaiKIqiKIqiKIqiKIqiKIqSIhFRtSZ1cCSS/MEN0L59\ne3r37g3AscceC/hqpTZt2tjXBdwdUdkFTEUFFQ/HcSKbfZJ60mkbE1EUDB8+HIA5c+YAvq1kZ/2E\nE06gRYsWgL8zumnTJgAWLVoEuO6jAMuXL2/wuum0DYRnn0yRC3UnU2jdSUwu1Z3jjjsO8NUX4k0y\nd+7cUK6XS7aJhyh5nn/+eXbccceo9/7xj38AcP755wPwySefpHLqfzuOMyAdZYT02EeUbmPGjOHy\nyy8HYIcddtjc03L33XcDvmpu3bp1gO+FE0Q2152nn34agNGjRwPw17/+FfDrgdxfiGRd3QlCFMrx\nFMlvv/024Cp55O90kM11pzEMGOB+1R9++CHgKlHB9yYQj4AkyYm6I4jnhCgJhd///veAO7/44x//\nCMDSpUsBOOiggwCYN29eytfL1rrTt29fT20scy0bmQssWbIEcL1DRf30zTffAHDIIYcA8PXXXzem\nGDlRd+Se27dvD/iK244dOwLB/Y45LzX56quvgPg2N8nWupOIxx57DIBRo0YBvkJ3/vz5XrsjasLN\nIVfmEaKW/PWvfw34akGpS+Kmfvjhh6f1utlcd6QNlvHb7373O8B/Nm6//XbA9UIPg1ypOzbvvfce\nAHvvvTfgr92Ix4nJvffeC8DZZ5+d8nWyue7EQ8bOd911FwCdOnVq8DPffvst4M9bV65c2eBncsE2\ne+yxBxA7D5e2SMYzIZBUf66KZUVRFEVRFEVRFEVRFEVRFCUlQlcsSywQWWEfO3YsAAceeCBdu3ZN\n9rqAuzO8Zs0awF+R3xzlXDbvTBxzzDEAXHfddUDDKrAzzzyTX375BfCVyoWFhYC/cyoqqWTItR0/\n2eG74IILAN9+oqiLRCJMnToVgHPPPRfAq0uNIZvrjijXRW0qO+miypCdzmnTpgHpj1eea3VHGDdu\nHOCruvr37y/X55ZbbgHgwgsv3OzrZHPdsZFYjA8//DDgP1933HFHKNfLJdsIspN+/PHHA3D00UcD\niVVOEpfw9NNPB3yVSwNknfpL2pQFCxZsdnkS0a5dOwBWr14d95hsrjvdu3cHfMWOcMYZZwCp9c2N\nJOvqjonkh7j66qsD3zeVyub/6SKb606qDB48mL/85S+AX+9EsSyq02TUlAYZrzv77LMP4McIToQo\nmUaOHJn0+UUpf+CBB6ZatKyrO2eeeSbg9tGSn0b6l9mzZwN+eyOKdqkXrVq14s033wT8OZuMfS65\n5JLGFCfjdScePXv25LzzzgP8sbLMlYzrAdF9+csvvwzAxo0bAdhiiy0AYpKJytw3EdlWd4KQ3EdS\nZ2S8c//99wONU0wmQ7bPI7bZZhvAV2yLh4SM7YYNGwb4dWrMmDGe5186yNa6s/3223ueEtKGCLJG\nIXz55ZeA22dJPFxRvQuNWePJ9rpjI23IP//5TwDP0zGRYlli4Qe91xDZWneCmDhxIuD3P6msWQqP\nPPII4PeNicgF28RTLMuajkSBCAFVLCuKoiiKoiiKoiiKoiiKoijpp+Et1Uay2267AX5coauuuqrR\n55K4ZzvvvDOtW7cGfCVGWLE+M40oeOIplf/1r38BvprgxRdf9Hb8mgOiYJEsoPK/qLRnzZoF+Eqd\nGTNmeGooia8nNs4ndthhB26++WbAf/Zs1YUomDt06ACEpz7NdkSdJBl3JS6cqNzNnVFRtogS7PPP\nP2+ycmYSiTEo7LzzzhkqSfZw2mmnAf7ut2TmbdmyJeDHSbv44ou9z0hWeYkPJqofySTeBIrVtCJq\nrCOPPLJJrme33bmGeBHZKpNevXplrEzZwv777x9XqSzYakDFR/rxPn36APDkk096uTnWr18P+Mqn\nU089tekLmAZEqR4v9rYCAwcOBODWW28FoKSkxIvpL31VQ3GS165dm1QcylxG5qLnn38+bdu2BRpW\nwYlKecKECXz88ccA1NbWAr7dRW2Yb0jOiCOOOALwbSVjGJmLjxkzhhUrVjR9ATOEKLVFkSzzLLGL\nzYgRI9KqWM5W3nzzTU/N/dNPPwFw3333Ab637MEHHwz486nddtuN+fPnA/Doo48CvufJrrvuCvh9\nWD4iCmU7J0tzRNb4JGdLvDG/eIzMnDnT8xqQ3BHvv/8+4OcoE0V4riMeSCeddFLg+zK/zDSqWFYU\nRVEURVEURVEURVEURVFSIjTFsuwgNCYeimSEf/XVVwFfAbZq1ao0lS77iZclXmKcyk6fKFKaA+Xl\n5QCcddZZnipXdolvuOEGACZPngz4sZyC6t/f//730Mva1PTr1w+ABx54wMuAKuo4qTOy23XbbbcB\nfrzgqVOn5r1KxWTrrbcG4M477wR81aDE3H766acB+OijjwBXiSG2k0zpzQV5vpo7PXv25MorrwT8\nGNx22/LAAw8AvlLZjJs8Z84cIHZHecSIEUDuKZYly7fEP0vE0qVLAV+tcsghhwBunDDJHt4Q0obl\nqmJ5yZIlADz22GMAXHHFFYBfV0Sd0RxJpFZWpXLD7LfffoAf87RNmzbeezIGOPnkkwH45JNPmrh0\n2Y200TLnyGVE6SVjlAkTJvDKK68Ayc8TTjnlFK8+CdJu5zqiLDbbGxnf/Pe//wX8WJzCu+++C/jz\n2SBERZ9vYyWpB6I2/eKLLwB/XCzjn+HDh3vHSX6JfOeggw7yYr6Kml28h+24wpK75YgjjvDUt/nY\nDouKctttt/XWL6RufPbZZ1HHSl2SWMwffPCB11aJQn7Dhg0ASY8R8wG7DUnUpjQmtnK2U1hY6CnW\nDzvssMBjJAeAjJnNqAXiLSDxzoWZM2emvayZ4NJLLwX8NkWQfkpU/5lGFcuKoiiKoiiKoiiKoiiK\noihKSoSmWE4FUSSLCvX1118H8GIG27sP4GYezWck7uuMGTOiXhc1QnNSKguSEfzWW2/lxx9/BOAP\nf/gDAM8//3yDn5edsMao6LMV2QF/6aWXANhqq628HbwTTjgBgIULF0Z9Rna1JLby119/7WURfeON\nN8IvdAZp166dFwtP4oBJ7C7J4rxgwYKoz8yYMYPp06cD0KVLFyDWpvmKZLgWj4DmhngCzJw5k86d\nOwN+DG6J/S+qjMWLFzd4PvmsxH7PNSQm5fnnnx/3GIknfP311wMwZcoUwFcuS9922GGHefWqd+/e\n4RQ4yxAFitSD5sxbb70FBMfNlZi6b7/9dhOWKDeROPhByi6Juyw5KHJVKSc5Dey6UldX542RR40a\nBfjqHbl3ibMYhMTblf49l5F50y677JLyZ2WOdeGFF3reWVOnTgXg22+/TU8BswQZ/y9evNjzILnn\nnnsAvHlFMoidhg4dGnVe8VzKZTp06OApcOW+JAeJKEkF8SaaNGmSpza1x9D5xhlnnOHFcT3uuOMA\nP+brO++8E/iZSZMmebaSPB35RElJife32MJWKguiehc7nHHGGQwZMiTqmD//+c9A/rU/ibDXJvJp\nrSIZ/vznP8dVKstY8PjjjweiIxhIHy/zCWmbZZ7++OOPh1LepibePOm6664DYPny5U1ZnLjo7EZR\nFEVRFEVRFEVRFEVRFEVJidAUyxID2N6Zk9i3s2bN4m9/+xvgx0yRXS6b008/PeY1iYear8yaNQvw\nlW3NWeEkMYNvv/12AH744QcvTqcoWZLBjrOz7777pqmEmeO1114DfNXSQw89xLnnngtAdXV14Gck\nntwHH3wAwODBg724c/muWL7jjjvYdttto16TNspWWYjKSxRQ4MeWldio+c7333+f6SJkBNnxvvXW\nWwE3Q7WoB0SJKyqnZJTKgrTnuapEkLhuiTyG/vOf/wBujM9EvPjii7Rr1w6IjW2Zr8j3nquK9XQS\npFQWVcqf/vSnJi1LLiIx3xPZSlRfuR5DWOKYnnPOOYAfk/7KK6/02t8xY8YAvmJXYuoGITFAxVuy\nuXP22WcDriJK2iiJeZoviHpSxnWLFy/2YpA3BvGWtOPAyzOXy5x88slerOC+ffsCsUplQXK2bLvt\ntp6H24ABAxJ+Jlfp1KkT4H7nEns63rqFIHGEx44d67VJW2yxBQA///xzWEVtcqQtjUQingfEbrvt\nBvhjQhvxMjFV/jK+bq5eks0RaWOkHwKora0F/Bjvl112GRDbprRt29bzWrLnJZIfIB/WC8vLy712\nQyIWSJzpeM9XpghtYVmCTMuizOzZswGorKwE3MXBZDnwwANjXssWyXdYSBgQSTCWyPU435G6JHXn\niCOOSGlBGdxJhrhypfrZbEQ2bsQ9XyYB1113XdwFZRtZWI9EIl54iHxn6NCh3sRJXPTtxXRZeJb3\nwV8QytUFwXQhk6jCwkLA7/zzDRkky8AY/IVScdNPhZ49e6anYBlm7NixmS5CTiMLp+eddx4QnWit\nuZBoIVST9TWMTL7EjvYmxTvvvOOFdsj1BWVB7lHGxRL24ccff6Rly5aAv9An4cESIckzEyVlaw4c\nc8wxgL+Y4zgO48ePB/JvYVkSNUoi3c1F6pDw5ZdfRl0nl7n00ku9ReJkw1pMnDjRm6dKEi0Rj+UL\n0vZ+++23nvt5Q8jG18svv+zZR0IP5ktiTICysjLAbUNEmCELfmeddRbgL8zvvPPOgJ9U1pxXySZi\nc6J///6ZLkJGkXFfRUWF95qEKbLXvqS/HzlyJOCKvOKFf5K+TEJIyP8rVqxIV9GbjG222cYLuyR9\nzA477ABk3/00XxmsoiiKoiiKoiiKoiiKoiiK0ihCUyyLi4fsOjQGcacZMWIE4O5qSSiNr7/+ejNL\nmN1Ikp/27dtnuCSZR5LSiHuN7Homg+xkPf74415yAUmgkMvsuOOOgL/TK8HpkwldILvJoqJ0HMdT\nWzQn5BkTJAmbJBHt1auX956owF944YUmKl12IPct6pWjjjoK8BNDSoKffEEUJLvvvjvgP18vv/xy\n0gqVIMRt3UaSmOQKyXgaSTJMJRZJ7LN69WrAVyxLm3PRRRdlpmBNiIRdMtEkfQ0jiTNFZRqP7t27\np02VmS2IQrm8vDzmvSOOOAJITqkMbkIf8QRsrojaS8I2SMLV008/3VMq54PyNgwk4aPMR8STcvLk\nyYDftuci4lrdoUOHlBPwrVixwgtpIMrAfFMsy3Pz+uuve94TyfLuu+96c09RYT7xxBOAHyI0l5Fw\njCZdu3YFYlXIMvcylcoSqmblypVhFTHrkD5dPNjsOamEPMh39t5775jXWrduDcDhhx8O+B5JYjPT\nmzQeEmpPwulOnDgRyD6FbzJIqC+AJUuWAL7nerahimVFURRFURRFURRFURRFURQlJUJTLKcDiaVi\nIjsN2RasOt1ceOGFQPQuRXNF1FyiKH3iiSc4/vjjAZg7dy5ATEI2SQogO+dFRUWeij4f1e5ih2QQ\nezZ3Nfxvf/tbALbbbjsA9ttvPwBP2W4icbnff//9JipddiCKAlFUyP+yE5wvSAJHiQUnygFJdPm7\n3/2uUfGkJZbeiSeeGHjezfHoyQSSZC9RgiKJtTd48OCo1z/++GOgcYk08k35ZCNJOfKZRLGVRcmd\nCkHJ/yD/1M+/+c1vAF8tFy/psLTRF110UbOJHVxUVOTl4EiW5pwUSuYV4n1TVOROAUWl/NRTT2Wm\nYDnC6NGjPa8SGQvJ2PvBBx/MWLnShcyb5s+f78Xdbgymt18+IZ5sdiL4ZJg1a5bn+ScxqCVGairz\nt2xFctV06NDB82wUJW6fPn0CP/PTTz8BcNhhh/HFF18ADSdDzCdkjCz1wM7hYyY1zGek/xFPWIAj\njzwy6neQyj1Z5LnLZS8cSZwOUFDgaoLFI0B+y9jwH//4BwD//Oc/M+JBo4plRVEURVEURVEURVEU\nRVEUJSWyUrE8aNAgwI9lJavzdXV1XszPfOaoo47yYsHY7LnnnoBvE+F///ufF6Mo33j33XcBOOec\ncwAYOHCgFwtM6kphYSHgq5Flx0ZiWV177bVedl7ZJW0utGjRAoBLLrkE8JW6JhLrK9+5+eabueWW\nW6JeGzZsWMLPrFy5kjPPPDPMYikZQuIkSuw72Q2X+HnyurQdqdK5c+dQztvUSDyzZLKYH3rooVG/\nBfEyEtXAfffdR9++fZO6fiK1ay4i/bf8FsX8o48+CjROwZuPiCr5rbfeSvmzolyWjOO5isRwFZVb\nPMSbb/r06aGXKdN06dIFgFNOOSWuGi4e9957rxe3UcYCMsbMV0QRJ2NoyVuyYcMGwB0fK7HI2FnG\nf9dee60X5/uTTz4B/NjKuYyo4cTz88orr/TqRmOwY8XmOqaSEnzvq1TYsGGD195IWy5t9dChQwHy\nItfNzz//zJQpUwA45JBDgFjF8rx58wA/Pv53333XhCXMHiTPkY3UgyeffLIpi5MxZP1h9OjRntrd\nRsbK0i6JQv6ll17ylN2zZ88GYK+99gJ8D9SHHnoopJJnhu233x6AF198MfD9iy++GIAvvvjC81Ky\n45yHiSqWFUVRFEVRFEVRFEVRFEVRlJTISsWyxJ2RmKd1dXUA1NbWerHB8plffvnFu2dbmXzFFVcE\nfmblypVceeWVgKsEy0dkV8qMOzRw4EAAOnXqBMALL7wQ9RlRxFVUVHgq5nxkxIgRAF6cKvB3Q595\n5hkA+vXrB/g7ffvssw/gxkSVrOD5zl133eUpJ/fYY4+o93r37g346kFh1qxZfPTRR01TwCxDPAF+\n9atfZbgk4SDxu2zlrMSGa4xSUpgwYYJ3HuGf//znZp+3Kdl1110BPwaaKLAbg53FOV6sWJOpU6cC\n8M033zT6utmIxHm96667ol7P57j3ojq/+uqrY96zX5MxYLw4yslgq51zUbncp08fJk2aBMSOBeV/\nif9/0EEHNW3hMoi024livcejsLDQi1ctGeaPOeYYAJYtW5amEmYHolR+9dVXAV+RunLlSsBXTuZD\njNfG0L9/f4CYmOTyurRZorw0GTduHJAf3iWiyJZY/9KmpIqMoRsTBzWbeemll9JyHlE6y2+J2Sze\nXfmgWAY49dRTAf/+bAW7eK01V6WyIPN2G1GX5opH4+Yi84oePXrEtB0//PAD4LfRMh6aM2dOzHnk\ns/J7m222CafATUhFRQUA3bt3T/mzvXr18vLTyBxOPNbXr1+fngIGoIplRVEURVEURVEURVEURVEU\nJSWySrHcunVrwI+La/Pzzz97uxayEy87OmGuvjc1b775Jscddxzgq7pEySQZwm3at2/PTTfdBPjq\nO1stl48E7VqZSKzq8vJypk2b1hRFahIky6mojiV2lx0/GPzd4YMPPhjwFcsPP/ww4MYplPOIojJf\nqa6u9hRstmr0zjvvjPpfYpZLXMLmiCiWRYmSL0hs5Xh9zeZkeH/++ecBN26exGMUcs3j5sQTTwQ2\nT6m8ObRs2TIj1w0b07PE5OabbwbyO06uxD4OUiMHqZk3l81RPWcKiUk5depU79kTLzZBVIUnnXQS\n0HzUTelExj3S98u4Ox/o3r07r7/+OuArlcXzSmIw5vN4b6uttgJgyJAhgK8ONL9jUVLaKjmxkyiX\n5f333nvPU5fKuDofkLimUh8aUy/2228/b746ZsyY9BUuCxBFt+01kioSL/+aa64B/HlcPlFcXMxl\nl10G+IpRif8vazziLSqx7mfMmNHUxcwoMv+QsYndt99+++0NnkO8unLZY0Jil19//fUAbL311t57\n33//PeB7i8QbMydi1KhRQG7naOnQoQPgj1VMJIa0jKl79OgB+P37kCFDvGfu+OOPB+DSSy8FVLGs\nKIqiKIqiKIqiKIqiKIqiZBFZoVjeaaedALjtttsA2HLLLQOP69ChAwsWLIh6TbJJ2kpNiSEmux65\nhqje5LfsrMsOhc2ee+7JrFmzAH8X8I9//CPgqjSbK7LL4zhOztaFIG699VYA1qxZA/gxBwcMGMAH\nH3wAwH//+1/AzYIOsc+CxFV2HIcdd9wRyG8FSzxE2XLyySdHvS5qglWrVjV5mZRwkdiaEkNYkOcq\nGUpLSwEYNGgQAFdddRXgKwlMFdS6deuA3FEXiAry9NNPz2g5RHGwyy67AHjx0XMd8bSRNuboo4/O\nZHGaFFFrJaMkFiWGPDfyv/w2sWMq5zLdunUDYOedd45576effgL8mMrNUaks3lbTp0/n//7v/wDf\nHtK2P/3001GfEZWc5G4xkfjvog5fsmRJCKVuGkS19Nprr3n1SDwgJH9EPqltBVEBylhY4te3aNEC\niI2/aWK/JrFh5XVRy40ePTovbderVy9g88Yno0aNYv78+UD+etzYytLGMnv2bMD1ws43xo8f73mU\n/+tf/wL8vnn8+PGAP1aWvFDNTbEsCnipT9LOSH2oqqpq8BziOZErcwoTUSo/8sgjgO8Zu2HDBh56\n6CHAV9aKyj8eBQUFDBs2DHDXP0zef//9tJU5G1m0aBEAX3/9NQAbN24EMp+rpckXlsW1dbfddvMa\nH5nMy8AgFaSCym9BDP7II49w7bXXAm7yv1xFGp54i8Tvv/++l9ROXPfFhaC5NdrgJ+qRScbMmTP5\n9ttvM1iicJBGWH6nQps2bdJdnJxEEmmJPVavXg3A/fffn7EyZTuSXCLXsSeUiZLOyAaEJMG86KKL\ngNikYEETWOmDcgVJmpctSXhksSBfFpZlUy+fQnglS9CicDxkQmovLIPv3thQoj9ZyM4lDjvssJjX\nPvnkE8DfAG2OC8rChg0bvN+ysCyTUxFh1NTURH2mrKwMcPv3oqLoqY/MRcQVN5cXlh977DHAXWBe\nvnw54NeZfE3S3KlTJy/sh52I9/e//z3gJ0wTevbs6W1QNIT0/SeddJIXJkvqYD4gz0xjhCWyeXHS\nSSd5IUTyyTZhIEKefAr1JXPtSy65xHtN1nZkoVTCUcrC8nbbbQe4dhDxRXNGNsWTSSIrIX0k7EEu\ncOONNwJwwQUXAH6fLQvqhx9+uLcZkSzDhg2LmY++8MILgJ/oL9+Q9nrPPfcE/OS8EirXTpQO/kK9\nrI2GiYbCUBRFURRFURRFURRFURRFUVKi0YrlbbaBI4+EoUNh112hUyeoqoKFC+HVV+H228Hc9Bcl\ngIR2CFpRTyddu3YF4PLLL+fZZ58FYN68eaFe0+SUU6Be5R+XdeugESLtQPr168fZZ58N+K6S2a5U\nPvFEOP102G03qKiAxYth5ky48UbYXHHxn//8Z8Df2XnqqadySrEepm2EpUuXpudEGSAd9jnwwAMB\nP3GJqDMlcUIuKsJatoQDDoA994QBA9zfEllop52gEfkPopDnSRIC5CInngjnnLOMPn2qKSioALrg\nOAfhOBd5CQ5E7SZ14LjjjqNLly6Ar9CR+vLjjz8CfniD7bffHnDdaeW9RxrqDLIAs0+HbYGlQAnQ\nAxgOnA90yUjZbLVZUxPWcyXPkyQFEq+t3XbbLSfV2dttB+edB8OHu/WpthZ++glmz4ZHH4V33/WP\nFaV/MqErJKlfKsn9RKmc6cQtjak7Y8eOBaJdr9+tN54dDi7X6d8fjjjCtcsOO0CHDlBWBitWwNy5\n8PDDUC9ASki88Z2oAsXDxFYrg+9um21h41KZZ40ePRqAgQMHAq5qdOTIkUB+KpVN2+y330Zat94T\nKKGysivr1u3LkUe+zfLlRTHPi3i3TpgwIe65xftTXKslNMbkyZO9caO0L5JQPlvp1AkuuwxGjoSu\nXWH1avjgA7jtNvj7391jZCy+6qH9AAAgAElEQVQjoSxSYfLkyYDbPskcNFdIxjZhIGF7SkpKwrvI\nZhKJuOsYJ53ktj1t28L69W5/NWMG3HGHu4YhiFK5rKzMC8f45ptvRp1TwjO+9NJLgB/OYezYsYGJ\n57ORzR0LXnXVVXGThos95HeueoYG1Z0NGyKUlT3Ohg3DKCzcALTis88+A/w5uIR0SISEspL+/OCD\nD/bek3Cwkjxy4cKFabundJPsWFnCnS5YsMALGyzttYSSkfoUFPVBbCHPV1OsgzVqYXnrrd3FGzNB\n6urV7gLPrru6P2edBUcdBSl4PeYlVVVQH+45hmboBQtAURE88wzUh8+kuhrWrnUftN/9zm2MjjgC\n8iBUYsqobRKj9knM0KFQv3enWETXnUrcNYQWRCLfEolMwXEep7T0QSorf53ZgmaA2D79B6A1sJ5I\nZB4wD8d5AJgGHBB8kjxGn6uGOe00uOsuqA9pyrp1UFwMvXu7P3V10QvLzQWtO4k580y37xbWrnXr\nSteu7s8RR8C0aXDCCWBFt8hrdJ4Vn1jbrMFx3P6qrOwLysq+YMaMAs4/vyt5tg+TEjvv7C6QysLX\n6tXu34cdBoceCuPHu2KM5ojaJj7l5fDiiyIycFm9Glq3hr33dn9++1sYMgS++SZz5cwE2p8nJqju\nrFkToVUrh4KCTygt/QTHeYa6ulmZK2SGyfexcqMWluvDovDSS64q98034ZdfXMMMHQp33w09ergP\nX69esHSpH/c3FaWy7J6OGTOmwWMlVs+xxx4b9frIkSM55phjgKZVLAvvv+/ubgXRunVrWreG/v37\nA35cHdnFSQYJAn/nnXd6SozvvvtuM0ocPjfe6C7uVFfDRRfBlCmwcaM7iZg8GY49Fp57zn3AUg11\nJ0pKURgIEn8t2wnTNjYNBcXPRtJpnwsvvBCA8vJywE84cmOOjyaXLnWVXh9+CIsWQb34Ji3ITmkq\nbVS2YNadq64q49FHS/n739+nqGgJPXrcTUHBNLbccix1df/14pYlijEsqqYrrrgC8OOEyY6w4zie\nijnbk7TYffq0aSuBdkAljvMm8HsikW9wnNHAAqBzKOUQZbckoZDkG89nwUg+jOdK4rtLbDRJujFt\n2jR+/etf1183+z1LjjsOHnzQXei580649VZ/wtmxIwwbBrY4S+IlH3DAAZ4SOZmEfg2RLUplk4bq\nzh/+8AfAj0lZYKwmPv7444CfjDnfmD0bFixwJ1JffukLLrbe2lX0XHwxHH00LFhQyrPP9gbg888/\nB9zYneKd2KFDh6jznnjiiYCfwHnvvfeOWwZpZySOdTaQ6jxLVO7SZ91zzz3MnTs3pWtuu+22XrJi\nSVLXsWNHAM+bR+YrN998M+CrEJuSoP7KcdoAVVx77f6MHfspnTtv4I47fqBVq6NYvbrc66clvi34\n8Salv3/yyScDr/fb3/4WgDvuuMNTE0pbNWLECCD7El+XlbnK0i23hI8+gjFj4PPPXS/Zq66CCy+E\nG25w35P2xn6GghCPrVdeeQWAiooKAMaNG8eKFStCupv0koptZs3yky+LncaNG+fFC06WoqIirw6K\n0lAUqakkjW4KrrzSbWPq6uDyy+Gee2DNGrftOfJIuPde6N7d7fNPPtn1Yjv11FMB1wvruuuuA2Bl\nHFWdrHWIx9Y+++yTM4plSNyfi5eIeDLYnq/Dhw/34lFLfRLPpFTiTIvtsg2z7lxxRYR774UpU54i\nEqnhyCMdIpFziUS+IxI5i0mTtgGClcoyLz/jjDMAf54lazxiuzfffNPr56ZMmQLADz/8EOIdbh6p\njpXlGTr22GNj1jAlRnW7du2iXhel9vDhw72/05V4NBkatbC8ahXsvjvY67TV1fDaazBiBHz8MbRp\nA2PHQo7lLVJCpEMHOPdc9+/Jk11XPmHRIleV0q8f9OkDV1wB9Xk3mgVqm8SofRrmxRej3Ybr5wDN\nHrvu3HdfmfdeTU1nHOdvOM5nRCLziUQmAndlpqAZIrZPl4FKCXAI8DKOsweRyBoc534g+ZAE+YA+\nV/Hp0MGdeBYUuG7F9WvlHsuWwd/+lpmyZQNadxLz178Gv/7jj3DJJdCli7vwc9JJVdRHtWsWpDrP\nak4E91d1QAkffdSJa69twS23vEWbNjBkyFdMn75L5gqbIcaOdRf/1q51Vbj1ERJZu9YVZWy/PYwe\nDddfn9FiZoRUbDOrGQor6/fkePjh6P68uhqeespdmH/kEVex3KZNHatXN590XdqfJ8asOzfe6C9+\nO04RjnMksIlI5AwKCt6mRYtj2bChNDMFzQDNZazcqIXlNWtiBzsmX3wBc+a4St36zW1PcZRMBktR\nI0gcomQyNEs8QlEdCt27d/d23rMNiQMsam7ZmVi4cKGnoHjvvfcCPytZrGXns6SkxLOBKLSzkSFD\noLS+HQnapK2rc2M33Xefu1B4wQWpuT8OGTIEgNL6i3z//fdAajuBmSJs29jsu+++gLvzaSqkspV0\n2UcUN3vssUfU6xJzT9SSuUgTbkrmFHbd+eWXXwA/TteIESPo02dXBg+ej+M8zk8/XQgUe+qvL7/8\n0lPoxFOXiFLBVBK88847YdxO2rH7dPH8eeqpp+pf2QkYCLwNfNSoa3xTvy0vGZvvv/9+li9fHnWM\nfC9NubueDGEV54s4Afm6detGWVlZ4HvZxtlnQ/v2ruq0Mc4eb7/9tqdeFhWg/B48eDDgP0f2//J5\n83e2kUzdkXbGrvd1dXVZpbxuanr16sX3368CltGtW4mnApN405s2bfLiDm677bYpn1/Ghffff396\nCpxGUp1n2Z6KRx99tOchmsjzBvw+q0+fPp7CTuYjolDt2bMnAH+vDz6byRwUtm1+/PFHLwfCc889\nB8CqVbtTXv4po0dvy6hRj3o2+PTTTwG47bbbvHnWl19+mfB64p309ddfe33iFltsAcD19SuzMp7O\nFk46yf39+OP+wqnJzTe7i6f9+8PXX79EVVUPHn30UcBtf+3Y1PKcSdsr9y9tdbYpthORim169fK/\n/8MOOwxw45gH9UVByHzjsMMO44ILLgDwfj/44IObfS9h0KmT+zteagszrHjHji2BYs+zwXEcvvrq\nq8DPScxyiakr3n1PPPHE5he6iWioP5f40fG4/PLLPQ81+S1tk8TJF0/HRDTUpmcKs+50794dgCOP\nPNJ733H8efe++/Znw4Z2ngp511139d475JBDALx2XfooWR+UeO651O5szlj5s88+87ywZJ1LIhbI\nOpd46z322GOAnyuoqQltNUk8f8VlSVHA39375RfXnSQIGc+0bw/W2l9eo7ZJjNpHaSzJ1J1ffnHD\nOxQWrqakpOnde7OfLep/504SVCV8ZJL+179Cls51lBxmt93cjd7Kyq0yXJLsQ+dZ8amqkkRGza+/\natnSF3XNnBl8zJw57ngIoKLiX01TsCwgVdvUr+E0KyQBuhVR0kPst2QJLFvWKH2ikqc0VHciEVeY\nUlfXkQ0b2jZNobKE5jJWDqVFKCyE+vCASPiteLF2TP5a7xN3+eWXA8kplRviW6nlGaJvX9cGPXq4\n6snvvnNda+64w48zJEh8xfbt23s7exJ7ryGmTp3qxeDL5nie8jAlEsiaSbv79nWz9CaLxOUR5PuX\nzJrZTNi2sZFYc47jZJ1CMIh02KdVq1Y8/fTTAGxZn7VDMsnGUw8qPqLOaIrMsukkXt0RdcFLL73E\n0KFuoiiAyy47gocfTu7cAwcOBHzVhSgJvvjiC6+u5RoSP1AUFFdccSm77PJ2feyvvgk/K3Er/2b5\ndInq53//+196C5sHiDpMVIEAN910EwDHHXdcRsqUDO3bgxT5n/901ZOXXAJ77eV6CHz7rRvLctIk\nfxEsEdmuPk43nTp1ZN26Ys4666yo1yVm4Nlnn+2pUZoTFRXumPmqq1Zx6KGux2Fp6f9570tm+MZQ\nU1PjeU1I+5xqvNRswJ5nTZ16J+CrAbt16+YpxpJVLDuO4ynEpG/817/cRUdphyR+pcRizgYuv/xy\nzj//fAC22WYboIaOHV0V8oIFRcyb94wXz1a8ZxvjyfrWW28xfPhwwPUSbex5wqZ3b3+sEy8dhuO4\nqve994ZXXpnEZZfdzwf1A+Z3333XU35L3RhVnzFb2qO+fd1xQK7EVRZStU2fPv7r48ePB9xn45ln\nngHw1LliJ/GqEI9Iyfczd+5cL29CtucoeeABuOUWN8nYV1+5MZUlxvLo0a7XX12dG4v6xx/d8d7M\n+lX64cOHM2nSJMBXZJ9wwgkADK3P6NamTRsAz2MtV8fJjeGtt95KKddYrmHWnW+//Z4HHihi9uzZ\nRCLV/OpXS4hE/g/HiQA3c/rpJyV93qlTpwK+x6h46OcKmztWdhzHywEgv+1xY7YQimL53HPduGi1\ntfHjpzUXOnRwO7ING9y4RP36wbhxboe2886fZrp4TY5467Vu7SZnCcLsyLdqRiIVtU1i1D5KY9G6\ns3l07PgMJSU/4zgFwG8yXRwlSzDyYHHQQfDGG3Dwwb6Csk8fuPRS+M9/oN6TWlEC6drVXdBxHDdL\n+rx5cPTRy9i0KUJd3TXA2ZkuYlah86z4lJf/haKiFThOAd9+2/hNiFylfm8ACA71YL/XqVP2C0vS\nRaq2MY9vLtx2G9x1l7sAf8MNsHq1G9d840Y3xvKCBXD44fkRD1ZJL2bdmTChhiVLNjFw4CEMGnQg\nBQUnAr2oq5uO4yS/qJwPNKexctoVyzvvDBMnun/fdZebaRX8LIWyWzxq1ChPuSSxTSX7dS6oJxvi\np5/c7LLPPuvu+FVXu5kehw514zf17QujRz/PPfe8yJZbuomiJKtqx44dGTRoEOBmvQY/PqVkyJQs\nmrKrPHHixKzcObd56y2orHR3aC65xM36bVJc7MbGFVq1IiWOPvroqP+Dso1mK2HbxuaNN94AslsR\nZ5IO+5x55pkxKp5x48YBuR1bOSz6mKutwIwZM4Dca6PDfLZchVSst8S9996b1d4jiZBn44UXXmDn\nnaE+nCJTphQzfvxgL0ageCLdfffdMZ/NVHyvXOSIeqm85IjYaaedvBiW2Uxbw5Nx/Hh3w/yMM9xs\n6ZGIO3B+5BF3M+fZZ2GXXdyFMMVl6dJlLFrkZzOfPHky4HvTtGjRgurq6oyVrymprXVdqwHatXPb\n6upquOeeNvTr14uamtc8tWhjEMXThAkTcmpcGETwPMt1D+3VqxcA5513npeDRZA4zLZCW8Y+99xz\nj/eatO250I7/9a9/9drO/v2Lefllt+z331/E2WdflNZrffRR43IMNCUVFf7fiYa1Gza4v4uLq1i+\nfLnn9Xrdddd58TtlDCNzTalTuaZUFlK1TcuW/mv/rXfBHjlypJcj6dBDDwV8xbKMB0VVKHP2RYsW\n5cQcHVw18gUXwMKFbizY4uLovr5VK1c0B36c+oceeghwFcsjRowA8H7bfPLJJwBccsklId1BdiNK\nbomZ27mzG4Yvk3Hr00VQ3Skq8nNcrV69iNatVwSGgvjwww+57rrrgFhVf6ajD2wuzWmsnFbFcufO\n8PzzbsM9d647gW+uzJoFEya4Az6ZF1RVwauvwqBB7mJzURFMnJijNaeRLF/uJlcDOOccuO46V6lS\nVAS77QavvOK6QNavpzerZGRqm8SofZTGonWncdh9+jXXtMh0kZQswgwtU1vrusl++KH7v+PAa6/B\n6ae7//fp476vKEEsWeKqA7t0gfJy1230ueda8sc//sK++55Hy5bfNXySZoDOs+LTqVMdjzzyCy1a\nwMcfF3L11bmRADXdGPmDFQu1TcN06gTvvQeTJ7uq5F12cdubHXZwVZU9esDDD/ubW4oiBNWdHj06\nMnDgFvznP8fTsuUyCgrOJBIZn+miNinNaqzsOE7SP4AT76ddO5x589xDv/gCp2PH+Mdmy08q9745\ntgn6OfVU96O1tThbbpl5W4RpG9s+JSU4L7wQ//A778SZP9/9++KLUyt3XV1d1M9ZZ53lnHXWWVlt\nn6ayjf1zww03ODfccINTW1vrnHbaac5pp52WdbZJt30WLlzo1NbWRv2MHDnSGTlyZE4+Ww1dq1s3\n//BevZrm/rLVNul+trbaaitnq622cubNm+fMmzfPqampcWpqapwffvjB+eGHH5zy8vJ022duU9ad\nXOvT9blq+rqz777+y9Onx7/+ggXuMffdl3E7ZFXdeeaZCc6DDz7ofPrpp86nn37qXHbZZc5ll13m\n9O/f3+nfv3/G7RJm3Un2Z9Ik96Mff4zzxz9e4IwbN86ZOXOmM3PmTKe6utq5/vrrA3/69evn9OvX\nz2nXrp3Trl07p6CgwCkoKMjpupNrbXJT1p0ctE1odefww/23WraMf/3nnnOPmTYt87YI0zamffLB\nNmHWHcCZOdN964EHgq998snu+zU1OH37Rr83evRoZ+XKlc7KlSu9OdacOXOcOXPmOBdffLFz8cUX\nO506dXI6deqUE7ZpqN3JwbFg1tadbPgJyzZ5MlZOqj9Py8PVujXOBx+4h337Lc4222T85jNagZL5\n6d3b//iAAZm3RZi2iWefo492H7Avv8T53/9wXn4ZZ9QonMJCnPXr3Y+OHp1auR977DHnsccecxYt\nWuQsWrTIqaiocCoqKrLaPk1lG/tHFpbnz5+f1o4+m+vO2WefHbOw3KVLF6dLly45+Ww1dK1cG/Q0\nhW2a4tkK6afJJum52Kfrc9X0dWf77f2Xb7gh/vVlQ+fllzNuB607WVJ3kv0x7bXHHhm3RcbqTi62\nyU1Vd3LUNqHVnQED/Ld69ox//Tlz3GPuvDPztgjTNqZ98sE2YdYdc22iT5/411++3D3mkksyb4um\nqjtBPznYn2vdyYBt8mSsnFR/vtkxllu0cN2I99wTFi+GAw+E+qTBSgJMdxy3/jU/pk1zf2z23NOt\nVwBz5jRtmbIFtU1i1D5KY9G6kxjt05VkWbjQjUXZokVy45jmOtZRGs+iRf7f228PORDiNu1omxwf\ntU0sCxa44bwKCtx8Pl9+GXtMJAL14bi9XEjNAbVNYnr39v+uT+0UyMKFsOWWUJ+yRlG07iSgOY2V\nNyvGclkZvPgi/PrXsGKF26HneE6MJmOvvfy/v9PQcVGcdpr7+6233IFiKowZM4YxY8bQtWtXunbt\nyvr161m/fn36C5khNsc2NpdeeimXXnopvXv3ZunSpSxdunTzC5hhGrLPvffeS2FhYdTP4sWL8yJp\ngrJ5pPPZylW0T1dSwXHg7bfdvxNlspZJuo51lFTZbjv/73Xr4h+Xr2ibHB+1TTDr1rnxtwGGDQs+\nZu+9/YRSb77ZNOXKBtQ2iTHzi2y7bfzjunVzf+dIPkKlCdC6E59mNVZurKy7uBjnlVfct1auxNl9\n94xLtLNG8t7QT6tWfhyVOXMyb4ewbZOKfQYOxKmqcj82bFjm7ZBNdac52kbts3m2yTU3rUy1yTlS\nd0J1K871Pl2fq8zUneOPd1+uqnLd/exrjxjhf/TQQzNuB607WVR3Cgoavv6UKX79ats247Zo0rqT\n621ymHUnD2wTat05/3z3rdWrcTp3jr32tGnu+x9+mHk7hG0b2z65bpsw60737v5bkyYFX3vkSP+Y\no47KvC2asu7YPznYn2vdyYBtIC/GyuHFWC4owHnmGb9h3nvvjN9sVlWgbt1wZs/GOf306FhfxcU4\nBx/sJ5ioqcE54IDM2yFs29j22X9/nAsuwNluO39i0bYtzu9/79Ynx8nawOWh1x21jdqnsbaRny22\n8H92280/fO+9o9+LRDJvi6a0TR7UnVAXeHK9T9fnKjN1JxJxJ+CO445tJGdEJOKOdxYvdt/L1k10\nrTuZqzvduuHMnYtz2mk4XbtG16ldd8WZOtX/6C23ZNwOTVp38qFNDqvu5IltQm13yspwvvnGfXvu\nXDf+KbgJ62680f9otm6kp9M2tn1y3TZh153XXnPfqqnBmTgRp0MH9/WKCpxTTsFZscJ9f+FCd10j\n07ZoyroDOd+fa93JkG3yYKwc3sKymd1wwwbXGPF+Pvgg44Zo8gpk7mCJjZYvx6ms9F9bt87Njplp\nGzSFbWz7nHKK/1ZVlas2qK31X5syJTklS77YR22j9kmHbfzzJ/fTrVvmbdGUtsmDuhPaAk8+9On6\nXGWm7oC7KPj11/4hq1e7Yxz5f/58nK23zrgNtO5kWd0JGisvW4azcWP063/5i5tcNQts0WR1Jx/a\n5LDqTp7YJvR2Z5dd/ERZjoPzyy/ugo/juGOfbEyeFYZtguyTy7YJu+507ozz2WfRh4n4Qn4WL3YX\nVTNth0zUnWQ/mqX9udadDNkGcn6sHEryvhXAd61b0wroCVBe7v7Eo7aWKuDTFK/TFHRL8/lWAN8B\nrFhB5PLL6TBoEC379KG8XTuK27alYONG6r78ksp332XNbbex/KuvqEpzGdJFum0Dhn3mzqX0L3+h\n48CBtOzShZKKCgqXLqV67lzWTZnCipdeItsj74RWd9Q2gah94uPZxqB/Mh8sLeVTyKo2KFTbaN2J\nwbNPHvTp+lwlJlT7LFoEe+xBwdVX03nkSNpusw2ljgOff86mGTNYdf31LFuzhroE58skWncSE5p9\nliwhcuaZtB0yhNa7705Fhw4Ut2tHYWUlztdfU/Xvf7PuoYdYMWsW2ZooQ9vkxIRiH7VNIDHtzrx5\nsMceFF1zDV0OPJA2HTtSsno1tZ98wvrbbmPpjBlZO+YJdR4BOW0bCLnuLFkCe+1FZNw4Ohx+OO12\n3JHyli0pXLuW2u+/p3LWLFbfdBPLFi+mJs3lSAeh1x20PzfRuhOfmDa5OYyVI/Wr6oqiKIqiKIqi\nKIqiKIqiKIqSFAWZLoCiKIqiKIqiKIqiKIqiKIqSW+jCsqIoiqIoiqIoiqIoiqIoipISurCsKIqi\nKIqiKIqiKIqiKIqipIQuLCuKoiiKoiiKoiiKoiiKoigpoQvLiqIoiqIoiqIoiqIoiqIoSkrowrKi\nKIqiKIqiKIqiKIqiKIqSErqwrCiKoiiKoiiKoiiKoiiKoqSELiwriqIoiqIoiqIoiqIoiqIoKaEL\ny4qiKIqiKIqiKIqiKIqiKEpK6MKyoiiKoiiKoiiKoiiKoiiKkhK6sKwoiqIoiqIoiqIoiqIoiqKk\nhC4sK4qiKIqiKIqiKIqiKIqiKCmhC8uKoiiKoiiKoiiKoiiKoihKShSlcnAkEnEKCgqIRCJRr9fV\n1SXzWQAcx/Fek78LCgqi/o/3etB5GvrffM18r66uDsdxom9kMxDbmNeNd33bXkFltt9Lsgxxz2O+\nbp4zyG71P2mzTf35nUgkkvD7scsk338y9cs+Vv6vra2N+j/oOvb/5vcVZLMw6k68MsYra8A54h4b\nz75B9xb0rAQdW1BQ4NnW/Gy6bVN/rahnK9Gz3Zi2KN7/Jg3ZNNHxYdcds00Ouq7YJJkyN/QsCuY5\n4/UH8eqz1BP7Oulud8Q2dnnM+2zoe01k13j1R65XWFgYc4z9XQSdI14ZamtrVziO0yF5CyRG2uRk\n+wX7mATnjfrM5pCMfeT1MJ+rRGWz+x67TaqtrY07xrGPNWnoM0HnkDbZvHY9aa875vOdaOwS7xlL\n9JmG2pC6urqE/WUqZQqj7oD7/JvXNNu8htoD+ay0i+Z78cZFQc9IUNsX9BkTs/2CcNqdhspgE68t\nMdsv+3zx2qyg9r8xZZBrp7vuRCKRwO8r0RzHLpe8bx9rj4uDxk/xxgBC0Fg7wZwj1HYnmXInGtPa\nz5v92aBzxbN/Ms+WPRasq6tLe58VVOZ4JBqfJDvGNe0brw9MNCdtivl5/fmdeH1Gsm2IeX/xxsbJ\nPqdB5403lrD/bqp5RGPGcInGsMnUj3j2s9tEc2xvXqep605D5TbLZh8bcJ0Gz9VQO9cQYdSdeG1d\nvOfHPCaJ8wOJn9GGjgl6vppiHhFv7SLouW5oXTCV+bn5ekP1MmC8F3e8mGx/ntLCckFBAWVlZd5F\nN23aBECLFi2oqqqKKkhpaWnU/0GDk40bN3qflxuCWAPLDVdVVVFSUhJ1PilLdXU1AMXFxQDU1NQA\n0Z2dvFZSUkJlZWUqt94ghYWFtGzZ0iuHfInmFy7vyWty3xs2bIj6TCQSiTmPfd+m7eV1uXf5LuQ6\ncq9iBznOcZyYjqykpIS1a9dujikCKSgooEWLFt615XrV1dXea2IH+V/uXb4305ZSV8rKyrzzgH/v\ncg6ph9XV1bRq1Srqs1IG+8ELqjvyW86fTgoKCigvL/fuRb5bx3G8713KZD9P8t3KfZqNgvyW+5Jj\ni4rcx96sB/Yxcl3BtvemTZtinvXq6mrvmU4nkUiE0tLSwAbYnigJco9BjardyYi9pZ0RuwimTc0J\nv/lbbCB12HxNbFpQUOBdK11EIhGKi4tp3749AGvWrAHc+5fnuLy83DsWYp8vsV1RUZFXz+zfcozd\nrpeXl3vfuRwj1xM723W0sLAw6prympQ9Xdj9lfnsms+LWVZpT9etWxf1uhxvfkZek/PbtgL//uzP\nxquv5jXt99auXftd4jtOjUgkQlFRUcxgpa6uLqrPBWLabXswUlxcHPOe3Q7ZtjYn8/E2BO1jgwar\ntbW1MfbcXKQ/l7os/YvjON7f8lvqQUVFBUBM/1lcXBwz3rA/a38Hbdu29c5j1wc5l9Q36deKioqi\n2hrwn8XFixente6Aa4s2bdoAfhtaUFDglcseb8g9y/ty78XFxd5r8j3L+aQfku/XrG/S1sq9yrHy\n7Npjp7q6upj2q6amJu19uvTn0i4G3ac9yJf7k7KaY0F7/CM2sPta01bxxlBSH+R/OW79+vXe9yNt\noNGup73dKS0t9eqqXVaIXYCQe7brSUFBgXceeyHftq05N7DrgT1/CJqL2IshYfTnhYWFtGnThlWr\nVkWVp7y8POZ+pBxSf+X7l3upra2N6efs58luh0zsOmOPJ8wxvGDbEwil7kgZ1q9fD7h2k37Snv/Y\nY1uxaVlZmVfH7TFfUBCA4NYAACAASURBVD2Tc8lrZp9g/i+fNedmQf29OVZMBwUFBVRUVMSM6+rq\n6mLG82YdkfJA9DNoL7YL9njZXJCwj5H5QqLFE3vOXl1dHdo8q0WLFjH1obCw0LsHe04o9aN169aA\nX7cKCwtj2ijzOTBfl3OZYzw5jz0ml3PKsUVFRd53J59Jd5sj5SgtLY0Z7xUVFSUUZ5llTrSRa6+H\niF3l3hIJFu1xRNC4z3z20yFoCLqP0tJSrwzmPFm+d7sO2ceac9J481b72TXbHXseZY+Z5fkRzM13\neQ7BHx+lCxnvSN2Ra1VVVQW2DeB/7/Z4tbi4OKZdtfusIFGSXFPOZ9c3+7mqqqoKHFuE0e4UFxfH\n1IWgMa/9rNi2Medldh2w5+vmONmuf3Z9sfv52tramLGGMeZMqj/XUBiKoiiKoiiKoiiKoiiKoihK\nSqSkWBa1n6zq27v+EK0OMbF3UwoKCmJUhfHcH001rVxbVtdt1XNQ2eLtfKSTuro6Nm7c6KmWZIV/\nzZo1MTvngn3fpnLX3D0AYpQu9g5wdXV1zO6FXFdsIbYx1Rmya24qs8LY8ZNdezm3uTNq71AJ9o5l\nIrcZsbfsXNmqnpKSElavXh11Hnun3FajmrvF5o5XGDvG4O9Em8p6Kb+9622rVIIUfbbaT2yTyIXP\ntrXUP3snr6amxqsz8p6tzgwLs22J5+5o7yJLPa+oqIhpZ2xlm60IKigoiKmj9o5okALBVkGZ76eT\nIBc22WE370vKI/XAVvytWrXKa0ftHdaOHTsC/m63fGbNmjUxCiY5h6iuTKWyXN9W4K9duzaUdtks\nq634M69vK/tspVJlZWXMjq8gz6itZDJVSbbqxFSEQLSizLaNrYRJJ0H10bSP6dVgHm/vmNfW1ib0\nNDL/D2pL5Xy2/U1vCIgOwWO2icmEwEkFx3GoqakJdMe021x5z/5OpZ6sW7fOe0YEuW9RG0vfJJ9Z\ntmyZN5Yw2y7wny85R5BbndgxDO8juU5JSUng+EHKYI/v7PbIVKgJtppZPvvuu+8C8M477wBw5ZVX\nxnWVFRW13RcUFRV5fydSWaWDwsJCzyZih40bN3ptr93H2MpSOc5UqQi2isR+hisqKmLGWfYzaKvf\nKisrvTLYisQwqK2t9exito3xwjbZz7zZ79pum7aKTTDHinbdsMc79njbfC+em2g6cByHTZs2eW2J\nqS6yx/X2uMWe+1RXV8edj9n3bY6XTaUt+PXBVi7Lcaa7rf2dplsdF4m4IRqkTKbSM+g7M7FVu5WV\nld5nzOcNYttwUwVtz0HlHqUs0k6bqkZ7vBjGWEf6LLNPNl83r28/G/bzUFpa6o1rbK+dROpA255S\nBtvD1hyDB3kUhzHmcRwnqo0x+wCzjzAJ8kQUbIWmrfq251+VlZUxnkR2exPUptt9VllZWWhzUHut\nwLSH3e/Y4x/z9Xghuew2yuzD7fPZz4zcs5SppqYmZsxdWFgYs9aUTmxvrI0bN3rlsdtYuy0RgjwY\nBFu5bqpX7TGk7TVrf7a0tDTGM6Gmpibt/ZY9VpZ2wfSEFruZYyGzzKaHgN2/2XNr+/ktKSnx6oY9\nTrD7UXOuZiugy8rKQml3TM93uX/TUz/enNNud815jt0myLmuueYaADp16gTAxIkT+f7776PKE6+t\nMb8j+5lOFVUsK4qiKIqiKIqiKIqiKIqiKCmRavI+CgoKvNVxM36KvVtiq+Ts3SjzNVvVFU+da6oc\nJLaW7A7b8ezMeFf2zlcYuzZ2jCIz7p8d08TeIbB3bM0dDlthIju+cp9y36ZqwFb9iK1kZ9VURtsq\nVnP3J51ILC17J8lMcBVPUR4U081W+tm7nLbqpra2NiYesx3nx1Y0mCoI8/xhqZxsRaUZN87c9YbY\nWImmmsCOJWfvbtm7Z0EKD7v+yXNmqjXsmLINJTfYHMzYdqYay96RtJUztjq9qqoqatcQYmPlBrVZ\ntqIlXvxvUy1i28es6+lCnitRPJq7m3bbIcSLR15eXh5zf7aKzX7ezF1024vEfp6l7aqsrIw5pqKi\nIu3qJohWMJj13P7ebMWK3WeY7avdt4n9guI12kpcW8ljn6OysjKmroURt1wIimtqvm6rQuPFOg1K\npmbG3YXYdqKmpiZG1Wqry+28BNXV1THqzrBi6hUXF3v3YMbYl+/H7j+krFKP5Xkw48+JQtmOkS/n\nNOuJHCOfCYpLCMExd6U+haUcBNcmch1bTRSEXU6zjtnqFLn3/fbbD4CePXsCsPfee3u/DzjgACD2\neRTs/s+MlW8+52EonBzH8eqpKDxbtmwZEx/bLqM9RqlPtOOdE2LbFFupa96nIOezY4VKvW7Tpo1X\nNjuGfFjYHhmmt4Y9/rBVmGb5bS8uWwUVpLC0z2OPs+x6UllZGVdRl07Ew9JWdpo5VGwVoO01YNYL\nez4iBHnkyP8yXwgaq4NbjyG6PbLVV2GNBaVdtuNDVlRUxMxb7P5a7GR6UNntTkOqQ7OvsWNXxlPn\nVVdXB3pDprv+iDeNrQo1x8nxchfIM2L21XY/YyvYgxIexlP8xvvf9JA1VdNh9un2GsWGDRtiymXH\nN7XHweacwH4e43k2mHGZ7Xu2n0fTc8VWKZqev+lC1naCYv3bbbD9nNkeieZ8w64PcoypOgbXHva8\n1R5j2p6WZtxg0+ZhtMsQPcY1v694fbndZpieNLbHiGC316b62K5f9lzXbu+qqqpi8t6YKuJ0IXXE\n9nKVOmXej92n2Gs9pnI9XuxywXxWbKW9PX8RzHG2/ZnKysrQnivBbFNttbH5GYhVI5u2suvc448/\nDsD+++8P+Os15eXlnHjiiVHH2mN2Odac6wStDUDy84hG+a4HuR/YX4jtHhzUkNqBxWXQ27t3bwCm\nT58e9ZkXX3yR3/3ud0D0QpF5HTG4aRg7gHiLFi1CcdEyFx8SNXRmRQZ/4mh2ZvaDaHdegrw/fPhw\nLrroIgB23HFHwK8w99xzDwBXX3014C80ByUbDBPHiU1GZw4ibPdnqUP2BKq4uDjGHnanJg+COeG1\nH1S7EbInVNXV1YENYljuEnZnYgaTl4mGvTAVFJDdHuDabsX2YlFdXZ13PqmLdoIqOb88oxs2bIjp\nAMJKnCCuNvYA3kzMJkjdtpMgmW7qdsdv36Nd/8wNI9vNOyg8CwRnVjUnMulC6o1dLoh197YXmYJc\naO3JvkwiH3nkEQDGjx8PwHffuTH8TddZu0MMmoyBa4e2bdtGlSWMwbK4OAZNyO0kYeI+L/XH/p7M\nBSh7o8be7DGfsyB3SIhdHDIXV+zFTHvAmk7q6upiBmHm4NOuQ3b/Y74v93TMMccAMHDgQACOPfZY\nIHiSIff2888/AzBu3DgAXnjhBSA2wYQZvinshS9zomUOyuzwRFL/5R7shHbg348sjA4aNAiAH3/8\nEYhOeCLXlvpk36890DQnO3a9lfocBubmlbn4GS90g51kzXze7XZ6n332AeCZZ56JOpfYYo899ohx\n2bfbM3uR0nSxDgqnlE4cx4lJyrxq1aqYgbo95rAXOmtqamIm2nayFdlUlHpXW1sbs+gl7bgkSJXv\nwNwYFPvFm/SlC1ngsRfzTDdYKYvdn9ubCJFIJKZdsReO7EmYGRogXnLVRO6htogm3ZjhDMzNb3s8\nES/ZtbnoId9v9+7dATjppJMAOPPMM71rgV8PKisrWbp0KQDXXXcdANOmTYu6nv0dFRYWxg3xlG7k\nu7Pdpc26Y4/v7Lmo2S7Ec7uX0F+yedWrVy/vfTnWtr/Y4/777wf8MZK56G32q2GEbzL7brNdNMf6\n5m9z48R83WwrbQGG3EufPn0AePDBB73PXH755QDMmTMHiA3FZIfPMNveMMOEyLVqamq878nc+LbD\nvdgb3bZwzbSpnO+JJ54A4KOPPgLg+eefB+Czzz4DosOB2uPPeGIfM8lYUFiKdCHhGYIEM/azFm/u\nY87TbVGJ3UbZm5hlZWUxYUGCRILm9c1wBvFC/qQL6WeCkk/a60t2/bLnAOZcx7bpxIkTAb99njRp\nkve6mXQUfBvamBs/dtg0aSPSidmfmvdiirjihXCww1KWlpbGrMeYoSoAL1H9rrvuCsBTTz3FG2+8\nAcDkyZMBvD5MrifhIMxNEju8TVh9lhlK00xSKNiCJDvxqWkHe2Nml112AWD77bcH/PHj8uXLAbf+\n2AvKgj0nDXp2bKFm0vec0tGKoiiKoiiKoiiKoiiKoihKsyfl5H3mbkvQSnpQ8hH7WIC2bdt6u8AH\nH3ww4O+m2273sjp/yCGHeDsSF1xwQdT5TBWjien2Zqod0r1rU1tby9q1az0lnu0GbJZR7kd+i2rP\ndIOU+xKFqOycz58/H8CTt4utDj/88Bh3WrHfkCFDALjhhhu8ssr7soshyhBTLZFOZIfIVuyZ6kHb\nJdVWzpi7uPZupuw022pk8/qCrU6wlW9mYhBbqRqWKjcSicTsiq9bty5GhWKrRuxdftM11HahtRVj\nZogAe5cwKNEZ+IonMwGBmbwirMQJkhzTLFt1dXWM0s9+/u26bO682UkobLWfqXiy3d7s+mXvRJq7\nuEEKvXQhqlzTZQqIUh/YyS/MkBTm/5s2bfLaE2HYsGEA7LXXXlHHBiWYlGvbLm1BXiXyd5gJVUXN\nbSvWIpFIjEu6raQRzOdL7t32drHDCUm/9vTTT7PFFlsAfls/d+5cAC677DIAPv30UyC6n7QVCWEl\naoFgbyOzz7I9Qmylhfw+8cQTueSSSwDYaqutot6zPTHMhEh2G3LfffcBvrL32muvBYhyz7bb/jCU\nBvL82spSs82JFxbEdtUsKCjwVKViv7POOguAG2+8EQh2L12xYgXg9/F2aBQ7NEZVVVWMp0ZYnkii\n4LE9Rsy20laE2AoMUxUl5Zw1axYAAwYMiDqHvP/ee+8Brt3iuUrafZAZIiDMcE02djJTMzmM3Vba\nqhXTG9AOzSTYz44ZruhXv/oV4KvmxFZS71555RXAb8tMbxUhTNVpUOgc8/7iJSgMcv+1xzViW1Fw\nC6ICa9GihecZsWjRIgCOPvpowFcX2m2L6bpq93fpRNTc9hzBVKLKfcrcIF5Ish133JFHH30U8EPJ\n2OENxMviv//9r3f9Hj16AHjtuSgwP//8cyA25EZQeLGwlIPmuNO8j5KSkriJ9+xxsKkME3tss802\ngK+Ge+CBBwC8+ZzZD9hKe2mfpVxDhw4FfK8L09suLDWuYJ7ffIbihXSw/zcV4Pb3LPcrthk5ciTg\nz0nff/99rrzySgAOOuggIHbMa3sDmn2IObawx9fpoKCggIqKipiEZmaiVbucdvtjhp+Rck+dOhXw\nxyzicX3uuecC8PrrrwPu+oY5twP/ebQV0qaK0A6fFVYoRnPsGfSM2GMJuzymPcVuF198MYDnaf7l\nl18Cfh166qmngOjEhrbNbZd90yMpKMlpWPaB2DmN2c6Z4dLA7/ftNQTw79E+3+677x517JgxYwBX\neWoroG+77TYAzj///KjXTY8Vu00Ma35ueuuba3J222Er2IPmBLa6Xcp+6KGHAv6YWbxKNm7cyOGH\nHw64nvvg36colffdd1/vWCGe5186kXBUifpMG9uLJChkqai17fGdjI9PPvlk7xx2vyfYHrH22Mp8\nLdV5hCqWFUVRFEVRFEVRFEVRFEVRlJRIWZJgxtwxYy3bCZLsuB2ye3v88ccDMHjwYDp37gzExqax\n4wKa8fcOPPBAwI8tIrvoQlAsK3M3JCxkN9ROlGfuEMlrcozEnxJlhdisXbt2nspYYlZJjDQ5n+yG\nie3OPfdcT00qKh/5fmQ3ftWqVYAfb8+MrWsqLsOKIWzGuw6KN2Xv1so9CmbyGlvFI/VBdu9EBW+q\n1J977jkALrzwQiA2aaQdM81UOIWZsEWwd/Hke4JYRaW9iyU7ceXl5d6u+FFHHQX4u1s77LADgKdi\nmTFjBuA+M3aCFjuhoR2L29zda6qELbY629wZl91sebbsnWwzlqWdOE2OOe+88wA48sgjAX/3uLCw\nkFtvvRXAU2TYCcTsGFLmec0YZGEkBzDjvZlKiHiKSvkO7XpfVFQUEz/WTmokO7+ffPIJ4N633dbZ\n8Xnt5Jumh4tcJwxPADv2l6nmsVXb8dQgZnw5WyEqSH0ZMWJE1O8WLVrEJOeTOiXtlNQ56bfMuOpy\nbTs+arqw7WN7HZllsBVX8rtfv36AqzROVQ1hPr9mmcBXVp5++umAnzdg1apVMbENw1CoFBQUUFZW\nFpM4sbS0NEa5GM8TSdqi8vJyrrjiCsDvl0444QTAf45eeuklIDr2YrzExHYymyBlmvlchUVtbW2M\nN1FxcXFcrxd7XGGqAEUdKX2Vbdt///vfAFx//fWAq/y3VaV2/bX7MjMGtVmfw+jTTc8hM2eC1Fkz\noR8Eq77ks/K92/Ev7WdR6sOAAQO46667ol6TY0RBJvUtXo4A870wENUyRH9vtopG6tCee+4J+O2B\ntJemUlXuoUuXLoDv5Wd7d5mxdTt06ADANddcA/jx4e24omZ5zXtIN7YHktmm2HOLoKRQAL/5zW8A\nuOmmm7x+TvqO999/H/CVgqJwWrx4MeDaXeLBi+eN2FzqjmCOQW01dVjKOIlpanpMQXAicttTxu5r\n+vbt69lK1HDiYWR7ppleV++88w7gt1HSTh922GEA3rw2aA4qvysqKvjll182wxLBmDFUzefKboPt\nHA92/15UVOS1m9JG3XvvvYBvK0kYJer/tWvXevVNzmfPK4KSIwblJQqDuro61q5dG6MWjUQiMUr7\neB5aphq+U6dOgN9niS1FoSyqbfk9cuRIXn75ZSA2WaLtYWR69NnxiCORcBLIm9+59M1m/PSg8WFQ\nmXfccUemTJkC+J5HUl6Jy33zzTcD/vh333339b6Pvn37Ar49v/jiCyA2wa2Zxyas9kaQeZY9PzI9\n/uz5u+2FZj5jdv3acsstAejatat3PfNc1dXVMap6qVf282Kuwdmq3DDy/Eg57XwR5vdjr/EI9jzT\njEcsn5Gxs/Q/dmLNmpoabw5rr0VI7GFROcu8y/QAMtuBMHIgmWtq5nNueznbqu5Efao917bXTs01\nJHs91fZuDso5ZavGU22TVbGsKIqiKIqiKIqiKIqiKIqipERKimV7Rd+MAWKriCROlyh0xo8fD0Qr\nH+14K3bcJ7mWxOXZfvvtvV0bUTCJ4sdWesg5zV0bM65TuhGlgb0za+6M2PECZadbdh8knteaNWs8\nVa3s3sn9iep49uzZgL+LPHPmzBh1pq3ItDOEmjsp5ncQZnw0WxloZgG13xN72erQSCTi7YSK0mTw\n4MGAryyQrMSi4HzrrbcYO3Ys4Md7EhVq0G4SRCuMhDAV3fI82coLuS74O1L2TpWpTpfMsvvvvz+A\nF6NL4nxKLDDZJX3ggQc8O0kdkfPZsaTM1+0MymHtGttx9cx46raK1I5RGZRtWZ4HiR8scVx32mkn\nIDb+ZSQS8RSUkvlZ4sqJfeQzpjLF3nktLi5Ou41EdRqkajSV9xBbr2zvh+rqas+2Uh9EfSP3Zcdq\nrKqqilI8y32a54+Xcds8prS0NO22kTiwNhs3bvTKL2Wy65GdtdhEcgGIkkt2xaX9lrbn6quv9j4j\n3gLSXos3wauvvgrgeVOYqr14u/zpwnwWIFpZaV/bbvOkLkn/bn4+npeH1E1ThREvfp8dF/uiiy4C\n3LifthItDAWGxEaTa0g5KysrY3b6bcW+2E7idZo5Af73v/8B/nMk/fv06dNjrm9f21Yy2HZu2bKl\np4SVZ9r2AkoXdnZxWz1rltNuk+37GTx4sKdcstWn8vyOHj066vqJlPbx4vGaKmJpt+3+PV2Ysd3N\nNs6OB2zHVo6nPgK/HbWV0KKck7p09913e/F3ly1bBvhZwkUZbreLxcXFMTEcw4pVKX2W3T6Yinu7\n3f3Tn/4E4MWONr3/bMWPrWaVvsz0nJHr2Lk5BLGPqYy287iEEfs+nmdfdXV1TJkEGd+JclLGM2Vl\nZbz99tuAH9N/4cKFgG8Tc54E7pzEzuMRb4wT5KkWtupUzm2rj805qHw/9j3K7z/84Q8AnHHGGV6b\nJF6jck9SL+Rcr732GuAqLSUOtxw7aNAgwM0BBLFjCFNtKNfbsGFDaPMse+xbVlYW812ZbZL5v3zX\n5eXl3uclZrB4Zsk8YtSoUYCv+h83bhxLliyJOo8dB9/u7808NubcOay2J0jtaypI7fim9pzQnE+c\ncsopADF5NGRMJONBuecjjjiCmTNnAn67b8eFF1tIXS0qKoqKKWx+Jp3Y+UjMfsru223Fo+1J89xz\nz3ke1j/99BMAjzzyCIDnSSNeffL/gAED+OqrrwC3/wJ/firzNImHb46L7FxWYc3P6+rq2LRpU4zC\n36yrtrdNvLjzpaWlMXVevENEsSzvm32knbvDPiYolryteg0De35uzgPsdsf+HdTPythFxvx2PjV5\nnsQL55133vFyBIgnjuTqkHZd2iizXtvjhLDic9fV1cXMJ0tKSmJivdued/Zv8L9bybFmlh3g4Ycf\njrpOVVVVXK9QsbmZ202w+357fNQQqlhWFEVRFEVRFEVRFEVRFEVRUiIl6a6tUjFVFrJCLopKUW3F\ni0HqOE5MLEJZff/LX/4CwBtvvAHAhx9+CMBXX33l7UDYO6JyLntHtLa2Nub8YewUSwweO26vqcy2\ns7vbcfZkh92MdWrHR5FYMbIzEZQh1Y6xZatkzO/C3rE2Y0imEztmpamQtuN72btZcj+y6z927FhP\nDSi7LjfddBMA99xzD4AXv0zOWV5e7t3ju+++C8TutAr/396bRttVVdnj895z3333NQkksbCiDNCI\nQInYgFpAUFQoQSgHFRrpUvStCoqhigAKOgRE6QUsAXFgFAoJghBBUPpGLAS1DEMijQYCWkRMAUle\nf+/9f3jMfdaZ+5zAk3Pqw++/5peb3HfuafbZe+2195prLsuk14jf+Ph4JVGtdrsdRYVsRV6NlCpL\nhxHPc889N7C5n332WQBptgD73xlnnAEAgcF94403hmiwgte3Fef5verTDg4Ols6MIywDxjL1NNKv\nTFTem40OvulNbwKQtsOWW24JAHjhhRcAANdccw2AtBr6vvvuG6J6Tz/9NIB8TTp7vYmJiYjtUIWO\nMBlOGhGt1+uh4juZExrdV+ay1cQi41FZqIwSW0apMjZtfwBShotG9IGYqVE2bNQ8j+murFfVz+W9\nvvOd7wz6XNTHVTv5rW99CwBw+umnh3Owfzz00EMAUoYGn5dsjMWLF4f7UPtdJdvAVm62zHrtp6rP\nffDBBwNINcdtNWcdE2RLfvvb3waAUD9g6623Dscq60OfnRXWTznllMinmGo0/bWg0+lgdHQ0N3uE\nz0NGsvVpgFi3e2JiAsuXLweAoF/KvnTEEUcAAE499VQA2YwD1eHjGKSN4xxn+7eyHuhTVAXLdOQ9\nFlUC5zHK1DjyyCMzWRNA2g6s9q0V4pvNZsSk0qw5Hff1ej16N7Zqdllg9prO0WNjY+E5lbGm92Dn\nXbUHyij+0Ic+BGCycjwwyWCl3/j8888DAD71qU8BQGBbKiyzpcpMAJ7XMqb5/mxNC2XlK4PQ+v+6\ntrC+PxCz0q095RxJf1r1Q/MyXqwvVkUGUrvdjmpccDzYf+v6acaMGQBSP+bf/u3fgr1RdluR/7Ln\nnnsG/5HtRLahji+bkaXZSfZ+q4D6JXmZN5rp+J73vAdAylgeGhrCBhtsAAD49a9/DSDNHOGzch37\nm9/8BkCW/cv22WqrrXKva3Uq1b+x2QtloVarodVqRf3eZtko+1zXFZZlSbtCBikzh+kX87fMjDzn\nnHNCFpdmy2pGsfWX9V1WBfrKXKNbzVrN0OQ+g83uBdI1+4477ogFCxYAQMgK+MY3vgEgXU8Q9JX+\n6Z/+KdSkYH9Se6Zjq16vR/6O2qgyQH9Hx5P1Q9S+EuxLzOTbcMMNQ2Y1We3Lli3L/JYZn/R7f/nL\nX4asPTLki56Tc2er1YrmrLVr11ayPme2vmYeNBqNaB2g7aUZRiMjI9HasKgf2L9rxh8zVPQcds7U\nLI4q9i/q9Tr6+/tz5xhdY/I+VDfcri+oz816ajwv2/HOO+8EkGbmLF26NLQJde45F7JNqHtur5OX\nvVHFfN7pdMJ90P+zSgaqMKCZQbZ/UWf6sMMOA5DaJdZKoI22a3z157SGT15Wpt7LVNfnzlh2OBwO\nh8PhcDgcDofD4XA4HA7HlDBljWXLTubu/9DQUKRjRWabRmsse4D/vuuuuwAAl156KQDgvvvuA5BG\nEqghtmbNmoyWLBAzEpXx0Gg0oohfo9GoTIdHWdH1ej3SMeNzUUtGI14jIyOhauqiRYsApO1KjTRG\nEKx2lUastCKnsiDGx8czOtm8t6p0ZqwuL69r2WbKIFa2xr777gtgUrt01apVAFImG7WrNOJnozDX\nXXcdgDgypJFFq1WkbVFF+zCSzjHDftFqtaIok2oSMWr5/e9/H8Ck3hejw9QAo64no2Wsskv2+913\n3x0YdNR8Vb2mPOa26jtXxeYGJtud0U5bjVv7UZFmJe9xcHAw6C9Rz+qZZ54BkGrkkZXMZ7nttttw\n1VVXAUi1mlhFXVkxyrwEsozGKthxY2NjUf9ot9uBjUOGhjLo1I7bavT8jv2B0WGyDgmr98i24Heq\n324jtKrhVJVOrr2WZf4p60v1sMm2ppb/DTfcEPSmeSyjw7vvvjuAlClmdQXVFmsFae0//f39ETOk\nKi1GnlvZyO12O8oEItgu1Kknenp6wjPy/XMOYwYSmb7MLtl5552DRj6rhbOvKuvDjq+iiu1lgr6O\nsmIbjUbIeFAWpc4nxNDQUBg3OscpC9myN7UGhWrF0h7yHQ0PD2fmcSAdr7SLZcJmnXEct9vtyAdS\n3Uq+tx/96EcAJhlvyuAl+5aMQWXWWWa0viP1AS3D12rDA5PvrGxfkNlr+v6sjrG+J7WHdswrI18Z\nk2TnWMYfz89MUo53fgAAIABJREFUJtZV+O1vf5s5l80y0EyTqrKParUakiSJMg4sK0ZZ2ZyjtU0b\njQaWLFkCIGW333HHHQBS5iDn7DyN0rPOOgsAcNNNN4V7s9e1mXWaSVcFc5Bsbp0DhoeHo/lb75E6\nwGRnDQ0NRTUztK/zt7Qlxx13XLAvHJ/MZuP1NIuy2+2GtmHfqWJ9RVitdKtVrllWRTUK2M9efPHF\nUDPjwgsvBJBmVxHa32z9AdrWuXPnhr8B6ZrNZojRp9c5o2xYu2H7B6+rc5RmQ/D/G264Yci8YmYM\n2YCq+XvIIYcAAM4888ygrcs1CMF3w/vg9QcGBiIfvapaLUB2DrD+jrL6VGec4P8POeQQPPzwwwBS\nvVM+G+sfWX10YNLWMEOJ61b1mflpbZWuZarKuLbzjPXLX21e1ew/IB039JHV1lMTl+1w0EEHBeY7\n2+QLX/gCgHQ9RtixyOvQfnU6ncr6j82OsT6Nzs+vxuweHR2NNM0tC9ueg7DZPLpmUd/R6uLm1b4o\nG6yZoPtcfX194bk4p7B/69zFZzn11FOx2267ZZ6D905fkFkRzDbq7e0Nczznc7YRNd+ZhWwzapRF\nXUVGcb1ez7SD9XNt3ScLHd+WYcx9T9on6pAzq4RrLOvXaR0htbeqg29rULC9ppo164xlh8PhcDgc\nDofD4XA4HA6Hw+FwTAlT1liemJiIGG99fX1RhIV6OdSjZCSA2jv3339/qOBI/UmNfHHXfZ999gGA\njI4LoyJFldMtQ6woClQmyI5jFMJGhjU6w3tUdqXVuGSbqPaTwmplKRunSIfMRmfJBmfbWE2/MsGI\nqEbzbLRG24H3ufnmmwMAvvrVrwIAVqxYEfoVI6IEozNakR0Arr76agDps6p+I6GalkC2TatgneZF\nlixbsIgZS40qspYWL16MhQsXAoiZ3/wN9a1+/vOfAwA+8IEPBMYy2bxFWnlaad3eU17F5TJADSfV\nY7KaYKrDbZnqFueddx5mz56duW+yL8mK4jmpBbt48eLwHRkH1JZVzUK+u/7+/vA3GzWuSh+NNs5G\nITWrQVlLZJFYzTmrnQykEVBC2QpWa9tWFAdifX3LjtF+XFUmgNUQtnq5qq/Fe9QMDrJ2BgcHw5i4\n6KKLAKRM3JUrVwKIs2aSJCls+yJt1bVr1xayZMoG7Y5Go21WkjKbOHY23njjzPftdju0D1mRZCYX\nZRPddtttQcuQ2UraLuoLWDZ11YxuMiuBrB1UfThCKyjb8cDzaBYO7YVmG1mda+tn2WOUodLf3x+x\ndZjZUwVs3+H9W5aMsnL1GbfffvtwLrYps2nIPNHq6dY3KGKOqr3J08m1jMey2YPK/iKGhoaiOVkZ\n7Hl69WorCVZNJ7OL+p/j4+OhnS644AIAqYawtoXNKFQGWlX+MjN31Fe3dk7HOBnFhx9+OICUFXrm\nmWcGHem9994bALDFFlsASPtXHrOLcx59ILVRhO1L+k6rys4CEOlp9vf3B6aw6lQqbB2OogwJbV+y\nTt/61reGa/74xz/O/Faz1ogkSQrZUGWD/UYz+Wzmgc7tPIa2hevJ5557LvQdXSvpGsBmNSpTl9rN\nBP0D+lcvvfRSZAttdlhZoE6u9tPVq1eHedYeC6TvSXWZDzjggKC1ve222wKIWbw8lrUT5syZExjg\nO+ywA4C0j2pftYzPPPZ0lRlsvI7VhNUaTUWa7mQMzp07Nzy3rksIthPH0aGHHoqtt94aQJqFrfsY\neRroWt9mcHCwkiwbu36z9ZrUzuk+Au/rv/7rvwBk623QFlPDXPeOmO13wQUXhLan33j++ednrpvn\na2j72Qz1ssH9L14bQGbPR/ctlFlss640q8uysO2nspQtivYErK2xe0pANbVs6CdbrWJg0o9QNqz2\nJT4/+8mRRx4ZrQHouzBrVjPMBwcHQ8Y21ye8FzJ5abt4b7Zfa22UMtFut7F69eqo5pP1t3Qdo/2F\nfaXVaoV6SXyfxx57LIBUs52w+2y6R/pqfYDzlsVU7fGUN5ZtCryVDtALn3nmmQAmN5CBdLHJDamV\nK1dGBrmIAs5JyspKkOKuBevU6PX09EQbrVVtgLXb7cjpazQakag578Omb9jP0dHR0DbcvDjwwAMB\nxGnmdgLSTQsVBdeCBJSnsNceHByspOAPU/a1n9i0P11ocGBRsJyO9fz580MRGt34VGkU/n3u3Ll4\n73vfCyBNrdG0sLwNeE3ParVawUiVhW63m5EUsJOMbgrzk6l7LCDFQpcXXnhhlHJsU3Ds87FwGJAu\nsLR4m05WtngSYZ3vqmRUhoeHI7tjN+7UAdR+wP+/733vC98x0EDpHbY7JQ+4uVGr1TJpIkDaPlzM\n6/edTie3YElVadeaQmftdJETo4Ugx8fHCwuFsO9ss8024bo8rihwZSdxnh+Y7EO0RXYTo6qghAbn\nbLFDtpsGpBhg4UKg0+mE/sCij7o417TZJEnCM2200UYAYmkCTY23RTrUaS4b3ABT22Ltnm4SsmgE\n+7ndANNCd682vydJEm2SFm1G2qJ2uqFYlXyT3WSy76Ko8IoW3bBONfs+JZso61SURpkkSVRoycql\n2P+zD7300kvB8VTpiLIXFLQ7CruxofaGz3bSSSdl7j9JkpAqzjRIgn3KXhfIvnNtJ5vayPPzeupr\nDQ8Plz6+ut1uJt2VtsUWRtbFk6ZE8xlsoR8NhH7uc58DEAfHfvWrX4XNDG7AampjXmBDF7NF0i6v\nF2wftTF5Gxvqn/LYe+65B8BkMJjj4TOf+QyAtPiTbtbzOcbHx/GVr3wFQLou0U0AbR8bbLMbG1X0\nHdtPdcOB92LvUQsc2jZUX1rnOcp/cdE+OjoaNnZYJEl9Km6K0Q/OK8RYZfG+brcbLdSHh4ej4C3b\nTgPoLD5n15Oaoq0yBtaXUZIBfZknnngCQCoDyfvJKxJXRdFQbvCoT7zeeutFAXP6IVpwmf396KOP\nDtKBv/vd7zLX0f5AnH322aEwIu04JeQ0Td72D70Xu2FYNuz8bX2PogJauuE7f/58AMCf/vQnnHfe\neZlzqx0muFfx05/+NNhsFrVjYUwr8WTvw25CWvtVBbnJbnZZH1bnLN3w0g1FICU6XXvttQDSYsVM\n3edGIoOB1obce++9mfMSPD/H8cTERLR2HxgYqGTzlBuROpfYeVPfYR4Jh/etEjQMTqmNpTSPlSQp\nCkLofdhNRaKKoA3nc/VTrA+rxAD14T/ykY+Ee+ZvSDylv8h2pb2ldMpnP/vZQD5USSba6Dlz5gBA\nmPdXrVoV3qXtO2VLxlEKI6+Iqa5xlGygbTR79uzwzLzPTTbZBEA652i/Ghsbi3wnHqPrNV7fzqXr\nCmys87mndLTD4XA4HA6Hw+FwOBwOh8PhcDj+f48pF++zUXAbNVOWCqN0TI1RhkZelFuLp73zne8E\nkBZH6HQ64byMDuvOuspLDA0NRUXGqirYYhmJttAFIwOWmQHEUXJG5GbMmJFJewGyrBcgy9oEssxB\nZQAXCadbVJVubWGvayP3GkFW9jkjWIxsv/GNb4wKAvEc/D9ZCu9617sATKZrkRW1YMECAGlfURkV\nG43MYyVWwTSwzDVev6+vL2Jj8f+M0PF5b7zxRgCTRTPYZ3gsWbV8Bgrds7hbo9EIkiIaYdR25t9b\nrVbUDs1mMyrsUgaUlWtZOMqGVNasRv0sy0iZmjvttBOANMWYLFNbEOKWW24BkBZq07FN2PGo475M\nkM2tDGAbuef413ejEdNGoxGlYrMvsiAQC7iQcXH99ddHmRdsT0bbNc0wSZJQeMHat7KjxRpJt6wj\nZXDxGZhpw+wGsiPuvfdenHvuuQBiyR6eSwsXNRqN0CaUp2Ef5rthkRtboE2ZL1UWYMsrzmLnZp2v\nWciJfcmyI9hWTC8uYvbmFXEk1BdQ2Sj7nY3+l80cpO1XFlyj0YhYhMr20myP6dOnh+dkyhrtx6ab\nbgoAOPnkkwGksgZkOvD5gLTv0J6rL9Db2xuly1edAqnsuN7e3sgWqk3+/Oc/n/l7u90OhVk0HdBK\nffFYfs9jlNWs42dd83mr1SrdF+S745xp/QwtYqWp18osrtVq4W9kMe28884A4n5BtvoGG2yABx54\nAEBc9Ff7FMfs4OBgVGi7yuJ9zWYzymywmY86NzGDhG1gGVCUNGMBUF1raJr/M888g8suuwxAnK2m\nbHfCZleon10mNBPA3p9mH+TNa/b/lq2k/jGz1U477TQAaT84+uijQ5YpZQvZZ4qKUU1MTEQyGTYD\nr0wwo4fPZVn26n9oGnYeg1DnPs0E1eyhnp4eHHPMMZljaI8vv/zyzLG2f+RlJJSd+WifA4gz1ezf\ntQ/RRnFt9IY3vCEUqCY0o0HH6F/+8pfAwKWNJ+uwSFrEyiPa81YlM2MZm1YmQO2vjiW2If3f22+/\nPcpALlpz8LgHHngARx11FACET64n6A/rmsSyqe04r0K+qdlsRvIx1u6pj6Vrb64nW61WuGd+R6mC\nvCxOXo9F5lesWAEgv+i3hc04IIaGhiotdq2Zq81mM4wdzfBR+2z7OZ+FczZldQhmjdt+oYxkQud4\n2080u6CKNWi9Xsfg4GCwZ3atXVRoW2V1ttpqKwCTfYftybn+Yx/7GAAEu8t1FlnenU4ns98HpOsT\nStf867/+KwDgG9/4BoDJtan6GjZTqCxwXPF9WkYx3xOLo3Ke5TvTbPX99tsv3B/XWFqUUO27ZUZr\n5oPdg7PXyZtLvXifw+FwOBwOh8PhcDgcDofD4XA4KsXUhDOQZTjl6WwSjPwz+qAaKzbqVrQrzmiO\njSxwd//JJ5/M/Ia77sow6u3tjSI8q1evrkzgXSPgPT09EROEEQSyV/SeR0dHcfzxxwMADjroIABp\nBEuL/9hog7Y1mW6Esn4sIytPL61sWL1TG7FWhpEWsSO7ZJdddgEwKeZ+8MEHAwAeeeQRAMCGG26Y\nuX9qfFHzK0mSUIiMfUf7n74nq6dmo/9VRP3su2D0zbJUVAtWGbos9liv16Pou2o+kZE7a9as8Jy8\njhZzVH0tXn98fDxXU6rKoht5DHZldPOetD+rPjMwWaAESKOaLNantgpIdeZYoIK2SVkLlnHAazJ6\nWkVBG7Ld+bx8b2NjY5E+smaVaP8YGhqKGH38GzNF2N58/nq9Hh3Lccs5QMdzvV4PDOsq2dxAlmFq\n9Yz5nvjdJz/5SQCplj3f3aOPPgpgkoFT1DbKBrM2df/99wcA7LrrrpljmXFDDTq+P8uoZ7tVwWwi\nbBE0q8WlmUB8T2SekGGbx4biWKQeGJ+ZBVw4l6mGnoWyklkMmFqA/DfPUxXDifdqtfX0Wnzv6q8Q\nq1evzth0IO0jHBMsOpKXDaY63Mr6skxz9tuqGIOEFtGy87oyA/kOqbOodmdkZCRo/CtTjMibh6nL\npzaY51JfzN6nZZlXUURrZGQkuuckSaICRGQ70hfUwr1JkmCvvfYCkGaJkN2jx5Lp9aUvfSnUoFDW\nF9uVmnyqlW6husNlwvaddb0f1VzWbLxWqxX6leq4qlYh7ei5554bZfNoH8q7N/U/8gpblQFbIN36\nW5pNpDZSmXH2nZLlRb+ZmTm8zk9+8hMAwJIlS8Jv1I9U/yVPY512R5n5ZWJiYiIaW8PDw5HWKKHj\n29aY0LmEbaiF1nmdD3/4w0HLmz4Msy04l9Pfs4wzZm9xTVZVkfQ8P9myTovYcOxnZP8/9thjoY8Q\nmh2oY7PVaoW/UeecsLrkFnk1C6xPWTas7qxtC2Xaq81gf2YW9Z133hkxU4vq4dh5iTUW6A++6U1v\nApCyFtXfsuxWogq7w/pZbBNbXFD3GtQ35PNRk/1tb3tbWH9zrLz5zW8GkLYjf8uC6fvvv38orsk5\nUddhqp1u1+e2blWV/jJhsxX5TJrtq8WcrW/HPsPCmOxXatu/+93vhnOq76D3wk/aH2bR2/NWmTWr\nfl+n04kKxhXpCd96660AgD322CO0Ews7zps3D0CcPW3XX9pvdf7musXWRNIs8Cr2L+y+HJCdo3ld\nzs1am0j3VGfPnh3VRWL2Oe3JP/7jPwJI56QHH3ww2BbNONEsdGb0W43lIt34V4Mzlh0Oh8PhcDgc\nDofD4XA4HA6HwzElTFljuV6vR3opVgdO2U9F0e5utxtVXubuOPUtqdNkWTiqW6R6Ico46HQ6UXSv\nr6+vkqiWjYDb6IDVnAHSaBQjS8osnjdvHk488UQAWZYfkEa2tL3//Oc/hwrXRSxujYZNnz49Yo/Z\n91sFlDkzNjYW9RFGjfl/skRPPfVUAMC73/3uoEW55ZZbhvsGgKeffhoAgsYgq12fcMIJ+MMf/gAA\ngbms96QMz2nTpkVsnSpYp4RWpLaRzSJ9PX4yamr7ID8ZEWNF4sMOOyzzLLVaDYsXL87ci44rfSd9\nfX2h79iq21XqW/E5eC+dTifXrgBpO/He+JuLLroIZ511FoD0GclUVgY7n2XVqlX41Kc+lfkuT/PT\nXrfRaERM4ar0uW0lcKsJp7qRqh9odTzt90AcLVUmD9k6zWYzYrUzakz7xk9bjZbfWSZaFXaHOsv2\nGSwjl7aXmnd8r/w77ceKFSsixoAydtTeWs1qzU7heVeuXJm5rtUls3qMQDU6uZYBnKezz79x3vn6\n17+ee2y73Q7tSw3YHXfcEUDaPmRRUrvzyiuvjJhNCl6H7TUxMREx76uoIq/1JPL0nNkPaJc4V9O3\nsNklqqnLtmK/YJt96EMfAgAsXbo0Yr7xufm9MnJrtVroM38r0+C1gr5gHtQm067YeQLIVqVWRg3v\ne7vttgMA3HzzzZlzDg8Ph9+rRhzHCf2GPfbYI9yXHWdANWxcsrnzslheLetBGT3296w1okxRtjd9\nn1tvvTViG6sOvFYEz3sHVcJewzIHde4tYjCT6XfIIYdg6623BoBI45G/Vcbf+eefHxg+5513HoCU\n5a7rCGtrOL71XZWNWq0W6bZb9pnWAikah/V6PRxDZhN9P37PzwsuuCC6ttaPUJ1gm3WhjNQq/UAg\n1iJvNBpRtoeOP82UGB4ejn6jx7IN9ttvPwCTWRccf5zPrrjiCgBxfQA7D+gcbrWFy4Rl5ObVbaG/\nwzmENpkZnxtvvDEA4Kyzzgosa/V7+PzKFs2bg19Nl7nVakW+epVzlmVvWz+O753tw2fhHE72JO//\n17/+deRPF627+JtVq1bh4osvzpzvO9/5DoCUKf7HP/4RQDZjx9aG4n1X4Qvaa9ixo9lPRf2W7fDC\nCy+E52Ldmre97W0AUt+Pfi/H1RNPPBHa2jKS8+4pb76osgaShWZD2HGsTO6iDFH7HdtF+87y5csB\npLWT7BzGdmIf1T0xu5+ie09VZUp0u93cjAZeX22xttkPf/hDAJNZWdQx136m7Ofbb78dwGT9HzK7\n+R31l5mdvWjRIgBZe6TZCfbvZcLWTbDvSv3VonncKjbw/uj/UNPeZu4AwLHHHgsA+MMf/hD2zZgt\nodfhb5nFZmsPsG2mWt/HGcsOh8PhcDgcDofD4XA4HA6Hw+GYEqbEWOYuu1ZTtNp+eX8D8nfllTHH\nzw9+8IMAgPe9732Z7wcGBnDhhRdmzqPRF2UUJkkSXbsq1qmNllk9INUapBajsvYY4X7hhReCLgrZ\nf4zaUU9OdT3b7TbOOOMMAHEUQ5/fMqw0+lxVtK9er6O3tzfci9VW1aijVrnmb775zW8CyGr3kK1C\nDacf/ehHmeuyUvgpp5yC3/zmN5nrEKrhxMj5+Ph4FEmsiqViWafsD7baNr/L02EGUj3Txx57LPyG\n2sHf+973AKSsw/vuuw9AqsdjWfXK7lGNYvtO9LvBwcEQ9SoT9XodzWYzYupZ5pay9Mk80Ejp5Zdf\njqVLlwJI2e5sd7Inqb3M69x1111Ba1f1iVS/N4+Bqyy8KqCMmDwbp8xKzaCo1WqRbhxtldpi2qqR\nkZHQR8hgf8Mb3pB7j/YdKQO6qkixZSlatj/fI7WV+e55zAknnAAAuPvuu8O969yWdz0g7WunnXZa\nYIjx3d97770AJvuUhe2vykStSi+XjII8pgGfgdlDtCGMlBOWBa7zHMHnYBuzj334wx+ONFMJ9qmr\nrroKAPDss88CQIZFbLXsyp63yDK2umN8FmWmE3yWGTNmhPviPdMu8t4vv/xyAJN9hNcD0rFjmdkc\nazpm1qVpZzV6gfL7EPuOambmVS/nuyXbnSwSzrNr1qwJ4412jPaG8xqfgxp5rVYrPJOy8djG9CN/\n/OMfA5hkw6hGXRUasGSXap9OkiRiV2smAzNB2IZz5swJfp0y4PgM1KZk5fPx8fHIP2C7FrELkySJ\n3lcRg+b1wmZJAFl2Hq+tz6iVzcn4O+200yKfI08f2f4/SRJ8/OMfB5C2N2uZkEmXx2TV+iO2enpZ\noNap6nQODg5GDDW1g3mZd295y1sApIwwarkza4/zE/Xvrfa1skuttrT9u20X9b/KBucmZcLa+Ufr\nkKifQ/T09AS9cmY3sC9uvvnmAFJbxUwSu4ah7X7wwQcBxJmhHHO2H7L/VsFW5rV0zHDtBaTvju+H\n73afffYBAMycORMAsGzZsrD25NynrDvtD0mSYNNNN838TbWd2SY2E0HXX41Go7J1lmUqWp31Iv1W\nft5yyy0AkGFgsp9pX9Q9ANsPf/WrXwFA+Hz7298OAMEekembl3GtDOmyYTNAudZqtVpRBojaHWWl\nNhqNkCVE5iifh74R2f5PPfUUgMm24ftQu1Kk9W59PsvMrarvTExMhHdubYlmfPK+lPWZ56NSi9pm\nKQMp85a1bWwNJr4bnrdoXdLpdAr7ZtmwtdcIu47QvQLNutpggw0ATPo7usZ+7rnnAACPP/44gDS7\nhnWlent7ozUMxwrnO7aD1ThWZnxV2WtWh9vudeo+Bu9Rs8v4+da3vjW8c35qFpHapI022ijsmd5z\nzz0AUiUIrivYZvadqI2Zar9xxrLD4XA4HA6Hw+FwOBwOh8PhcDimhCmHvqxuiv1Oq81qhIKwkQXV\nL2QUdf/99wcQR8xXrlwZIn2MxDPyvmrVqsz5LbNTdTOr0OHRyAQxOjoaIiOMJjDipKwE3tPdd9+N\n4447DkCqMfjGN74RQBrhYttZ3aXTTz8dAELUeOHChQBinRTLguW9kW3YarUqi9yMjY3l6tiqPqxq\npGnUu7e3N/SZhx9+GEDKONAqx1/84hcBTD7zddddByCOvCvL3WrQamS/Sh1hjcS22+2oqiujeNdf\nfz0A4AMf+ACAVH/6jDPOiPS3yPLae++9AaSMZUb+dtttN7z//e8HkDJXeA5lfVjGGO/Jav1V0Tad\nTgdjY2PRuW3UT7XICRt5BybfH5+f7FG291e/+lUA6ft/8sknAQALFiyI2OTKCtHocU9PT6TbVwU6\nnQ5GRkaC3bG69aq7pJqM7G+MXE6bNi1iQfL5yDbNe798drI7tTK8VkS3ery8dqPRqEw3ju+e7ZAk\nSbjXY445BkCsH0iGLp+/v78/0pbU98o+cc011wCYZDlpe1LTU3UYbR0BZS1WwaoEJp/Z2lLLsOe/\naTM22mijzG+V+djtdgu1X/W92rGjfkOezr2FZdT9X4wv1ZHsdDqFjGFlplgmAJlg7INk6qhG/kkn\nnQQAWLJkSWAqsI34W85ttMVW45FjjGOuSh1Yy95mO1l9NtVmZXtQz5YsQOujffrTnw7f2d+oHt7o\n6GhG798eYyvEAynr2WpT2hoVVWRLWDtpGSmqNaq6kXw+MtkuvvjiaGzwOclUpg174YUXwrmL9PuU\nsa0+kD2m6r6jc4ldVyizU8c424/zO5Det/qLqt1qmfb0e772ta8BmNRs5j3a6+TZySp0csnm1r5t\nfWe1s/qOedzGG2+MO+64A0CaCUGmIP1F+kJ23UQbovZF67rYZ9e+UqVOrs04sr6yzst8ZmbmUVeb\nevY2w0PZhcxq22yzzTLnvOeee3DggQcCiOudEMr2Gh0djbJU82r/lAHLErS+Kq+rdoDgPE8W4P33\n3x+eS5mpRXWUtt1229DWRxxxBIDU59PfWF+MsOv0KvoPswF4v/Qtenp6CtcP7OOssUK/sVarRfOG\ntm1e9iCf65xzzgGQZi6p72BZ4vzOZh1VkSlh7SLn7ImJidzMG3sPeXr0XHdTu5uZIBwH73rXuwAA\nu+yyC4Csv6MZGfxUXV5b38VmulQ1rmytDJsJpAxlQn1H3v/g4GAYWxwv+pv/+I//yPzfPhO/Y80F\n7n1oto/1NyzrvOw5ixlaOqatb1X0Tpgxyvlo9uzZoY2px81MLNbI0rW4zfBhW3POZyYA6yrZtYju\naVSRCUCmufoO7XY7ere8H123c+313ve+N/LXFixYACCtKcZjaa/mzp0b6iuwrbnP8cQTTwCI623Y\nfRW9t9fqKztj2eFwOBwOh8PhcDgcDofD4XA4HFPClLboGSnOq/CqzE7VF1V9HhvNYGVMVn6fNWtW\n5ljuzs+cOTPszPO8rHRIJhjPSY3ilStXRtpE9Xq9EjaGZWHY6IdGQZVpZZm4wGR0gFXQf/aznwFI\n249MZmWLbrXVVrjpppsApEwgZTjweowIjY2NhciOZSFUyQBTjeCRkZFCzWONWJK9YStUahRTmU5k\npNTrdfz5z38GEDPGiyrFN5vNSKPIamaXBWVzM4JUq9UyjBz7t29/+9vht0Aamdtyyy2DljQ/WbX6\nr3/9a+ZZ2I7rrbde0JQjA5xQxpDVYSxiblYFZVvZiKy+E743rTRsWXYEo3zMlODfqc3517/+NVe3\nzn7mRYGLbGGZYLTYMpUJPgf/powm1XgaHh6OdArVhqiubLPZjPSl2UbK8LXn0orjVenGWWaJ1Yok\ng3STTTYBkD4vq3YrG8dqAap9Iuvgy1/+MoBU931oaChiz91///2Z83M8W5tDFrNWxa6C0a16p8Bk\nvyBzT7OHtN9bxj6fgW2pz5Gn0642RFmHe+21F4CUUUitcwurz1cmarVaGEOW2aaMfPVx+MmxaLOz\nyMr57/9NdV7LAAAgAElEQVT+bwCphjerwlv9ZmYR6djm2OF7sxqVzNxS/biyQWac6sONj49ndOzs\nffL/zJRhNhaQtqFqGFKLnDqmZOfcc889GW1eINVUZsaAzYYgtF3IgCwbeXr1dowQmq3Gzzlz5gAA\ntthiiyhzgVl6Bx98MICUecJ+0N/fH9kv1YHke2Mfs9qsqgNdBer1emRTrC51kc4z7+naa68FMKl9\nSpY7s/m4FrnhhhsApP2PNSa22267iOnGWhz0BajpbvUXtS3tfFkWqIerzKBGoxHN56pPz/fP9dQP\nfvCD8DwcE1w/6Nxs6ywou1X7cR4Ljn/TLIsq0Gg0Il3Mer0e2KT0hb/0pS8BSPU7aQ/seNf5jHrd\n7Cv8nkzvI488MrJrui7hOLLrOo4zay/LtjvMmlWt9ImJiajPqOYoM4CtXrQy09kWnH80Q+1f/uVf\nAquQ61fL0AZiO5SXuVBVpgTvQ+sOjI6ORs+qGqbqQ1p7yfeu2uMcC3YNxTbkPMZ9CtWttnsBet4q\n65HkvSetgZVX48b+fcGCBaG+DxnwHJMnnngigFTn9fjjjwcwacf5PtTmK1Oezz80NBTepfrRZYN7\nX3nZCHk1SixsrQ3+RjMl+YzUVNbscss05j0w84LauXlrKd3jqGLvyyoW2Gva+jvqq9Kvv+SSSwBk\nbSZZ/NwP1MwQtW8AsMMOOwBI6ybR1j/yyCOZe7Vzl86Bdh4rE0mSrLNmgzL/dX1hWfI6Fthfnn76\naQDp/EUfKK8ege4zETZLndfW/RW7v7AuTLl4n93MyaOiK4Va0yRoMN/xjncEB4g0eBpiQoWp2+12\nJp0aAHbccUcA2fQmIJ3QFi1aFGjw9t7Kdpq5QFGafrPZDO1Faj+fSxdGdnLRTqBOnjreDz/8MC67\n7DIAwOGHHw4A+MQnPgEgLWhnBe6BfOem6hStvGJNWliG0L6k6aNA8eTGzXVKiCxZsgTLly8HEBtg\n3TxgH1u1alXkWFSRosXNQZ6b/aS/vz+SXtB0F75zbjTbe9SCdrrxwVTBer0ejIpOXir1YA2N9p0q\nJ3Wbnm8dK7VFKo2hxjlJkmiyZXEkShDwWKYj2etomnCRk2Xv0W5EVjGpdzqdsHCx3+s708UEJyHe\nX29vb/QO1aHmpsadd94Z/q4LDy0aqqmB3W43WuhUAZ2v7H3R8dDNcA1UEaOjo6Fw3bvf/W4AaQo6\nnRq+A5vGzH549tlnA4jHFZHnGLNvVd1G6vQ0Go1gT9hHilKd7bhTySXtf7ppZAN3uvnId8X3NG/e\nPAD5G8tVpV3b1Ec+//j4eNhI0Lah/WBqHfv4tGnTokIZ9Gn4yXFlx1vRxrzKFLG989Iyq9wctLJo\n9rp8Jr1f9hVupudJPvGZOQd/9KMfBZDKZ1C+qNlshsJalINiwT8NcDDt2F7TzvlV+IL2vHajoWgs\na3DiIx/5CICsbAPT85nmSDkV9YltkSHdQFX/2PYdLaZdVbCP95FHNuG1rc8PxAEH2toXX3wxpF0z\nsEfoRiyf56mnngrn43cMMNIn+uMf/5g5V968XUXKvkph2I3PPP8HSMcZ74XB0Q033DBskB911FEA\n0jbRRaX1y4vGgwbM7PjO2zCsCnl2Z9asWSGQsPHGG2eO//d//3cAqcyblQo5//zzAaS2ifIIOpdx\no2z+/Plh44PXps3SRbj1O9S/qGoNajfdOYZarVZEeNKi03xOBr7tWpbny1v3A6n04h577BGkKnUe\nL5KNGB8fDz66zndlg5unecXV1DfWeULnJyvhqMQJXbvnFSrk3kcRgcPKHqnUk641yoK1Mbx+q9WK\n2kD9eYL7N8cff3xoA24c8nwMOLBYL8fV9OnTI7KJSo3p2tS2p26IV4FarRZdxxbIKyqgzu+tLIT2\nDYLjj/6g7j8AaTtQ2sfKfdpj6/V6ONbKcJQN2h0l0Vh/h++fm8WUE2J/I+lt//33D8EIe34g3tfg\n9zvvvDMWLVqU+e6nP/0pAITCdYT1RdWejY6OVrb3lVf4VvdjVMZVx5ctHMvfkNREyat9990XQCo1\nY2XmKJXLTWhtT0u6UNs/1XHlUhgOh8PhcDgcDofD4XA4HA6Hw+GYEqZMSbCsO8sKLBJ7ZrTrzW9+\nMwDg0ksvBTDJWFYmk6aBqKD+9OnTw/mU/cQoFiMyvMeTTz4Zt956K4A0Yl1F6myn08HQ0FDErLDM\nXN6bRpQ1dThJkojJpQxMmw4CTKZuHX300QCAFStWAEgLvGm0mr8dGBiIitlMnz69spRrW8jQpr4q\nq6aIhWyLOyjTUFNJWbiQ0Zibb745/IbQ/sXrk82Tl1JSJWNZi83YlEhtG2WekD3X29sbsUU06snn\nYrGf1atXRxkFGs1S1uvExEQhm7ps2HQOIMuo0jRQlU1Rhli73Y6KOpEdxvFIWR0bNVb7lievA2Sj\nxRrZt6zrskAWhka+LdNNo4+8H42wt9vtKPquDA6yMiklsWzZsogdp9F4Te3pdDrhWLLtqipQZ+/d\nMnOVMc1jmKLFdqB8zt577x0KjzC9mKmgZLf94he/AJAW3tpss81CH2JEXbMH1PblpbxVyVi2mQfW\nDqqdUyaNMvYte29dRbnyzmGhtliLKXU6nWgeq4odZ8eqlYtRZoGy23is9ZOUsaVjkeOAftKcOXPw\n+OOPA4j7qPoG1gYpS7NKxjJtj73HvEJFamfYLiwmcu2110aZESoBdcoppwBIU2f7+voim6zpo5RP\nOffccwFM+krK1Ozp6anE9liZEOu/aJq8HsNnYsGadrsdjmX6NDOvlDHJPjQ+Ph5Y82RgagqjFky2\nKddFKb1lwp7bvnvN+FM7qazQJEly2UBA2u8473zmM58BMNkmOlepREAeS6pIXqRs2Gwj62/odwTv\nfc899wQwWeQHmJxr5s+fDyDtb7RZBPu+siKBtD8py10zHy0jV7OUqoBl/PE6xx13XCgwTAm4Y489\nFkAqFcNjmeW6cOHCcB61m9/5zncATEoMAikL+oQTTghSV5T04fU4DnkOmzGo65W+vr7S11lM19cM\nEVuMic+rRYM5Vij5YVnzukYkuJ5lpsB9990XikkRuqbS4vY9PT1R9ljVrFPCZkqozdMibboOsxJK\nHDN870VFD20GFDNxlNHNT/u9MoarytAC4mJxY2NjwTYo655Qmc7+/n789re/BZBmGvG8zDj7yU9+\nAiBdex1wwAH41re+BSB+ziJ712q1wr91Pi0bzELis1q5IPXTi7J+2S8WLlwYsh11zv3nf/5nAGm2\nOfeurJ/OzxkzZmTOr7bcylUWSUaWBcuOtoV3+V5YxJGSb/RLfve73wFAmKeefvrpaJ7T9mM2OjO3\nbJF0FqMlM5rSPJr1B8R9pop1RKfTwcjISGT/e3t7oz0rXfvQJtM+Llu2LMzttDkHHXQQAGC//fYD\nkK7Lbdbk17/+dQBp9oBmPLK/5BUW5L3QF3itUhjOWHY4HA6Hw+FwOBwOh8PhcDgcDseUMOXifVaz\nw2oEqxaHRkQPOOAAAKk+pdWrUQYQwWgDIxN512F0gxERRnq44z5//nzsvffeABD0n4aGhkqP3NRq\ntQwbxrKKinQ1qefGSDt1Zh599NHoN7xfZWyzgMs555wTohQrV64EELPMtHCNZScQVepbNZvN6Lks\n+4BQvV+NZOfpk/G87EPUmKEW3+233x7aTvtvESvXMmhsAa2y26jT6WDt2rVRERBbKFMZbuwPys6x\n2l/KztLoKDWtenp6oiwEzTiw7BRCmeRVMQ3I6FYWo20fZcoUsaet3tyRRx4JII3yUfuTGoU2cqpt\np0WQVGe40+lEEdGqCow1m82MJhufUzXZ9F0qU7Xb7UZav/wbmbf8O9lzVpdN9WjZL5SlYhmxHJ9V\nMJy63S5GRkZCtNW2P3XMn3/+eQBpsSw+C/VbWVzFRphpL8hq+sIXvgAgbSNe5+WXXw7FMGnbleGp\nYz5P417HYlmgnqe1q0C2OJL276Iie3Zu0/6lzGJb1EYzDq6++moAcfENZt/Y/mbvpYqCNraYh217\nHdc6n+h8OzY2Fv2N56D2NmtEMCPg4osvDoUTyZpnG+m8bt+B1mLQLJ2yUK/X0Ww2I803W9RIn5Xg\n2Gch5t133x0nn3wygLTYbhFrhbZkfHy8MNOJGSfUVuY5BgYGIv+xiiwbat7r2EmSJPJBeD9kMJFp\nY20q9QJpZ1RjkDbZFuLjGFPfRvuF9SPYR8nGqqrv8H7yWMOa5cN2YgE26tw/+eST4V7JJuUx/C3X\nHNtvvz2AtCCbta98RmpbMqtRM4Dsb3QeLRs2s0mZQxZaoJhrAb7HSy65JBRjUx+Av1H9z4022ijY\nXmbBsV3JjiKLl/rEjz/+eGHGW9nodDoYHh7OZJAAk0XBOKdz/LOPkMlNrWWuFdvtNv70pz8BQGB1\n3XLLLQDitRGL2S5cuBBz584FkGq7049kW+etI2y2ZZXgGh3Ismt13tZP9gNq3v7+97+P+jmfixlb\nixcvznx/+umnh7WnrjW1jo71OTn+q/JzCPrKmjXWbDaj7FWtqULbSqblcccdF4p7a90VZdzaNeTn\nPvc5ACmbnoXXvvvd7wLIsgbtfdh/J0kSZfS8XpDtrv3EaggXrYFoH2h/JiYmQt0a+r1qzzhWOU9t\nv/32oV4QobZPswxt8Wf1iapAt9uN1sd5ewH02+i7MqORz7PrrruG7EcdD8wi1gyaPNg1AxAXTrVr\nKrvXVsX+xcjISC7jl+30la98BQAwe/bszD2yjtFzzz0X7o/PzoxQzuPMQled+J///Of45S9/CQC4\n6qqrAKQ6wkU1suxehc3kLnsPI0kSDAwM5Gahao01gsewb3MMHXbYYcFntjrWQKyQwL3Aj33sY2Ef\nVTPMtR/k6X7/rfO5M5YdDofD4XA4HA6Hw+FwOBwOh8MxJUyJJkadXO5s2wiSRiuUOUitGFYnrtfr\nUaVq7pRTE4uRH0ZBLRtTKyFT54raPfzeVoq2DL0qIupWC9ZWfNT2YjScEXQyARiZWL58edCeITOQ\nEQielyxnVlcFEKLvZHgzolWkU5ckSW6l1ypYy6r/ZRnAGrFm+yhrybJTixhNO+20E4CUkUG96TVr\n1kTsHdV+Va2+8fHxjG4hf1sFM9fqfOXpzmpUXBlIVveP/1YGqTJsqG+VF6kmeC95FcmVQVylNhoQ\nM4Xa7XbUHnyn+qyW8b3lllsCSJk3jP4zIspxo3pn9jzKqlB92UajETGVx8fHK4kWDw8Ph3dgNTWV\n2aY6iMoQaTQaGV1AfmeP5bjKY5eQbaksRh7Ldu52u9H7qcru2PfAvpEkSZhTaD932WWXzCfZ/OwL\nzzzzDO68804AqbaistZ33333zG86nU7QXebzqg6v6tAODQ1F+rhV6cbx+hrB7na7QeP1oosuApDa\nyCLGp7U7qgXH7xk5/9nPfgZgkvFNxrgyWQhliU9MTEQR/SrsDrMkNBuj1WpFjGzt71oJ22Z5qUY7\nWXU6z2yyySahH5DdQtaUMqTtvK71KapiDrbbbaxduzZidtn7U6Y6P3mPtB0PPPBAyDSjft4HP/hB\nAKmN5jjabrvtAEz6RbQnZJmSMUhodpTVna9yTKkeo507lbWvDBNb/4J/p0Z0EduQv+E5R0ZGMvU6\ngJhlpnY+SZLwGx2/VcDaC2v3leHITJJvfvObAFLWMd/50NBQ8IXJZlbWWp6PqzVKmH2isBlI6kfl\nZZe8XrBdVL+10WhE7EllG//+978HkI6hefPm4T3veQ+AtD/xt8qg4ucWW2yB//mf/wGQ2mIyx+g3\n3XXXXQBSdt20adMybHl7T1XAakDS33nxxRfDe6GWJNldO+ywA4D0Ganzeumll4Z/U89e+z4/ySh9\n8sknQ1/8+7//ewBptgHtT956hn6TslrLBJmDHOu2n6oPZrXV+VxA6tvstttugWnJvkJ9z9tvvx1A\n+q6pC/vggw9GPq9mi5EFzz5Vq9Uif7uqmgntdjvYWSAdP9aH5b3omuaaa64BkGYWbbXVVmEu4tyk\nvhGfh+Nml112CTrvJ510EgDgpptuyr1XtmOSJJn6OUA1vjL3LvKyq/V96LxG/4QZ2KOjo3jmmWcy\nv2E/Y1vQVyZuvPHGaB9Imbc6pw0ODgb7qG1fNtQfzLse759MfrWxPPbLX/5yqOVy4IEHAkjtMrMf\nHnroocxv8rJsdF+EsMeqtrrdjyoLnLPyshHe8pa3AAA+/vGPZ+6D73abbbYBkNrxzTffPDwfayAx\nw4Tn5d7Y5z//eQDp+ANiLXRl2dv5XG1wFWxuMrA1S6Knpyf8W21O0Rz61FNPhTpq1GhnnZJnn30W\nQJqld91112WuD8T1PHRPx2ZJaEbbVOGMZYfD4XA4HA6Hw+FwOBwOh8PhcEwJtans0CdJ0rW6rZZ9\nY1mwQMzg22yzzQAg6MX19fVFul/ULPriF78IIGXw2gqtWt2yKEqYF3mzeiuvaPSVFrpJkqTb19cX\nMZZHRkbCc+o9kbFMfUHLhuS9sr1XrVoFIGWlKPtwyZIloXI6WWCq9WRZX/y/th8r15bZNgBQr9e7\nzWYzYgLYiIgymzRqkqcbyWdiVJd6PNTJJeN73rx5kSajVnPVCFYe6yJJErICSmufer3e7e3tzX1f\nRZE39gtlnzKrgL8H4igu25cVoNdbbz2ceOKJAID//M//zByr2mNWV1SjjwMDA1izZg0mJiYq6Tuq\nHddutwvfmY41y+hl5VhqxfH/jP4p485GqlUTVvVUCVsJ1jJY1qxZg3a7XWrfabVaEVvUaiwrw0D7\nDvtLq9UqjNiSvcJIOrMsXn755Yi9SnaOzgW8TrfbjVgJfX19WL16dal9h+NK7V9PT0+kWa6VcZUB\nb6uk81iyf7bddlsAKatp1qxZACZZUKyCrAxoyz4B4uwM+28zLzzS7Xbf9zc3iKBer3fzdEJtxXMy\nDcgOYI0Eeyzvn/fJLJEf/OAHmWOof8a+ZJ9VbXGR/pdlFdj57BX2YKnzeX9/f5TJ0d/fH5gz7O9k\nc+v8ymep1Wrhfetv+Vys/0B2xsjISPCVDj30UADpuFXbZlnVyswgXnrppVL7Dv0dZTQkSRKNbbWZ\n6rv19vaG+2X7sF/qnG/ZHEW+hPoPPKetZm/bcmhoqFSb3Gg0utOmTcu8f0KzYP7u7/4OQKot/o53\nvAMAsHTpUgCTPiLZucp21Homto1Ud5q/oZ+k8xdZ1kDcji+//HLpdqfZbGa0p4HJ96PPSHtzxx13\nRM/I32idiaL+YBk6N998MwDghhtuADDJmAMQZVHavqQ6htTOLXsdMTg4mNGd5v2oL6P2huxkZm32\n9/cXZlVoPZu8au9kJnPtceGFFwJIMyPJaLZzo/bJbrdbut1ptVqRTzt//vzA9iNzkvdJhhtraDB7\n1uqC8pNzuvri9jiy5tnf2A5kPdPPIVt3aGgoGrPMvq1iDZrHplR/Q/U0ea9kec+cOTOwdAlmlbBd\n6dvwXY+OjkYa0rp+0VoDrPNgj2k2m5WsI9h3dN+hVquFOZzvX20G2+vtb387gMl1ErWFOXezP5AF\nT1vOvY+lS5eGrMhly5YBiNsnrz6B2rx6vV76nEWbrHUj7L3pGOd74zulv7fTTjuFsXbFFVcAmFx/\nAykLlf2NexVbbLFF5Evomlf3eCwT3/qPZdtkIF1n5WV952Wp2/vOy/Yl85QZAuyLzJjkOsuOJ/Un\nHnvsMQApC1z3SRqNRi77v4q+k6cX3O12w7giM59jgv2MTG2umVhvCoh12bk/SG1/Pr9tV9Xapm3S\n+c6e186rZe/tJEnStbU9bOYYr6tjXvuYaozbey7K8rC/yduTBOI2sRn7WtPEtOdrms+dsexwOBwO\nh8PhcDgcDofD4XA4HI4pYcpCT7VaLVOVE5iMLBRVXVR9RUbTP/nJT4ZIMnVByCJg9IbRB8vGfLVq\n5xrlsLqhWj27TJDpa6uWA1ndQ9VeZCVi6ruRBTg4OBi0BRnpoIbKPvvsAyBtT7Kazj///PBcbDeN\nYihzzzKcbHtVoVPU7XYzDNM8ppv2IdWsJKyGnh672267AUjfNdttfHw8isYqU1kZzVYbkxpAVqOr\nTLTb7dyIp7K9GGUqiu5a5pHqqqmmD9kJn/jEJzLMTPuprHEeN23atEijut1uV6KTC2RZWJb1pYxT\nrSavukKHHnpo0H3iMaqtzHZiv7C68hr1U51TW6VYI5JV6QhPTExEGn5W/1Erweu7tpWotQ8ywsxj\nyfZhn8rTKuV7UvYP72PmzJnBVtmq5GXb5VqthiRJclkyyrJWHSqrBw1MPj9titoAVlIng4XnvPLK\nK8N5NBpdpF1l2V+qLVc1bKSc90Am3y233AIg1dEm44JstiuuuCLS7lJN9CIWct49KPPJRu/1b1XO\nV8pkHx4ejiq3s+9of7c2uYgxyL606667AgB++MMfAgA23XTTwOqxeotAPH6tNj/vgW3CDCcy5suC\nZTUAWd1nZRYpK1DBLCAgnm/UHtmMAvU1leWsNspmaHHO4nXLBFl4ylyyfZd9hzq1ZCwz64xM5p6e\nnigbRdtGtfna7XY09+hY5LG0acPDw1E2YNVQf8zO53xWzglkwFFb0GadKetP24vPTu3Lc845B089\n9VTmGGXjFdUnsN9VZXcs89POnco+p+2gnSDLnRk0RxxxBD796U8DSP2U5cuXA4i1Xdnul112WfiO\nfVP7kq7tbAYS5yplhZaJWq0WrRmuvvpqLFmyBEC8XmAf0vu2/rX2GSKPEclMP52f+X/1xWxGBt/D\nSy+9VIme59jYWLQGtbWJlOWumQzU/j355JNx+OGHA0jt6JVXXgkAOPvsswHE7GfL6i+6Du0tjxsY\nGIjWfVVonfK8ExMTUX+emJiI5m6OLd1PICv9kEMOCfU59txzTwDpHEs/kFrUzPZasWJFOEbti+qq\n8vtmsxnVMdD+XQaoIcw1kJ036EPwfavfwXe1aNEiAJOsZOpPv//97w/PYZ/rkUceAQB87WtfC+fS\n82lmhmbF52X39fb2Rhr7ZYBZfBy/llWrdY7U79HnqdVquPbaawEg1DLhfM/aL1qjzDL7tR14fV3n\n2XnctmEV85atX2EzenhPfM6zzjoLALDHHntkjmWbPfTQQyEzhnM0bRO1/3WO5nMBxet/re1l1/T2\nGaqA9fvYHnYvTDOHtf6G7VfqQ2sf070f2we0f2jb2/Z4vTUAnLHscDgcDofD4XA4HA6Hw+FwOByO\nKWHKGssDAwORLmSz2Qy74UUap1rp3jLqVFdN9Qdt5FWP5XXJKFXWrtU4trpzw8PDlejqadRjbGws\nE32096EVwBkF6+/vz+id2Ofl90ReZELvwUbOgSybWjXYarVa6Tozr5y3azWyrb4Lo9i8F9UwtdXO\n+XfVvOVvyaDj9wsWLAAwGW1XJo72JWVN2fPYiF/ZfYdap8rOWrNmTYYBC6QRdGVj5TG5lIGkkfpT\nTz0VAHDUUUeF6Pv3v/99AGkfUUYuYSNuNqJWhT636pfbSLbeJ5kGGpVjOz744IPYdNNNM8/ETAFq\nOBGWmVikgaZsd6LRaESZHYODg6VrLDcaje7g4GChtr29V9W5Y3uSpdDf3x/ZDrVRymiwTAOtMM93\noaxm+94sY6Mq3ThlhbRarfBONJKtzFK2ma1AzXunLhhZ3HPmzAGQZklsu+22kf4p24bzVJ4OujIT\nq9JYpuZg3rsoYi2qVliefdA+ZBn7QNY3UAZnnsafvS5Z6AAyWvJl6+o1Go3u+uuvH/koIyMjUTV5\nbQvCapfrPMW2ILtMzwXE45Wg7Sd73Orsq11iO/7v//5vqX2H/g7HhPpuQDrelCmhzz4yMhLpMiuz\nVrOJ7HfmngDEVa+V+WHvqYq+Q1+H78eyyHnP9GnIzvmHf/gHAMD1118PINW3ffTRRyP7SihTyrJx\n1H6ppjzb1x6n/ZjtVoU+t9WrzKstoqxgHnPMMccASJnLH/3oR0PmH8cln40MS7LAyBbMY/5o9lqe\nZqGyiNvtNsbGxkrXZLS1DmwbaZuoLeH4svb21SrAE5YlpZluei/0BawOLO22+mNl63PT38lb4yiT\nUzP0eE+27+t6iudle7ANrH+g84/2WR2X3W43tA/vpYqaEvSTrf44kM0E0ExE9TVsZpWuR4qOZf+Y\nNm1aaBOd69WmsB92u92IiVuF/jSQrrPy9LOL1obKhLRMfI43rQuh/Y7jxe618Hz8LfubzoPj4+Oh\n7ew6eWJiotSaEvV6vdtoNKI9inq9HvnE6rNpPZK99toraAeTictaR7fddhuAdJ3J9frQ0FChL6QZ\nT9ZX1nvhfZS5jnjl2t2enp4wx9jMjCI97qJ1+Pj4eJTFl8dqBvLrPOlvi+q0tNvtyC4nSVL6/oXW\n27DtULSO0LW8fbdFzHXNurDH5T2nPQdhs73y6nqUPZ/TT9bsDpsto/eY52coitby+ty1Wi3YoSI2\ns7XF/LuOabNufU3z+d/Ed6ZB5Quxiz3dnMtLB+SnDhD9bV4BLi1ap4ZYjZ+dSKxzVXaqTafTyU2r\ntEW01CHU1Ak+98jISJhouAFhZUfsb2yn4+/teSx087/ZbEYpSzZwUCbq9TryCktYqRBdCNpUJSC7\nua4LAT7b9773PQDA9ttvDwC47rrrwvW03dUJ1knV/sY68VXJPRA8/6xZs4JR0LGgY8cuIHTCL5LN\n4Dmff/75MOHzPAzUFC1EbDCpaHO1bGh/6HQ6USofx4e2Af9/xRVXhPQrHvuLX/wic17CTvJFKSi6\nYZSXMmuL5ZXdd9rtNtauXRvGsXVC2V7qmOrky37fbDZDIRo6wzxWBf9pI+r1eqEzNHPmTACpDcsr\ndKhOWJlgep8uCrhY5P3b5ykKcrLgqwVThbfZZpvcZ8grZMY5c/r06QBi59AWJdO5s2ww5VT7ZJ4N\nUTujUiJ5hTTVadbf2MBmngMNxGmQLNQHZAOlVczntugSr5UkSaH0gm7A5G2Sa3uyLWgj7KaEvn8N\nyinGAKAAAAmdSURBVGpAoN1uh3+rrE/ZoCyZPnOn0ykcU/qObTFPu+Gi57OfhB1bHFMqjZG30awF\nRqvydWyBMd7neuutFxVv/OxnP5u5D51T8+QzlCjADVO+C7tw1Q2doj5lSRtVg31HyRL9/f2FC0Pe\n/0UXXQQAuOSSSwBMPqv6xLoRoan2diMprxggEKfb1uv1KBBbJMf3ekB7bCVKeC312xS6ULVtw+fi\nvMPz6prASgWovaEPwP42Y8aMcF0NMFY1Z3GdpW3faDQKr8k20OKU9jxqm7Qf5MkPWHkkIC5abH1E\nth2/Gx4erqyNdN1n771oQzlP5kTfpUoiaJr5yMhINDeq/5PnI6jUA1DsD7xe2Oey40VTydXu6Bp1\nYGAgameVzdLPPBtLP1v3L+z6lr+3a5sq0vatbKjdqCqS7bB2Bkjb7oYbbggyIBwbGozPKy7Lv+kG\nsq5BuTa1657/Kxkn3cCzEpvqfygZyW5g5q3b7WdeUbaijUDdVLV7ObpJnyddWBbUP+nv749kiHQO\nyxsrSkRR8g/7lJUEKZIjUXtjfWUNlFbhC1KeiLB+mMqx2TU1jwGye6c67xURLO0ai9dRP1nb3u4T\nsN2KZAxfDS6F4XA4HA6Hw+FwOBwOh8PhcDgcjilhylIYlvJOWFYYIyRaQMAeS/A8Gs3Swg82gqHR\nM43wqOD72NhYxPZkMZ0yKe9MJdGIgi3coxIPGuHm/fX390dMAkKjVTYSpVGposIU9v0x+sO0zaGh\nodLb5pVr57aPZb4qK7KI7W6Ld2hUkMdqyqdtR2VX5EUUeT1ltIyNjVWS/mjZ3ISVU1CmMqG/6e3t\njaLChLJu2Q5r1qyJZEg0pVojn4ODg1GE7RUpg1JTtF45f9emHNnnKUqzL0ozsen3ykpSW2Wjqxo1\nfS0Fg/ReqpDgSZKkOzg4GLG/arVaJJui96P21qbs87sXX3wRQPreyRaw1ysqgqBZFpahqO2VJEll\nUhh5RcPUjnK+0n5ko81qa4oyIGzfUAYMoXbJpuZr1o2J3JeaVsw5S99fHuujKLWeqNVqhfONZtDY\n1DYdgzqe9J663W40L3RfKcpTpt1hSrqyX61NVlaWppxZdoIyh3msZs3Yed1mXdljtW3yMrG03734\n4oul9x3bPnnvTaWstGiuTU3XOb5Iismy1HmMzQixx+r4tL8nk6aqvtPf3x+xqF7xGwCkbaLvVFnu\nZPcCMbtdbbVtQ5UhUZkiLbxrr6lMsaGhoVL7Tq1W69oxYdlbfFb6IcoOzmPZFMnmKDPHMpmV4WPu\nLXOstWk6XwIoPWWfc5Yyu2xGiK4X1D5YNpiOJ+1nmuFQq6XFn9lHtH8R7Du1Wi34zvQP+P/Xmjr7\nWsGxlScXpYwzfUZFvV4Pz6jMR7LY/vKXvwDIyvHxmnx+m14NxH6kTbtWZnjZ64jBwcHI78ubMzV7\nLE++o0gWrYiVbOc4XTcQahMtU9VmPlYhZ8C+o89l26dI2knliJrNZsRYVjarpvknSZKRx7K/UVay\nZUxrdsn4+Hhl+xfK8LRjXu2O2hL7G2VSqg0pkjMD4kyjIv/RZkfZ91X2GuuV++v29fVFjFD7LPqs\nalvs3/My+O2xygq3TF7NplAf2vYp7TsASperZN9RWQZrBzVzRseIVSsoku3ReT1PGkXbLa9N+L3t\ne0TZNpnzuWbIWdk6Zeqr726fr8geFTHgkySJjtUCh4QqRQBZeSIAGBkZeU3zuTOWHQ6Hw+FwOBwO\nh8PhcDgcDofDMSVMSWOZ7AllNFjBbWUDFunP2IhPEetYNaxs1CZPS8TCRgaU+VyFRm69Xs8UeCKs\n/rSyEJQdZ59J2aDK4CB4vfXXXz8Uy1KWFSPXjBrZ96dMvWazmasn9npB3UHVo+x2u1EUt6hwi41Q\nqfaVMlC0n/T29ka6WdqP9T0UaU6VrUVIdoA+rx1rRRFfZeVYhr5GBVWbyEY+LfvE/k3bOY91aiOx\neTrjZUGj3P39/aFva/QyT98MmBxHyuBV20RwzI2OjkYsRI0wa0TURv2qtDvUAef9kInX399fqNvF\ne9bxNjY2FphGfHYyd4oYhc1mM+hbq8a7sjJ4nYGBgUgDNo85+3pBXXerqchrKTNQC/EoG5LtYu9Z\n+0LRWAWK9Xf5G8uI0gybKnVy7TjOu16RHlces0/n/jxtUx7L/xe98yK9XKuxbJ+jbCRJgvXWWy/0\nA9qMiYmJiM2kmS58br7ToaGhqNgq+5nql9r5nudVnX32VWXtrb/++uFYnSfKBnWROW/wHYyMjIRn\nU/uq/cOyL4oYO8pwyWPhFfl32i/Gx8dztfeq0Ku0926Le+nzFNWKsG3GfqR/U7tur8t+xWtroRra\ndTvfF2UclA2yYpWB1u12I/9Dx1Sepqb606qxrH6fZZDqWC6q1ZLnx1cBXkfnlp6enmheUWaY9n+r\nJ8txqsXTtI3s3KiZozaj0l63200LsHENUpXdIZtVWfv2mmpf1A+xfaqovgufg7+17O2iOVCZYTaL\nkn4Zz1cVbK2fvMJmygLUNahmHAPp86nGcp69sPMAv7PHqN0bGxuL6nnYLNYyQVa77i90Op3IdyV0\nTcjn6u3tjZiiRRkFdj5SXVW7LgHSts2zMepHl4larYbe3t5MIW9eU9fjRRrLtj2K2Kvq2+oYtefn\n+XT/wraN2qi87MQywMwm9WkmJiYibW1tD8K2m75ftanq21hmP6G2S/9u9bnVnyoTtVotoxtt9wz4\nb62fpmPDzsdqT/VT6wkNDw/n6toDceY6YQsF69qsbNRqtagI7PDwcFTEWn1c9ve8ubRIz5uw87uu\n2XUcaXHE4eHhiL081bZxxrLD4XA4HA6Hw+FwOBwOh8PhcDimhClpLNdqtb8AeLq62/k/xcbdbvfv\nyjqZt8264e1TDG+bdcPbpxjeNsX4f6xtAG+fdcHbZt3w9imGt8264e1TDG+bdcPbpxjeNsXwdcS6\n4X2nGN531g3vO8Xwtlk3XlP7TGlj2eFwOBwOh8PhcDgcDofD4XA4HA6XwnA4HA6Hw+FwOBwOh8Ph\ncDgcDseU4BvLDofD4XA4HA6Hw+FwOBwOh8PhmBJ8Y9nhcDgcDofD4XA4HA6Hw+FwOBxTgm8sOxwO\nh8PhcDgcDofD4XA4HA6HY0rwjWWHw+FwOBwOh8PhcDgcDofD4XBMCb6x7HA4HA6Hw+FwOBwOh8Ph\ncDgcjinBN5YdDofD4XA4HA6Hw+FwOBwOh8MxJfjGssPhcDgcDofD4XA4HA6Hw+FwOKYE31h2OBwO\nh8PhcDgcDofD4XA4HA7HlPD/Adppkxv48+p8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19d3b082eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "origmean,origstd=(np.mean(x_train)),np.mean(np.std(x_train,axis=1))\n",
    "decodmean,decodstd=(np.mean(decoded_imgs)),np.mean(np.std(decoded_imgs,axis=1))\n",
    "accuracy=np.mean(np.argmax(pred_labels,axis=1)==y_test_num)*100\n",
    "print(\"Mean and std of decoded : %.3f, %.3f\"%(decodmean,decodstd))\n",
    "print(\"Mean and std of original: %.3f, %.3f\"%(origmean,origstd))\n",
    "print(\"Accuracy: %.2f %%\"%accuracy)\n",
    "\n",
    "\n",
    "n = 20  # how many digits we will display\n",
    "plt.figure(figsize=(20, 2))\n",
    "indices=np.arange(len(x_test))\n",
    "np.random.shuffle(indices)\n",
    "# pick randomly n images out of the test set, reconstruct and display them\n",
    "for i,j in enumerate(indices[:n]):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    if np.argmax(pred_labels[j]) == np.argmax(y_test[j]) :\n",
    "        ax.imshow(x_test[j].reshape(28, 28),cmap=plt.cm.gray)\n",
    "        # display predicted label\n",
    "        ax.text(0,28,np.argmax(pred_labels[j]),fontsize=24,color='yellow')\n",
    "    else:\n",
    "        ax.imshow(x_test[j].reshape(28, 28),cmap=plt.cm.gray_r)\n",
    "        ax.text(0,28,np.argmax(pred_labels[j]),fontsize=24,color='red')\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[j].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    \n",
    "plt.tight_layout()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis = {}\n",
    "analysis['accuracy'] = accuracy\n",
    "#analysis['training'] = infoLadder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_obj(analysis,'ladder_sketch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def savefile(filename):\n",
    "    if theNotebook is None:\n",
    "        print (\"Run the cell starting with %%javascript \")\n",
    "    else:\n",
    "        os.system(\"jupyter nbconvert --to script %s --stdout > %s\"%(theNotebook,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theNotebook=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefile(\"gug.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ladder_custom.save('Model_ladder_sketch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "989px",
    "left": "0px",
    "right": "1184.36px",
    "top": "107px",
    "width": "223px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
