{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Towards fc ladder \n",
    "\n",
    "Architecture and formulas of layers as described in https://arxiv.org/abs/1511.06430.\n",
    "We start with an external mnist dataset and do first a fc ladder. To be consistent with downloaded python ladder code (https://github.com/rinuboney/ladder/blob/master/ladder.py) we first scale the input between 0 and 1.\n",
    "\n",
    "Try to introduce batch norm as proposed by Martin Görner following his ipynb-notebook:\n",
    "https://github.com/martin-gorner/tensorflow-mnist-tutorial/blob/master/mnist_4.1_batchnorm_five_layers_relu.py\n",
    "\n",
    "There is need for special data and mini-batch preparation for *true semi-supervised* learning with mini-batches consisting out of labeled and unlableled data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we use ladder code only to compare to purly supervised benchmark !! Therefor we set noise sd_noise=0 and loss_both = loss_supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# if working on laptop on local docker:\\ndocker run -p 4242:8888 -v ~/dl_cas/:/notebooks -p 6006:6006 -it oduerr/tf_docker:tf1_py3\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# used docker command on cluster (possilbly data in Oliver’s data directory):\n",
    "\n",
    "nvidia-docker run -it -p 8710:8888 -p 8711:6006 -v /cluster/home/sick/:/notebooks/local -v /cluster/data/dueo/:/data -it oduerr/tf_docker:tf1_gpu_py3\n",
    "'''\n",
    "\n",
    "'''\n",
    "# if working on laptop on local docker:\n",
    "docker run -p 4242:8888 -v ~/dl_cas/:/notebooks -p 6006:6006 -it oduerr/tf_docker:tf1_py3\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# python module imports needed in customized functions:\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "# import customized functions collected in my_fct_for_fc_ladder.py\n",
    "from my_fct_for_fc_ladder_Lilach_vb import convertToOneHot\n",
    "from my_fct_for_fc_ladder_Lilach_vb import my_norm\n",
    "from my_fct_for_fc_ladder_Lilach_vb import my_fc_bn\n",
    "from my_fct_for_fc_ladder_Lilach_vb import my_noise\n",
    "from my_fct_for_fc_ladder_Lilach_vb import my_comb_vanilla\n",
    "from my_fct_for_fc_ladder_Lilach_vb import encoder_prop\n",
    "from my_fct_for_fc_ladder_Lilach_vb import decoder_prop\n",
    "#from my_fct_for_fc_ladder_Lilach_vb import init_weights\n",
    "from my_fct_for_fc_ladder_Lilach_vb import init_weights_v2\n",
    "#from my_fct_for_fc_ladder_Lilach import init_weights_combiner_vanilla\n",
    "#from my_fct_for_fc_ladder_Lilach import reconst_loss\n",
    "\n",
    "#from my_fct_for_fc_ladder_Lilach_debug import decoder_prop_ver ## for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.0.0',\n",
       " sys.version_info(major=3, minor=4, micro=3, releaselevel='final', serial=0))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# additional imports of python modules\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imgplot\n",
    "import time\n",
    "import pandas as pd\n",
    "#tf.set_random_seed(1)\n",
    "#np.random.seed(1)\n",
    "import sys\n",
    "tf.__version__, sys.version_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Edit Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n## TEST 1: arbitrary inputs\\n# construct the graph:\\ntf.reset_default_graph()\\n# define input dimension\\nn1 = 2 # batch size: # images in mini-batch\\nn2 = 5 # layer size\\ninp1 = tf.placeholder(tf.float32, shape=[n1, n2], name=\\'input\\')\\ninp2 = tf.placeholder(tf.float32, shape=[n1, n2], name=\\'input\\')\\n# symbolic call to function\\nloss_rec= reconst_loss(inp1, inp2, \"test\")\\n\\ninit_op = tf.global_variables_initializer() \\n\\n# define input tensors (encoder & decoder)\\nin_enc = np.ones((n1,n2))\\nin_dec = np.arange(n1*n2).reshape((n1,n2))/n1/n2\\n\\n# run the graph\\nsess = tf.Session()\\nsess.run(init_op) #initialization on the concrete realization of the graph\\n\\nlres = sess.run([loss_rec],feed_dict={inp1:in_enc, inp2:in_dec}) #Evaluation result from fct my_combiner_w\\n\\nprint(\"the tf result is:\")\\nprint(\"loss=\",lres)\\n# calculate with np\\nenc = in_enc\\ndec = in_dec\\nbneps = 1e-5\\nnormnp = (dec-np.mean(enc,axis=0))/np.sqrt(np.var(enc,axis=0)+bneps)\\nsqnp = np.power((enc-normnp),2)\\nlossnp = np.mean(sqnp)\\nprint(\"====================\")\\nprint(\"the np result is:\")\\nprint(\"enc=\",enc)\\nprint(\"mean enc=\",np.mean(enc,axis=0))\\nprint(\"var enc=\",np.var(enc,axis=0))\\nprint(\"dec=\",dec)\\nprint(\"mean dec=\",np.mean(dec,axis=0))\\nprint(\"var dec=\",np.var(dec,axis=0))\\nprint(\"loss=\",lossnp)\\nprint(\"normalized decoder = \",normnp)\\n\\nsess.close()\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################################\n",
    "# loss unsupervised per layer  - general fcn reconst_loss(encoder_clean, decoder, scope):\n",
    "# formula (18): normalize dedcoder using *encoder’s* sample mean and standard deviation statistics\n",
    "# input: encoder_clean, decoder (same shape than encoder_clean), scope\n",
    "# output: loss_reconst (squared Euclidean distance between clean encoder layer and corresponding decoder layer)\n",
    "###################################################\n",
    "def reconst_loss(encoder_clean, decoder, scope):\n",
    "    with tf.name_scope(\"squared_dist\"):\n",
    "        # normalize decoder using *encoder’s* sample mean and variance\n",
    "        mean, variance = tf.nn.moments(encoder_clean, axes=[0])\n",
    "        #mean, variance = tf.nn.moments(decoder, axes=[0])\n",
    "        m = mean\n",
    "        v = variance\n",
    "        bnepsilon = 1e-5 #A small float number to avoid dividing by 0\n",
    "        decoder_norm2 = tf.divide(tf.subtract(decoder, m),tf.sqrt(tf.add(v,bnepsilon)))\n",
    "        loss_reconst = tf.reduce_mean(tf.pow(encoder_clean - decoder_norm2, 2))\n",
    "        return loss_reconst\n",
    "\n",
    "'''\n",
    "## TEST 1: arbitrary inputs\n",
    "# construct the graph:\n",
    "tf.reset_default_graph()\n",
    "# define input dimension\n",
    "n1 = 2 # batch size: # images in mini-batch\n",
    "n2 = 5 # layer size\n",
    "inp1 = tf.placeholder(tf.float32, shape=[n1, n2], name='input')\n",
    "inp2 = tf.placeholder(tf.float32, shape=[n1, n2], name='input')\n",
    "# symbolic call to function\n",
    "loss_rec= reconst_loss(inp1, inp2, \"test\")\n",
    "\n",
    "init_op = tf.global_variables_initializer() \n",
    "\n",
    "# define input tensors (encoder & decoder)\n",
    "in_enc = np.ones((n1,n2))\n",
    "in_dec = np.arange(n1*n2).reshape((n1,n2))/n1/n2\n",
    "\n",
    "# run the graph\n",
    "sess = tf.Session()\n",
    "sess.run(init_op) #initialization on the concrete realization of the graph\n",
    "\n",
    "lres = sess.run([loss_rec],feed_dict={inp1:in_enc, inp2:in_dec}) #Evaluation result from fct my_combiner_w\n",
    "\n",
    "print(\"the tf result is:\")\n",
    "print(\"loss=\",lres)\n",
    "# calculate with np\n",
    "enc = in_enc\n",
    "dec = in_dec\n",
    "bneps = 1e-5\n",
    "normnp = (dec-np.mean(enc,axis=0))/np.sqrt(np.var(enc,axis=0)+bneps)\n",
    "sqnp = np.power((enc-normnp),2)\n",
    "lossnp = np.mean(sqnp)\n",
    "print(\"====================\")\n",
    "print(\"the np result is:\")\n",
    "print(\"enc=\",enc)\n",
    "print(\"mean enc=\",np.mean(enc,axis=0))\n",
    "print(\"var enc=\",np.var(enc,axis=0))\n",
    "print(\"dec=\",dec)\n",
    "print(\"mean dec=\",np.mean(dec,axis=0))\n",
    "print(\"var dec=\",np.var(dec,axis=0))\n",
    "print(\"loss=\",lossnp)\n",
    "print(\"normalized decoder = \",normnp)\n",
    "\n",
    "sess.close()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n## test\\n# construct the graph:\\ntf.reset_default_graph()\\n# define input dimension\\nn2 = 5 # layer size\\n# symbolic call to function\\nW0,W1,wsig,w0z,w0u,w0zu,w0b,w1z,w1u,w1zu,w1b = init_weights_combiner_vanilla(n2, scope=\"test\",verbose=True)\\n\\ninit_op = tf.global_variables_initializer() \\n\\n# run the graph\\nsess = tf.Session()\\nsess.run(init_op) #initialization on the concrete realization of the graph\\n\\nW0r,W1r,wsigr,w0zr,w0ur,w0zur,w0br,w1zr,w1ur,w1zur,w1br = sess.run(fetches=(W0,W1,wsig,w0z,w0u,w0zu,w0b,w1z,w1u,w1zu,w1b)) #Evaluation result from fct my_combiner_w\\nprint(\"W0=\",W0r)\\nprint(\"w0b3=\",w0br)\\nprint(\"w0z3=\",w0zr)\\nprint(\"w0u3=\",w0ur)\\nprint(\"w0zu3=\",w0zur)\\nprint(\"w1b3=\",w1br)\\nprint(\"w1z3=\",w1zr)\\nprint(\"w1u3=\",w1ur)\\nprint(\"w1zu3=\",w1zur)\\n\\nsess.close()\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights_combiner_vanilla(n2, scope,verbose):\n",
    "    with tf.variable_scope(scope) as v_scope:\n",
    "        # define auxiliary tensors for convenience\n",
    "        ze1 = tf.zeros(n2)\n",
    "        on1 = tf.ones(n2)  # used for lateral weight intitializing\n",
    "        ze = tf.zeros([n2,1])\n",
    "        on = tf.ones([n2,1])\n",
    "\n",
    "        # construct weight matrices by concatinating one-dimensional 0- and 1-tensors\n",
    "        # W0 for the first combiner-part (in front of sigmoid)\n",
    "        W0init = tf.concat([ze, on, ze, ze], 1) ##[bias, z_lat ,u_ver, zu]\n",
    "        # W1 for the inner of sigmoid providing the 2. combiner-part\n",
    "        W1init = tf.concat([ze,on,ze,ze],1)\n",
    "\n",
    "        # define weight matirces as initialized variables\n",
    "        # NOTE: HERE I HAVE CORRECTED A MISTAKE \n",
    "        # make sure to define is as a 1 dim tensor such that the tf.multiply works later on\n",
    "        wsig_ =  tf.Variable(on1, name = 'wsig_')\n",
    "        W0_ = tf.Variable(W0init, name = 'W0_')\n",
    "        W1_ = tf.Variable(W1init, name = 'W1_')\n",
    "        \n",
    "        # use the function tf.slice to extract the columns of the weight matrices W0_and W1_\n",
    "        # so that we can follow the weight development for debugging\n",
    "        # note: assign names under the given scope\n",
    "        # size=[4,1] indicates that we extract 4 rows witin one col starting from begin-pos\n",
    "        W0b_ = tf.slice(W0_,begin=[0,0],size=[4,1],name= 'W0b_')\n",
    "        W0z_ = tf.slice(W0_,begin=[0,1],size=[4,1],name= 'W0z_')\n",
    "        W0u_ = tf.slice(W0_,begin=[0,2],size=[4,1],name= 'W0u_')\n",
    "        W0zu_ = tf.slice(W0_,begin=[0,3],size=[4,1],name= 'W0zu_')\n",
    "        \n",
    "        W1b_ = tf.slice(W1_,begin=[0,0],size=[4,1],name= 'W1b_')\n",
    "        W1z_ = tf.slice(W1_,begin=[0,1],size=[4,1],name= 'W1z_')\n",
    "        W1u_ = tf.slice(W1_,begin=[0,2],size=[4,1],name= 'W1u_')\n",
    "        W1zu_ = tf.slice(W1_,begin=[0,3],size=[4,1],name= 'W1zu_')\n",
    "        \n",
    "    # add all column variables to the summary in order to display them on tensor board\n",
    "    # note: adding to the summary is done outsid the scope. \n",
    "    # Once the pointers to the variables exist, we can address them also outside the scope.\n",
    "    # if we do it inside the scope we end up generating one more scope level.\n",
    "    for v in [W0z_,W0u_,W0zu_,W0b_,W1z_,W1u_,W1zu_,W1b_]:\n",
    "            tf.summary.histogram(v.name,v)\n",
    "\n",
    "        \n",
    "    return W0_,W1_,wsig_,W0z_,W0u_,W0zu_,W0b_,W1z_,W1u_,W1zu_,W1b_\n",
    "        #return W0_,W1_,wsig_\n",
    "    \n",
    "\n",
    "'''\n",
    "## test\n",
    "# construct the graph:\n",
    "tf.reset_default_graph()\n",
    "# define input dimension\n",
    "n2 = 5 # layer size\n",
    "# symbolic call to function\n",
    "W0,W1,wsig,w0z,w0u,w0zu,w0b,w1z,w1u,w1zu,w1b = init_weights_combiner_vanilla(n2, scope=\"test\",verbose=True)\n",
    "\n",
    "init_op = tf.global_variables_initializer() \n",
    "\n",
    "# run the graph\n",
    "sess = tf.Session()\n",
    "sess.run(init_op) #initialization on the concrete realization of the graph\n",
    "\n",
    "W0r,W1r,wsigr,w0zr,w0ur,w0zur,w0br,w1zr,w1ur,w1zur,w1br = sess.run(fetches=(W0,W1,wsig,w0z,w0u,w0zu,w0b,w1z,w1u,w1zu,w1b)) #Evaluation result from fct my_combiner_w\n",
    "print(\"W0=\",W0r)\n",
    "print(\"w0b3=\",w0br)\n",
    "print(\"w0z3=\",w0zr)\n",
    "print(\"w0u3=\",w0ur)\n",
    "print(\"w0zu3=\",w0zur)\n",
    "print(\"w1b3=\",w1br)\n",
    "print(\"w1z3=\",w1zr)\n",
    "print(\"w1u3=\",w1ur)\n",
    "print(\"w1zu3=\",w1zur)\n",
    "\n",
    "sess.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data read-in "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Either load small external MNIST data set when for working local on windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small data before split X.shape (4000, 784)\n",
      "small data before  y.shape (4000,)\n",
      "small data x_train.shape: (3000, 784)\n",
      "small data y_train.shape: (3000,)\n",
      "small data x_test.shape: (1000, 784)\n",
      "small data y_test.shape: (1000,)\n",
      "num_class: 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# upload mnist_4000.pkl.gz which we have used in the DL course to home\n",
    "# To be compatible with python3 and python2\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:\n",
    "    import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open('mnist_4000.pkl.gz', 'rb') as f:\n",
    "    if sys.version_info.major > 2:\n",
    "        (X,y) = pickle.load(f, encoding='latin1')\n",
    "    else:\n",
    "        (X,y) = pickle.load(f)\n",
    "PIXELS = len(X[0,0,0,:])\n",
    "\n",
    "# if images are not flatten (like in mnist) we need first to flatten them\n",
    "# now flatten images for fc ladder\n",
    "\n",
    "X = X.reshape([4000, 784])\n",
    "#X = X/255 # is already normalized\n",
    "\n",
    "print(\"small data before split X.shape\", X.shape)\n",
    "print(\"small data before  y.shape\", y.shape) \n",
    "\n",
    "x_train = X[0:3000]\n",
    "y_train = y[0:3000]\n",
    "x_test = X[3000:4000]\n",
    "y_test = y[3000:4000]\n",
    "\n",
    "\n",
    "print(\"small data x_train.shape:\", x_train.shape)\n",
    "print(\"small data y_train.shape:\",y_train.shape)\n",
    "print(\"small data x_test.shape:\",x_test.shape)\n",
    "print(\"small data y_test.shape:\",y_test.shape)\n",
    "\n",
    "num_class= len(np.unique(y))\n",
    "print(\"num_class:\",num_class)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Or load full MNIST dataset directly from internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom keras.datasets import mnist\\n\\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\\n\\n# if images are not flatten (like in mnist) we need first to flatten them\\n# now flatten images for fc ladder\\n\\nx_train = x_train.reshape(-1,784)\\nx_test = x_test.reshape(-1,784)\\n\\nprint(\"large data x_train.shape:\", x_train.shape)\\nprint(\"large data y_train.shape:\",y_train.shape)\\nprint(\"large data x_test.shape:\",x_test.shape)\\nprint(\"large data x_test.shape:\",y_test.shape)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# if images are not flatten (like in mnist) we need first to flatten them\n",
    "# now flatten images for fc ladder\n",
    "\n",
    "x_train = x_train.reshape(-1,784)\n",
    "x_test = x_test.reshape(-1,784)\n",
    "\n",
    "print(\"large data x_train.shape:\", x_train.shape)\n",
    "print(\"large data y_train.shape:\",y_train.shape)\n",
    "print(\"large data x_test.shape:\",x_test.shape)\n",
    "print(\"large data x_test.shape:\",y_test.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 670.,   93.,   10.,    5.,    3.,    0.,    1.,    0.,    1.,    1.]),\n",
       " array([ -1.09939373,   0.31879865,   1.73699102,   3.1551834 ,\n",
       "          4.57337577,   5.99156815,   7.40976052,   8.8279529 ,\n",
       "         10.24614527,  11.66433765,  13.08253002]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f67952f3da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check if input data are normalized \n",
    "plt.hist(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83271211"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(x_train[:,200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 784)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Start the coding towards fc ladder network\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Architecture of the network\n",
    "\n",
    "**Architecture:**\n",
    "\n",
    "We start with a simple fc NN with an encoder including softmax output and and decoder with same-sized layers as used in the encoder. \n",
    "\n",
    "x:h0:784 -> h1:500 -> h2:50 -> h3:10 (softmax) d3':10 -> d2':50' -> d1':500' -> d0':x':784'\n",
    "\n",
    "**Subarchitecture of a single layer:**\n",
    "\n",
    "Each layer in the encoder and decoder is composed of different sequential steps as nicely illustrated in Fig1 of  https://arxiv.org/abs/1511.06430.\n",
    "\n",
    "Within one encoder layer hi (linear trafo, normalization, noise, batch-norm, non-linear-trafo): \n",
    "\n",
    "hi_lt -> hi_norm -> hi_noise -> hi_bn -> hi_nlt\n",
    "\n",
    "within one decoder layer di (combiner, linear-trafo, normalization):\n",
    "\n",
    "di_comb -> di_lt -> di_norm\n",
    "\n",
    "**Loss:**\n",
    "\n",
    "We want to have a supervised loss from label (armax-softmax vs true_label) prediction plus a unsupervised loss from reconstruction of each layer (hi_noise vs di_comb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# initialize weight matrices for encoder & decoder: \n",
    "# init_weights_v2(layers, layer_level, min_w, max_w, decoder, scope)\n",
    "# input:\n",
    "# layers (holding number number of nodes in each layer of the fc NN)\n",
    "# layer_level (defines the layer from which we start)\n",
    "# min_w (holds the min value of the random_uniform distribution)\n",
    "# max_w (holds the min value of the random_uniform distribution)\n",
    "# decoder (decoder=0 to initialize weights for the encoder, =1 to initialize decoder), scope (for naming)\n",
    "# scope (for naming)\n",
    "# output: W (weight matrices for linear trafo), B (offsets in batchnorm)\n",
    "# only offset Bs are used as offset in batchnorm (no scales in bn since we use ReLu)\n",
    "##################################################################################\n",
    "def init_weights_v2(layers, layer_level, min_w, max_w, decoder, scope):\n",
    "    with tf.variable_scope(scope) as v_scope:\n",
    "        # shape of W and B needs to be different for encoder or decoder: \n",
    "        # if decoder=0 a=layer_level-1 and b=layer_level, if decoder=1, a=layer_level and b=layer_level-1\n",
    "        a = layer_level - 1*(1-decoder) \n",
    "        b = layer_level - 1*decoder\n",
    "        W = tf.Variable(tf.random_uniform([layers[a], layers[b]], minval=min_w, maxval=max_w), name=\"weights_lt\")  \n",
    "        B = tf.Variable(tf.zeros(layers[b]), name=\"offset_bn\")\n",
    "        return W,B\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Set some parameters for the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0 has size 784\n",
      "layer 1 has size 500\n",
      "layer 2 has size 50\n",
      "layer 3 has size 10\n"
     ]
    }
   ],
   "source": [
    "# define sizes of layers\n",
    "L0 = 784  # first layer holds input \n",
    "L1 = 500\n",
    "L2 = 50\n",
    "L3 = 10   # last layer holds activations before softmax prediction of labels\n",
    "\n",
    "# layers is a list holding the size of all layers in the fc NN\n",
    "layers=[L0, L1, L2, L3]\n",
    "\n",
    "for i in range(len(layers)):\n",
    "    print(\"layer {} has size {}\".format(i,layers[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# standard deviation for added noise for purly supervised benchmark !!\n",
    "sd_noise = 0.05  # set as floating number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# set values for weighted sum of reconstruction loss in our 4 layers:\n",
    "#weights_reconstruction = [100.0, 10.0, 0.1, 0.1]\n",
    "weights_reconstruction = [0.1, 0.05, 0.01, 0.01]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Start the graph construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# reset the default graph\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define placeholder which we need later to feed in our data:\n",
    "# tf.set_random_seed(1)\n",
    "## TODO normalize input\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784], name='x_data')\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, 10], name='y_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name var_comb_0/W0z_:0 is illegal; using var_comb_0/W0z__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_0/W0u_:0 is illegal; using var_comb_0/W0u__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_0/W0zu_:0 is illegal; using var_comb_0/W0zu__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_0/W0b_:0 is illegal; using var_comb_0/W0b__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_0/W1z_:0 is illegal; using var_comb_0/W1z__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_0/W1u_:0 is illegal; using var_comb_0/W1u__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_0/W1zu_:0 is illegal; using var_comb_0/W1zu__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_0/W1b_:0 is illegal; using var_comb_0/W1b__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_1/W0z_:0 is illegal; using var_comb_1/W0z__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_1/W0u_:0 is illegal; using var_comb_1/W0u__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_1/W0zu_:0 is illegal; using var_comb_1/W0zu__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_1/W0b_:0 is illegal; using var_comb_1/W0b__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_1/W1z_:0 is illegal; using var_comb_1/W1z__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_1/W1u_:0 is illegal; using var_comb_1/W1u__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_1/W1zu_:0 is illegal; using var_comb_1/W1zu__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_1/W1b_:0 is illegal; using var_comb_1/W1b__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_2/W0z_:0 is illegal; using var_comb_2/W0z__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_2/W0u_:0 is illegal; using var_comb_2/W0u__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_2/W0zu_:0 is illegal; using var_comb_2/W0zu__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_2/W0b_:0 is illegal; using var_comb_2/W0b__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_2/W1z_:0 is illegal; using var_comb_2/W1z__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_2/W1u_:0 is illegal; using var_comb_2/W1u__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_2/W1zu_:0 is illegal; using var_comb_2/W1zu__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_2/W1b_:0 is illegal; using var_comb_2/W1b__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_3/W0z_:0 is illegal; using var_comb_3/W0z__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_3/W0u_:0 is illegal; using var_comb_3/W0u__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_3/W0zu_:0 is illegal; using var_comb_3/W0zu__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_3/W0b_:0 is illegal; using var_comb_3/W0b__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_3/W1z_:0 is illegal; using var_comb_3/W1z__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_3/W1u_:0 is illegal; using var_comb_3/W1u__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_3/W1zu_:0 is illegal; using var_comb_3/W1zu__0 instead.\n",
      "INFO:tensorflow:Summary name var_comb_3/W1b_:0 is illegal; using var_comb_3/W1b__0 instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#######################\\n## test dimensions for init_weights \\n## TODO muss neu gemacht werden fuer init_weights_!!!\\ninit_op = tf.global_variables_initializer() \\n\\n\\n# run the graph\\nsess = tf.Session()\\nsess.run(init_op) #initialization on the concrete realization of the graph\\n\\n#W3res,WD3res,WC03res, W0u3res = sess.run(fetches=(W3,WD3,WC03, WC0u3)) \\n\\nW3res,WD3res,WC03res, W0z3res, W0u3res, W0zu3res, W0b3res,W1z3res, W1u3res, W1zu3res, W1b3res = sess.run(fetches=(W3,WD3,WC03, W0z3, W0u3, W0zu3, W0b3,W1z3, W1u3, W1zu3, W1b3)) \\n\\n\\nprint(np.shape(W3res))\\nprint(np.shape(WD3res))\\nprint(np.shape(WC03res))\\n\\nprint(\"WC03res=\",WC03res)\\nprint(\"w0z3=\",W0z3res)\\nprint(\"w0u3=\",W0u3res)\\nprint(\"w0zu3=\",W0zu3res)\\nprint(\"w0b3=\",W0b3res)\\nprint(\"w1z3=\",W1z3res)\\nprint(\"w1u3=\",W1u3res)\\nprint(\"w1zu3=\",W1zu3res)\\nprint(\"w1b3=\",W1b3res)\\n\\nsess.close()\\n\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Using the customized functions for initialization ######\n",
    "##############################################################\n",
    "# initialization of learnable variables \n",
    "# predefine intialization of variables which are updated during trianing:\n",
    "# we use no biases since we do batchnorm (following Martin Görner)\n",
    "# Bs are used as offset in batchnorm (no scales in bn since we use ReLu)\n",
    "\n",
    "# learnable variables in encoder, W is for linear transformation (w/o bias), B for batch-norm (w/o scaling) \n",
    "# (encoder is selected by setting argument decoder=0):\n",
    "W1,  B1 = init_weights_v2(layers, layer_level=1, min_w=-0.05, max_w=0.05, decoder=0, scope=\"var_enc_1\")\n",
    "W2,  B2 = init_weights_v2(layers, layer_level=2, min_w=-0.05, max_w=0.05, decoder=0, scope=\"var_enc_2\")\n",
    "W3,  B3 = init_weights_v2(layers, layer_level=3, min_w=-0.05, max_w=0.05, decoder=0, scope=\"var_enc_3\")\n",
    "\n",
    "# learnable variables in decoder:\n",
    "WD1,  BD1 = init_weights_v2(layers, layer_level=1, min_w=-0.05, max_w=0.05, decoder=1, scope=\"var_dec_1\")\n",
    "WD2,  BD2 = init_weights_v2(layers, layer_level=2, min_w=-0.05, max_w=0.05, decoder=1, scope=\"var_dec_2\")\n",
    "WD3,  BD3 = init_weights_v2(layers, layer_level=3, min_w=-0.05, max_w=0.05, decoder=1, scope=\"var_dec_3\")\n",
    "\n",
    "# learnable variables in vanilla combiner:\n",
    "\n",
    "## verbose version  for debugging: extract separate matrix columns fo the WC0 and WC1 weights\n",
    "WC00, WC10, WCsig0, W0z0, W0u0, W0zu0, W0b0, W1z0, W1u0, W1zu0, W1b0 = init_weights_combiner_vanilla(layers[0], \n",
    "                                                                                                     scope=\"var_comb_0\",\n",
    "                                                                                                     verbose=True)\n",
    "WC01, WC11, WCsig1, W0z1, W0u1, W0zu1, W0b1, W1z1, W1u1, W1zu1, W1b1 = init_weights_combiner_vanilla(layers[1], \n",
    "                                                                                                     scope=\"var_comb_1\",\n",
    "                                                                                                     verbose=True)\n",
    "WC02, WC12, WCsig2, W0z2, W0u2, W0zu2, W0b2, W1z2, W1u2, W1zu2, W1b2 = init_weights_combiner_vanilla(layers[2], \n",
    "                                                                                                     scope=\"var_comb_2\",\n",
    "                                                                                                     verbose=True)\n",
    "WC03, WC13, WCsig3, W0z3, W0u3, W0zu3, W0b3, W1z3, W1u3, W1zu3, W1b3 = init_weights_combiner_vanilla(layers[3], \n",
    "                                                                                                     scope=\"var_comb_3\",\n",
    "                                                                                                   verbose=True)\n",
    "'''\n",
    "#######################\n",
    "## test dimensions for init_weights \n",
    "## TODO muss neu gemacht werden fuer init_weights_!!!\n",
    "init_op = tf.global_variables_initializer() \n",
    "\n",
    "\n",
    "# run the graph\n",
    "sess = tf.Session()\n",
    "sess.run(init_op) #initialization on the concrete realization of the graph\n",
    "\n",
    "#W3res,WD3res,WC03res, W0u3res = sess.run(fetches=(W3,WD3,WC03, WC0u3)) \n",
    "\n",
    "W3res,WD3res,WC03res, W0z3res, W0u3res, W0zu3res, W0b3res,W1z3res, W1u3res, W1zu3res, W1b3res = sess.run(fetches=(W3,WD3,WC03, W0z3, W0u3, W0zu3, W0b3,W1z3, W1u3, W1zu3, W1b3)) \n",
    "\n",
    "\n",
    "print(np.shape(W3res))\n",
    "print(np.shape(WD3res))\n",
    "print(np.shape(WC03res))\n",
    "\n",
    "print(\"WC03res=\",WC03res)\n",
    "print(\"w0z3=\",W0z3res)\n",
    "print(\"w0u3=\",W0u3res)\n",
    "print(\"w0zu3=\",W0zu3res)\n",
    "print(\"w0b3=\",W0b3res)\n",
    "print(\"w1z3=\",W1z3res)\n",
    "print(\"w1u3=\",W1u3res)\n",
    "print(\"w1zu3=\",W1zu3res)\n",
    "print(\"w1b3=\",W1b3res)\n",
    "\n",
    "sess.close()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### construct clean and noisy encoders  ######\n",
    "\n",
    "x = my_norm(x, \"initial_z_trafo\")\n",
    "\n",
    "#############################################\n",
    "# clean or noisy encoder construction  - general fcn encoder_prop(h_in, W, B, noise, scope)\n",
    "# input: h_in: signal from below, W: for the linear trafo, B: offset in bn, noise: None (in clean encoder) or sd_noise-value\n",
    "# output: hn_lt, hn_norm, hn_noise, hn_bn, hn_nlt\n",
    "###################################################\n",
    "\n",
    "#############################################\n",
    "# noisy encoder construction start\n",
    "# same weight matrices and biases as in clean encoder\n",
    "###################################################\n",
    "# we start with noisy input\n",
    "xn = my_noise(x, sd_noise, \"x_plus_noise\")\n",
    "# in intermediate layer we need in noisy encoder *_noise as lat-input to combiner of decoder\n",
    "# and *_nlt as input to next layer of the noisy encoder\n",
    "_, _, hn_1_noise, _, hn_1_nlt = encoder_prop(    x   , W=W1, B=B1, noise=sd_noise, scope=\"n_encoder_1\")\n",
    "_, _, hn_2_noise, _, hn_2_nlt = encoder_prop(hn_1_nlt, W=W2, B=B2, noise=sd_noise, scope=\"n_encoder_2\")\n",
    "# in last layer we need *_noise as lat-input to combiner of decoder \n",
    "# and *_bn as input to softmax and input to norm for ver-input of combiner\n",
    "_, _, hn_3_noise, hn_3_bn, _ = encoder_prop(hn_2_nlt, W=W3, B=B3, noise=sd_noise, scope=\"n_encoder_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# clean encoder construction start\n",
    "# same weight matrices and biases as in noisy encoder\n",
    "###################################################\n",
    "\n",
    "# in intermediate layer we need in clean encoder *_norm for reconstruction costs \n",
    "# and *_nlt as input to next layer\n",
    "_, h_1_norm, _, _, h_1_nlt = encoder_prop(     x , W=W1, B=B1, noise=None, scope=\"cl_encoder_1\")\n",
    "_, h_2_norm, _, _, h_2_nlt = encoder_prop(h_1_nlt, W=W2, B=B2, noise=None, scope=\"cl_encoder_2\")\n",
    "# in last layer we need *_norm for reconstruction costs \n",
    "# but *_bn as input to softmax\n",
    "_, h_3_norm, _, h_3_bn, _ = encoder_prop(h_2_nlt, W=W3, B=B3, noise=None, scope=\"cl_encoder_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#######################\\n## test dimensions\\ninit_op = tf.global_variables_initializer() \\n\\n\\n# run the graph\\nsess = tf.Session()\\nsess.run(init_op) #initialization on the concrete realization of the graph\\n# input: batch of size nb\\nnb = 4\\nprint(x_train[0:nb].shape)  # (nb, 784)\\nprint(convertToOneHot(y_train[0:nb], 10).shape)  # (nb, 10)\\nh1res,h2res,h3res,hn1res,hn2res,hn3res = sess.run(fetches=(hn_1_nlt,hn_2_nlt,hn_3_bn,hn_1_noise,hn_2_noise,hn_3_noise), \\n                                                  feed_dict={x:x_train[0:nb], y_true:convertToOneHot(y_train[0:nb], 10) }) \\n\\nprint(np.shape(h1res))\\nprint(np.shape(h2res))\\nprint(np.shape(h3res))\\nprint(np.shape(hn1res))\\nprint(np.shape(hn2res))\\nprint(np.shape(hn3res))\\n\\nprint(\"output of corrupted encoder, after batch norm but before NL transformation:\")\\nprint(\"hn_3_bn=\",h3res)\\nsess.close()\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#######################\n",
    "## test dimensions\n",
    "init_op = tf.global_variables_initializer() \n",
    "\n",
    "\n",
    "# run the graph\n",
    "sess = tf.Session()\n",
    "sess.run(init_op) #initialization on the concrete realization of the graph\n",
    "# input: batch of size nb\n",
    "nb = 4\n",
    "print(x_train[0:nb].shape)  # (nb, 784)\n",
    "print(convertToOneHot(y_train[0:nb], 10).shape)  # (nb, 10)\n",
    "h1res,h2res,h3res,hn1res,hn2res,hn3res = sess.run(fetches=(hn_1_nlt,hn_2_nlt,hn_3_bn,hn_1_noise,hn_2_noise,hn_3_noise), \n",
    "                                                  feed_dict={x:x_train[0:nb], y_true:convertToOneHot(y_train[0:nb], 10) }) \n",
    "\n",
    "print(np.shape(h1res))\n",
    "print(np.shape(h2res))\n",
    "print(np.shape(h3res))\n",
    "print(np.shape(hn1res))\n",
    "print(np.shape(hn2res))\n",
    "print(np.shape(hn3res))\n",
    "\n",
    "print(\"output of corrupted encoder, after batch norm but before NL transformation:\")\n",
    "print(\"hn_3_bn=\",h3res)\n",
    "sess.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#############################################\n",
    "# decoder construction  - general fcn decoder_prop(h_lat, h_ver, W0comb, W1comb, wsigcomb, W, B, scope)\n",
    "# input: for combiner: h_lat, h_ver, W0comb, W1comb, wsigcomb, for linear-trafo: W, B, scope (naming for graf)\n",
    "# output: d_c (needed in reconstruction cost) , d_lt, d_norm\n",
    "###################################################\n",
    "\n",
    "# the lateral input is always the normalized layer with added noise\n",
    "# the vertical input is the normalized signal from above (in upperst layer the my_norm(*_bn) that was input to softmax)\n",
    "\n",
    "# in all decoder layer we need the outputs *_c for reconstruction cost\n",
    "# and *_norm as vertical input in combiner of next lower layer\n",
    "\n",
    "d_3_c, _, d_3_norm = decoder_prop(h_lat=hn_3_noise, h_ver=my_norm(hn_3_bn, scope=\"normalize\"), \n",
    "                       W0comb=WC03, W1comb=WC13, wsigcomb=WCsig3,  W=WD3, B=BD3, scope=\"decoder_3\")\n",
    "\n",
    "d_2_c, _, d_2_norm = decoder_prop(h_lat=hn_2_noise, h_ver=d_3_norm, \n",
    "                        W0comb=WC02, W1comb=WC12, wsigcomb=WCsig2, W=WD2, B=BD2, scope=\"decoder_2\")\n",
    "\n",
    "d_1_c, _, d_1_norm = decoder_prop(h_lat=hn_1_noise,  h_ver=d_2_norm, \n",
    "                        W0comb=WC01, W1comb=WC11, wsigcomb=WCsig1, W=WD1, B=BD1, scope=\"decoder_1\")\n",
    "\n",
    "# last layer is only a combiner of lateral and horizontal input to get reconstructed image d_0_c\n",
    "d_0_c = my_comb_vanilla(lateral=xn, vertical=d_1_norm,\n",
    "                        W0=WC00, W1=WC10, wsig=WCsig0, scope=\"combiner_0\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#######################\\n## test dimensions of outcome of decoder_prop\\n\\ninit_op = tf.global_variables_initializer() \\n\\n# run the graph\\nsess = tf.Session()\\nsess.run(init_op) #initialization on the concrete realization of the graph\\n#print(x_train[0:2].shape)  # (2, 784)\\n#print(convertToOneHot(y_train[0:2], 10).shape)  # (2, 10)\\n# do not use tensor_names (?)\\nmy_x, h1_norm, h2_norm, h3_norm = sess.run(fetches=(x, h_1_norm, h_2_norm, h_3_norm), \\n                               feed_dict={x:x_train[0:2], y_true:convertToOneHot(y_train[0:2], 10) }) \\n\\nd3_c, d2_c, d1_c, d0_c = sess.run(fetches=(d_3_c, d_2_c, d_1_c, d_0_c), \\n                               feed_dict={x:x_train[0:2], y_true:convertToOneHot(y_train[0:2], 10) }) \\n\\nhn3_noise, hn2_noise, hn1_noise = sess.run(fetches=(hn_3_noise, hn_2_noise, hn_1_noise), \\n                               feed_dict={x:x_train[0:2], y_true:convertToOneHot(y_train[0:2], 10) }) \\n\\nhn3_bn, d3_norm = sess.run(fetches=(hn_3_bn, d_3_norm), \\n                               feed_dict={x:x_train[0:2], y_true:convertToOneHot(y_train[0:2], 10) }) \\n\\nprint(\"shape of my_x:\",np.shape(my_x))\\nprint(\"shape of  h1_norm layer:\",np.shape(h1_norm))\\nprint(\"shape of  h2_norm layer:\",np.shape(h2_norm))\\nprint(\"shape of  h3_norm layer:\",np.shape(h3_norm))\\n\\nprint(\"shape of d0_c layer:\",np.shape(d0_c))\\nprint(\"shape of d1_c layer:\",np.shape(d1_c))\\nprint(\"shape of d2_c layer:\",np.shape(d2_c))\\nprint(\"shape of d3_c layer:\",np.shape(d3_c))\\n\\nprint(\"shape of  hn3_bn layer:\",np.shape(hn3_bn))\\nprint(\"shape of  d3_norm:\",np.shape(d3_norm))\\n\\nprint(\"output of vanilla combiner:\")\\nprint(\"d_0_c = \",d0_c)\\nsess.close()\\n\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#######################\n",
    "## test dimensions of outcome of decoder_prop\n",
    "\n",
    "init_op = tf.global_variables_initializer() \n",
    "\n",
    "# run the graph\n",
    "sess = tf.Session()\n",
    "sess.run(init_op) #initialization on the concrete realization of the graph\n",
    "#print(x_train[0:2].shape)  # (2, 784)\n",
    "#print(convertToOneHot(y_train[0:2], 10).shape)  # (2, 10)\n",
    "# do not use tensor_names (?)\n",
    "my_x, h1_norm, h2_norm, h3_norm = sess.run(fetches=(x, h_1_norm, h_2_norm, h_3_norm), \n",
    "                               feed_dict={x:x_train[0:2], y_true:convertToOneHot(y_train[0:2], 10) }) \n",
    "\n",
    "d3_c, d2_c, d1_c, d0_c = sess.run(fetches=(d_3_c, d_2_c, d_1_c, d_0_c), \n",
    "                               feed_dict={x:x_train[0:2], y_true:convertToOneHot(y_train[0:2], 10) }) \n",
    "\n",
    "hn3_noise, hn2_noise, hn1_noise = sess.run(fetches=(hn_3_noise, hn_2_noise, hn_1_noise), \n",
    "                               feed_dict={x:x_train[0:2], y_true:convertToOneHot(y_train[0:2], 10) }) \n",
    "\n",
    "hn3_bn, d3_norm = sess.run(fetches=(hn_3_bn, d_3_norm), \n",
    "                               feed_dict={x:x_train[0:2], y_true:convertToOneHot(y_train[0:2], 10) }) \n",
    "\n",
    "print(\"shape of my_x:\",np.shape(my_x))\n",
    "print(\"shape of  h1_norm layer:\",np.shape(h1_norm))\n",
    "print(\"shape of  h2_norm layer:\",np.shape(h2_norm))\n",
    "print(\"shape of  h3_norm layer:\",np.shape(h3_norm))\n",
    "\n",
    "print(\"shape of d0_c layer:\",np.shape(d0_c))\n",
    "print(\"shape of d1_c layer:\",np.shape(d1_c))\n",
    "print(\"shape of d2_c layer:\",np.shape(d2_c))\n",
    "print(\"shape of d3_c layer:\",np.shape(d3_c))\n",
    "\n",
    "print(\"shape of  hn3_bn layer:\",np.shape(hn3_bn))\n",
    "print(\"shape of  d3_norm:\",np.shape(d3_norm))\n",
    "\n",
    "print(\"output of vanilla combiner:\")\n",
    "print(\"d_0_c = \",d0_c)\n",
    "sess.close()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nd_3_c, _, d_3_norm = decoder_prop_ver( h_ver=my_norm(hn_3_bn, scope=\"normalize\"), W=WD3, B=BD3, scope=\"decoder_3\")\\n\\nd_2_c, _, d_2_norm = decoder_prop_ver(h_ver=d_3_norm, W=WD2, B=BD2, scope=\"decoder_2\")\\n\\nd_1_c, _, d_1_norm = decoder_prop_ver(h_ver=d_2_norm, W=WD1, B=BD1, scope=\"decoder_1\")\\n\\n# reconstructed image d_0_c\\nd_0_c = d_1_norm\\n          \\n\\n## TEST\\ninit_op = tf.global_variables_initializer() \\n# run the graph\\nsess = tf.Session()\\nsess.run(init_op) #initialization on the concrete realization of the graph\\n#print(x_train[0:2].shape)  # (2, 784)\\n#print(convertToOneHot(y_train[0:2], 10).shape)  # (2, 10)\\n# do not use tensor_names (?)\\nmy_x, h1_norm, h2_norm, h3_norm = sess.run(fetches=(x, h_1_norm, h_2_norm, h_3_norm), \\n                               feed_dict={x:x_train[0:2], y_true:convertToOneHot(y_train[0:2], 10) }) \\n\\nd3_c, d2_c, d1_c, d0_c = sess.run(fetches=(d_3_c, d_2_c, d_1_c, d_0_c), \\n                               feed_dict={x:x_train[0:2], y_true:convertToOneHot(y_train[0:2], 10) }) \\n\\nhn3_noise, hn2_noise, hn1_noise = sess.run(fetches=(hn_3_noise, hn_2_noise, hn_1_noise), \\n                               feed_dict={x:x_train[0:2], y_true:convertToOneHot(y_train[0:2], 10) }) \\n\\nhn3_bn, d3_norm = sess.run(fetches=(hn_3_bn, d_3_norm), \\n                               feed_dict={x:x_train[0:2], y_true:convertToOneHot(y_train[0:2], 10) }) \\n\\nprint(\"shape of my_x:\",np.shape(my_x))\\nprint(\"shape of  h1_norm layer:\",np.shape(h1_norm))\\nprint(\"shape of  h2_norm layer:\",np.shape(h2_norm))\\nprint(\"shape of  h3_norm layer:\",np.shape(h3_norm))\\n\\nprint(\"shape of d0_c layer:\",np.shape(d0_c))\\nprint(\"shape of d1_c layer:\",np.shape(d1_c))\\nprint(\"shape of d2_c layer:\",np.shape(d2_c))\\nprint(\"shape of d3_c layer:\",np.shape(d3_c))\\n\\nprint(\"shape of  hn3_bn layer:\",np.shape(hn3_bn))\\nprint(\"shape of  d3_norm:\",np.shape(d3_norm))\\n\\nprint(\"d_0_c = \",d0_c)\\nsess.close()\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## DEBUG: TRY DECODER WITH ONLY VERTICAL INPUT \n",
    "## SET LOSS TO UNSUPERVISED ONLY AND ONLY FINAL RECONSTRUCTION\n",
    "## ==> NO LEARNING. TRAINING LOSS FLUCTUATES SLIGHTLY, VALIDATION LOSS EVEN LESS...\n",
    "'''\n",
    "d_3_c, _, d_3_norm = decoder_prop_ver( h_ver=my_norm(hn_3_bn, scope=\"normalize\"), W=WD3, B=BD3, scope=\"decoder_3\")\n",
    "\n",
    "d_2_c, _, d_2_norm = decoder_prop_ver(h_ver=d_3_norm, W=WD2, B=BD2, scope=\"decoder_2\")\n",
    "\n",
    "d_1_c, _, d_1_norm = decoder_prop_ver(h_ver=d_2_norm, W=WD1, B=BD1, scope=\"decoder_1\")\n",
    "\n",
    "# reconstructed image d_0_c\n",
    "d_0_c = d_1_norm\n",
    "          \n",
    "\n",
    "## TEST\n",
    "init_op = tf.global_variables_initializer() \n",
    "# run the graph\n",
    "sess = tf.Session()\n",
    "sess.run(init_op) #initialization on the concrete realization of the graph\n",
    "#print(x_train[0:2].shape)  # (2, 784)\n",
    "#print(convertToOneHot(y_train[0:2], 10).shape)  # (2, 10)\n",
    "# do not use tensor_names (?)\n",
    "my_x, h1_norm, h2_norm, h3_norm = sess.run(fetches=(x, h_1_norm, h_2_norm, h_3_norm), \n",
    "                               feed_dict={x:x_train[0:2], y_true:convertToOneHot(y_train[0:2], 10) }) \n",
    "\n",
    "d3_c, d2_c, d1_c, d0_c = sess.run(fetches=(d_3_c, d_2_c, d_1_c, d_0_c), \n",
    "                               feed_dict={x:x_train[0:2], y_true:convertToOneHot(y_train[0:2], 10) }) \n",
    "\n",
    "hn3_noise, hn2_noise, hn1_noise = sess.run(fetches=(hn_3_noise, hn_2_noise, hn_1_noise), \n",
    "                               feed_dict={x:x_train[0:2], y_true:convertToOneHot(y_train[0:2], 10) }) \n",
    "\n",
    "hn3_bn, d3_norm = sess.run(fetches=(hn_3_bn, d_3_norm), \n",
    "                               feed_dict={x:x_train[0:2], y_true:convertToOneHot(y_train[0:2], 10) }) \n",
    "\n",
    "print(\"shape of my_x:\",np.shape(my_x))\n",
    "print(\"shape of  h1_norm layer:\",np.shape(h1_norm))\n",
    "print(\"shape of  h2_norm layer:\",np.shape(h2_norm))\n",
    "print(\"shape of  h3_norm layer:\",np.shape(h3_norm))\n",
    "\n",
    "print(\"shape of d0_c layer:\",np.shape(d0_c))\n",
    "print(\"shape of d1_c layer:\",np.shape(d1_c))\n",
    "print(\"shape of d2_c layer:\",np.shape(d2_c))\n",
    "print(\"shape of d3_c layer:\",np.shape(d3_c))\n",
    "\n",
    "print(\"shape of  hn3_bn layer:\",np.shape(hn3_bn))\n",
    "print(\"shape of  d3_norm:\",np.shape(d3_norm))\n",
    "\n",
    "print(\"d_0_c = \",d0_c)\n",
    "sess.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# loss has several parts for supervised and unsupervised (reconstruction ) task\n",
    "############################################################################\n",
    "\n",
    "# cross-entropy loss function (= -sum(Y_i * log(Yi)) ), \n",
    "# TensorFlow provides the softmax_cross_entropy_with_logits function to avoid numerical stability\n",
    "# problems with log(0) which is NaN\n",
    "\n",
    "with tf.name_scope(\"loss_supervised\"):\n",
    "    out = tf.nn.softmax(hn_3_bn)  # TODO : IS THIS ERROR PRONE? \n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=hn_3_bn, labels=y_true)\n",
    "    # loss from supervised learning:\n",
    "    loss_supervised = tf.reduce_mean(cross_entropy) \n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    which_y_true = tf.argmax(y_true, 1)\n",
    "    which_y_pred = tf.argmax(tf.nn.softmax(hn_3_bn), 1)\n",
    "    correct_prediction = tf.equal(which_y_true, which_y_pred)  # no of correct predictions\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'squared_dist/Mean:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconst_loss(encoder_clean=x, decoder=d_0_c, scope=\"dist_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# loss unsupervised per layer  - by fcn reconst_loss(encoder_clean, decoder, scope):\n",
    "# input: encoder_clean, decoder (same shape than encoder_clean), scope\n",
    "# output: loss_reconst (squared Euclidean distance between clean encoder layer and corresponding decoder layer)\n",
    "\n",
    "with tf.name_scope(\"loss_reconstruction\"):\n",
    "    loss_us_layer_0 = reconst_loss(encoder_clean=x, decoder=d_0_c, scope=\"dist_0\")\n",
    "    loss_us_layer_1 = reconst_loss(encoder_clean=h_1_norm, decoder=d_1_c, scope=\"dist_1\")\n",
    "    loss_us_layer_2 = reconst_loss(encoder_clean=h_2_norm, decoder=d_2_c, scope=\"dist_2\")\n",
    "    loss_us_layer_3 = reconst_loss(encoder_clean=h_3_norm, decoder=d_3_c, scope=\"dist_3\")\n",
    "        \n",
    "    with tf.name_scope(\"add_all_dist\"):\n",
    "        loss_unsupervised = weights_reconstruction[0]*loss_us_layer_0  + weights_reconstruction[1]*loss_us_layer_1  + weights_reconstruction[2]*loss_us_layer_2    + weights_reconstruction[3]*loss_us_layer_3   \n",
    "        #loss_unsupervised = weights_reconstruction[0]*loss_us_layer_0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#######################\\n## test unsupervised loss calculation\\n\\ninit_op = tf.global_variables_initializer() \\n\\n# run the graph\\nnb = 2\\nsess = tf.Session()\\nsess.run(init_op) #initialization on the concrete realization of the graph\\n\\nd3_c, d2_c, d1_c, d0_c, h1_norm, h2_norm = sess.run(fetches=(d_3_c, d_2_c, d_1_c, d_0_c,  h_1_norm, h_2_norm), \\n                               feed_dict={x:x_train[0:nb], y_true:convertToOneHot(y_train[0:nb], 10) }) \\nmy_x,my_loss_us0,my_loss_us1,my_loss_us2,my_loss_us3,loss_us_tot =  sess.run(fetches=(x,loss_us_layer_0,loss_us_layer_1,loss_us_layer_2,loss_us_layer_3,loss_unsupervised), \\n                               feed_dict={x:x_train[0:nb], y_true:convertToOneHot(y_train[0:nb], 10)  }) \\n\\n\\n\\nprint(\"output of vanilla combiner:\")\\nprint(\"d_0_c = \",d0_c)\\nprint(\"shape of  x:\",np.shape(my_x))\\nprint(\"shape of  d0_c:\",np.shape(d0_c))\\n#print(\"shape of  loss_us0:\",np.shape(my_loss_us0))\\n#print(\"shape of  loss_us1:\",np.shape(my_loss_us1))\\nprint(\"loss_us0=\",my_loss_us0)\\nprint(\"loss_us1=\",my_loss_us1)\\nprint(\"loss_us2=\",my_loss_us2)\\nprint(\"loss_us3=\",my_loss_us3)\\nprint(\"loss_us_tot=\",loss_us_tot)\\nprint(\"w_reconst=\",weights_reconstruction[3]*my_loss_us3)\\n\\n\\nsess.close()\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#######################\n",
    "## test unsupervised loss calculation\n",
    "\n",
    "init_op = tf.global_variables_initializer() \n",
    "\n",
    "# run the graph\n",
    "nb = 2\n",
    "sess = tf.Session()\n",
    "sess.run(init_op) #initialization on the concrete realization of the graph\n",
    "\n",
    "d3_c, d2_c, d1_c, d0_c, h1_norm, h2_norm = sess.run(fetches=(d_3_c, d_2_c, d_1_c, d_0_c,  h_1_norm, h_2_norm), \n",
    "                               feed_dict={x:x_train[0:nb], y_true:convertToOneHot(y_train[0:nb], 10) }) \n",
    "my_x,my_loss_us0,my_loss_us1,my_loss_us2,my_loss_us3,loss_us_tot =  sess.run(fetches=(x,loss_us_layer_0,loss_us_layer_1,loss_us_layer_2,loss_us_layer_3,loss_unsupervised), \n",
    "                               feed_dict={x:x_train[0:nb], y_true:convertToOneHot(y_train[0:nb], 10)  }) \n",
    "\n",
    "\n",
    "\n",
    "print(\"output of vanilla combiner:\")\n",
    "print(\"d_0_c = \",d0_c)\n",
    "print(\"shape of  x:\",np.shape(my_x))\n",
    "print(\"shape of  d0_c:\",np.shape(d0_c))\n",
    "#print(\"shape of  loss_us0:\",np.shape(my_loss_us0))\n",
    "#print(\"shape of  loss_us1:\",np.shape(my_loss_us1))\n",
    "print(\"loss_us0=\",my_loss_us0)\n",
    "print(\"loss_us1=\",my_loss_us1)\n",
    "print(\"loss_us2=\",my_loss_us2)\n",
    "print(\"loss_us3=\",my_loss_us3)\n",
    "print(\"loss_us_tot=\",loss_us_tot)\n",
    "print(\"w_reconst=\",weights_reconstruction[3]*my_loss_us3)\n",
    "\n",
    "\n",
    "sess.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss_both\"):    \n",
    "    loss_both = loss_supervised + loss_unsupervised \n",
    "    #loss_both = loss_unsupervised "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"initialize\"):\n",
    "    init_op = tf.global_variables_initializer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for nicer graph withou Optimizer in graph\n",
    "# Optimizer\n",
    "with tf.name_scope(\"train_step\"):\n",
    "    train_op = tf.train.GradientDescentOptimizer(0.01).minimize(loss_both)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Execute the graph and do some training¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding  var_enc_1/weights_lt:0\n",
      "INFO:tensorflow:Summary name var_enc_1/weights_lt:0 is illegal; using var_enc_1/weights_lt_0 instead.\n",
      "Adding  var_enc_1/offset_bn:0\n",
      "INFO:tensorflow:Summary name var_enc_1/offset_bn:0 is illegal; using var_enc_1/offset_bn_0 instead.\n",
      "Adding  var_enc_2/weights_lt:0\n",
      "INFO:tensorflow:Summary name var_enc_2/weights_lt:0 is illegal; using var_enc_2/weights_lt_0 instead.\n",
      "Adding  var_enc_2/offset_bn:0\n",
      "INFO:tensorflow:Summary name var_enc_2/offset_bn:0 is illegal; using var_enc_2/offset_bn_0 instead.\n",
      "Adding  var_enc_3/weights_lt:0\n",
      "INFO:tensorflow:Summary name var_enc_3/weights_lt:0 is illegal; using var_enc_3/weights_lt_0 instead.\n",
      "Adding  var_enc_3/offset_bn:0\n",
      "INFO:tensorflow:Summary name var_enc_3/offset_bn:0 is illegal; using var_enc_3/offset_bn_0 instead.\n",
      "Adding  var_dec_1/weights_lt:0\n",
      "INFO:tensorflow:Summary name var_dec_1/weights_lt:0 is illegal; using var_dec_1/weights_lt_0 instead.\n",
      "Adding  var_dec_1/offset_bn:0\n",
      "INFO:tensorflow:Summary name var_dec_1/offset_bn:0 is illegal; using var_dec_1/offset_bn_0 instead.\n",
      "Adding  var_dec_2/weights_lt:0\n",
      "INFO:tensorflow:Summary name var_dec_2/weights_lt:0 is illegal; using var_dec_2/weights_lt_0 instead.\n",
      "Adding  var_dec_2/offset_bn:0\n",
      "INFO:tensorflow:Summary name var_dec_2/offset_bn:0 is illegal; using var_dec_2/offset_bn_0 instead.\n",
      "Adding  var_dec_3/weights_lt:0\n",
      "INFO:tensorflow:Summary name var_dec_3/weights_lt:0 is illegal; using var_dec_3/weights_lt_0 instead.\n",
      "Adding  var_dec_3/offset_bn:0\n",
      "INFO:tensorflow:Summary name var_dec_3/offset_bn:0 is illegal; using var_dec_3/offset_bn_0 instead.\n",
      "Adding  var_comb_0/wsig_:0\n",
      "INFO:tensorflow:Summary name var_comb_0/wsig_:0 is illegal; using var_comb_0/wsig__0 instead.\n",
      "Adding  var_comb_0/W0_:0\n",
      "INFO:tensorflow:Summary name var_comb_0/W0_:0 is illegal; using var_comb_0/W0__0 instead.\n",
      "Adding  var_comb_0/W1_:0\n",
      "INFO:tensorflow:Summary name var_comb_0/W1_:0 is illegal; using var_comb_0/W1__0 instead.\n",
      "Adding  var_comb_1/wsig_:0\n",
      "INFO:tensorflow:Summary name var_comb_1/wsig_:0 is illegal; using var_comb_1/wsig__0 instead.\n",
      "Adding  var_comb_1/W0_:0\n",
      "INFO:tensorflow:Summary name var_comb_1/W0_:0 is illegal; using var_comb_1/W0__0 instead.\n",
      "Adding  var_comb_1/W1_:0\n",
      "INFO:tensorflow:Summary name var_comb_1/W1_:0 is illegal; using var_comb_1/W1__0 instead.\n",
      "Adding  var_comb_2/wsig_:0\n",
      "INFO:tensorflow:Summary name var_comb_2/wsig_:0 is illegal; using var_comb_2/wsig__0 instead.\n",
      "Adding  var_comb_2/W0_:0\n",
      "INFO:tensorflow:Summary name var_comb_2/W0_:0 is illegal; using var_comb_2/W0__0 instead.\n",
      "Adding  var_comb_2/W1_:0\n",
      "INFO:tensorflow:Summary name var_comb_2/W1_:0 is illegal; using var_comb_2/W1__0 instead.\n",
      "Adding  var_comb_3/wsig_:0\n",
      "INFO:tensorflow:Summary name var_comb_3/wsig_:0 is illegal; using var_comb_3/wsig__0 instead.\n",
      "Adding  var_comb_3/W0_:0\n",
      "INFO:tensorflow:Summary name var_comb_3/W0_:0 is illegal; using var_comb_3/W0__0 instead.\n",
      "Adding  var_comb_3/W1_:0\n",
      "INFO:tensorflow:Summary name var_comb_3/W1_:0 is illegal; using var_comb_3/W1__0 instead.\n"
     ]
    }
   ],
   "source": [
    "#We want to visualize the development of the following variables in tensorboard:\n",
    "for v in tf.trainable_variables():\n",
    "    print(\"Adding \", v.name)\n",
    "    tf.summary.histogram(v.name, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'loss_us_layer_3:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want to visualize the development of losses in tensorboard\n",
    "\n",
    "#loss_both = loss_supervised + loss_unsupervised \n",
    "tf.summary.scalar(\"loss_both\", loss_both)\n",
    "tf.summary.scalar(\"loss_supervised\", loss_supervised)\n",
    "tf.summary.scalar(\"loss_unsupervised\", loss_unsupervised)\n",
    "tf.summary.scalar(\"loss_us_layer_0\", loss_us_layer_0)\n",
    "tf.summary.scalar(\"loss_us_layer_1\", loss_us_layer_1)\n",
    "tf.summary.scalar(\"loss_us_layer_2\", loss_us_layer_2)\n",
    "tf.summary.scalar(\"loss_us_layer_3\", loss_us_layer_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "! rm -rf /tmp/ladder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "! mkdir /tmp/ladder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "! ls /tmp/ladder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# collect all summaries for tensorboard and define the directory for saved summary files \n",
    "\n",
    "merged_summary_op = tf.summary.merge_all()\n",
    "summary_writer = tf.summary.FileWriter(\"/tmp/ladder\", tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session() \n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (3000, 784)\n",
      "convertToOneHot(y_train, 10).shape: (3000, 10)\n"
     ]
    }
   ],
   "source": [
    "# check the shape of the feeds:\n",
    "#x = tf.placeholder(tf.float32, shape=[None, 784], name='x_data')\n",
    "#y_true = tf.placeholder(tf.float32, shape=[None, 10], name='y_data')\n",
    "print(\"x_train.shape:\", x_train.shape)  # (2, 784)\n",
    "print(\"convertToOneHot(y_train, 10).shape:\", convertToOneHot(y_train, 10).shape)  # (2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Training: loss 834.8570556640625 acc 0.0703125 Validation: loss 268.86297607421875 acc 0.156\n",
      "100 Training: loss 11.358426094055176 acc 0.921875 Validation: loss 8.048396110534668 acc 0.871\n",
      "200 Training: loss 10.506567001342773 acc 0.921875 Validation: loss 7.057535171508789 acc 0.892\n",
      "300 Training: loss 8.553781509399414 acc 0.9765625 Validation: loss 6.212344646453857 acc 0.904\n",
      "400 Training: loss 7.521876335144043 acc 0.984375 Validation: loss 5.530648231506348 acc 0.902\n",
      "500 Training: loss 7.448641777038574 acc 1.0 Validation: loss 4.886605262756348 acc 0.904\n",
      "600 Training: loss 5.740861892700195 acc 1.0 Validation: loss 4.365663051605225 acc 0.915\n",
      "700 Training: loss 5.160611152648926 acc 0.984375 Validation: loss 3.8913216590881348 acc 0.915\n",
      "800 Training: loss 5.78906774520874 acc 0.9921875 Validation: loss 3.493112802505493 acc 0.913\n",
      "900 Training: loss 5.884727478027344 acc 1.0 Validation: loss 3.127711534500122 acc 0.911\n"
     ]
    }
   ],
   "source": [
    "vals = []\n",
    "for i in range(1000):#10000\n",
    "    idx = np.random.permutation(len(x_train))[0:128] #Easy minibatch of size 128\n",
    "    loss_, _, res_ = sess.run((loss_both, train_op, out), \n",
    "                              feed_dict={x:x_train[idx], y_true:convertToOneHot(y_train[idx], 10)})\n",
    "    if (i % 100 == 0):#50\n",
    "        acc = np.average(np.argmax(res_, axis = 1) == y_train[idx])\n",
    "        # Get the results for the validation results \n",
    "        loss_v, res_val, summary_ = sess.run([loss_both, out, merged_summary_op], \n",
    "                                                          feed_dict={x:x_test, y_true:convertToOneHot(y_test, 10)})\n",
    "        summary_writer.add_summary(summary_, i)\n",
    "        acc_v = np.average(np.argmax(res_val, axis = 1) == y_test)\n",
    "        vals.append([loss_, acc, loss_v, acc_v])\n",
    "        print(\"{} Training: loss {} acc {} Validation: loss {} acc {}\".format(i, loss_, acc, loss_v, acc_v))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## TODO check development of weights\n",
    "## todo check if supervised and unsupervised loss should get the same weight in loss_both\n",
    "## TODO: use moving average for mean and sd values in batch-normalization (understand code Martin Görner: bn-goerner.ipynb)\n",
    "## use proposed \"best hyper-paramenters\" from supplementary material\n",
    "### TODO do real semi-supervised learning (each batch consists of n1 labeled and n2 unlabeled data)\n",
    "# check the performance of the fc ladder with 100 labeled and 50000 unlabeled data\n",
    "## TODO : in test modus we should use clean encoder for prediction\n",
    "## Todo: check learning rate development\n",
    "## TODO: try multiplicative noise and dropout in test modus with MAP as point estimator and credibility intervals\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "!ls /tmp/ladder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# compare to directory in tf.summary.FileWriter\n",
    "! tensorboard --logdir /tmp/ladder/\n",
    "# check docker call and go to http://srv-lab-t-697:8711"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
