{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Ladder Network for Semi-supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current status\n",
    "### missing elements\n",
    "1. Reconstruction cost: the decoder is not normalized before inserting into the MSE. Reason: normalization destroyed the reconstruction learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.4.0',\n",
       " sys.version_info(major=3, minor=6, micro=3, releaselevel='final', serial=0))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# additional imports of python modules\n",
    "# python module imports needed in customized functions:\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imgplot\n",
    "import time\n",
    "#tf.set_random_seed(1)\n",
    "#np.random.seed(1)\n",
    "import sys\n",
    "tf.__version__, sys.version_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras import initializers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data from keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test_num) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize all values between 0 and 1 and we flatten the 28x28 images into vectors of size 784."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test_num, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ladder network: defining the graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, GaussianNoise, BatchNormalization, Activation, Layer, Merge\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports for graph plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## custom normalization layer\n",
    "All three channels (clean encoder, corrupted encoder, decoder) require normalization steps. Since no normalization layer is available in Keras, we define a custom layer that performs normalization (=standardization) of its input using the mean and the var of the input.\n",
    "\n",
    "The normalization is required before acting with relu:\n",
    "\n",
    "from https://theneuralperspective.com/2016/10/27/gradient-topics/:\n",
    "\n",
    "There are several types of normalization techniques but the idea behind all of them is the same, which is shifting our inputs to a zero mean and unit variance. We normalize the inputs before applying the non-linearity. We do this because we do not want the inputs to saturate the non-linearities at the extremes. (Checkout SNNs/SELU for some recent updates on this subject).\n",
    "\n",
    "Remark about the difference from batch norm:  Batch normalization is very nice but it is based on minibatch size and so it’s a bit difficult to use with recurrent architectures. With layer normalization, we instead compute the mean and variance using ALL of the summed inputs to the neurons in a layer for EVERY single training case. This removes the dependency on a minibatch size. Unlike batch normalization, the normalization operation for layer norm is same for training and inference. More details can be found on Hinton’s paper here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomLayer_Normalization(Layer):\n",
    "    \"\"\"Apply layer normalization.\n",
    "       shifting our inputs to a zero mean and unit variance. \n",
    "       We normalize the inputs before applying the non-linearity. \n",
    "       We do this because we do not want the inputs to saturate the non-linearities at the extremes. \n",
    "       (Checkout SNNs/SELU for some recent updates on this subject).\n",
    "       \n",
    "       no need for build -- no trainable weights. \n",
    "        # Arguments\n",
    "            epsilon: regularizer for zero division\n",
    "        # Input shape\n",
    "            Arbitrary. Use the keyword argument `input_shape`\n",
    "            (tuple of integers, does not include the samples axis)\n",
    "            when using this layer as the first layer in a model.\n",
    "        # Output shape\n",
    "            Same shape as input.\n",
    "    \"\"\"\n",
    "    def __init__(self, epsilon = 1e-6, **kwargs):\n",
    "        super(CustomLayer_Normalization, self).__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return (inputs - K.mean(inputs,axis=-1,keepdims=True))/(K.std(inputs,axis=-1,keepdims=True)+self.epsilon) # change axis for conv2D\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining encoder and decoder channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions that build a generic encoder and decoder layers\n",
    "Each encoder or decoder layer is composed of sublayers (e.g linear transformation, normalization, activation sublayers). Here we first build the generic set of the sublayers without defining their input or output dimensions and without linking them to each other. In the next step we define the linking functions that specify how the sublayers are connected to each other and what output is delivered. Note that the output of the building functions is sublayers = a dictionary of the (unlinked) sublayers.\n",
    "\n",
    "The reason to  separate the \"build\" and \"link\" steps is the fact that we want the clean and corrupted encoders to share weights. This is why they must be based on a single set of sublayers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder_layer(encoding_dim_,layer_id,stddev_= 0.05):\n",
    "    \"\"\"\n",
    "    Create the layers\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    \n",
    "    encoding_dim_:int\n",
    "        number of perceptons \n",
    "    layer_id: string\n",
    "        part of the name\n",
    "    stddev: double\n",
    "        standard deviation of the Gaussion noise layer\n",
    "        \n",
    "    Returns\n",
    "    =======\n",
    "    sublayers: dictionary of sublayers for a given layer_id\n",
    "    \n",
    "    \"\"\"\n",
    "    sublayers={}\n",
    "    s_id = 'encoder_' + layer_id + '/'\n",
    "    sublayers['lin_trans'] = Dense(encoding_dim_,activation = None,name=s_id + 'lt')\n",
    "    sublayers['norm'] = CustomLayer_Normalization(name=s_id + 'norm')\n",
    "    sublayers['noise_add'] = GaussianNoise(stddev_,name=s_id + 'noise')\n",
    "    sublayers['batch_norm'] = BatchNormalization(name=s_id + 'bn')\n",
    "    sublayers['activation'] = Activation('relu',name=s_id + 'output')\n",
    "    return sublayers\n",
    "\n",
    "def build_decoder_layer(decoding_dim_,layer_id,activation_name):\n",
    "    sublayers={}\n",
    "    s_id = 'decoder' + layer_id + '/'\n",
    "    sublayers['lin_trans']  = Dense(decoding_dim_,activation = None,name = s_id + 'lt')\n",
    "    sublayers['norm'] = CustomLayer_Normalization(name=s_id + 'norm')\n",
    "    sublayers['activation'] = Activation(activation_name,name=s_id + 'output')\n",
    "    return sublayers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions that link the sublayers within the encoder and the decoder\n",
    "Here we define functions that specify how the sublayers within each encoder/decoder layer should be linked to each other. Note that the encoder linking functions return two outputs: the final one and an intermediate one that is required for the combinator function of the ladder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def link_sublayer_corr_encoder(x,sublayers):\n",
    "    \"\"\"\n",
    "    Link the sublayers for the corrupted encoder\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    x: input for the first sublayer\n",
    "    sublayers: dict containing the sublayers\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "     x,y: layer output (after nonlin transformation), and intermediate output (after noise addition)\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        x=sublayers['lin_trans'](x)\n",
    "        x=sublayers['norm'](x)\n",
    "        y=sublayers['noise_add'](x)\n",
    "        x=sublayers['batch_norm'](y)\n",
    "        x=sublayers['activation'](x)\n",
    "    except:\n",
    "        print(\"link_sublayer_corr_encoder failed\")\n",
    "    return x,y\n",
    "\n",
    "def link_sublayer_clean_encoder(x,sublayers):\n",
    "    \"\"\"\n",
    "    Link the sublayers for the supervised approach\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    x: input for the first sublayer\n",
    "    sublayers: dict containing the sublayers\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    x,y: layer output (after nonlin transformation), and intermediate output (after normalization)\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        x=sublayers['lin_trans'](x)\n",
    "        y=sublayers['norm'](x)\n",
    "        x=sublayers['batch_norm'](y)\n",
    "        x=sublayers['activation'](x)\n",
    "    except:\n",
    "        print(\"link_sublayer_clean_encoder failed\")\n",
    "    return x,y\n",
    "\n",
    "def link_sublayer_decoder(x,sublayers,do_activation=True):\n",
    "    \"\"\"\n",
    "    Link the sublayers \n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    x: input for the first sublayer\n",
    "    sublayers: dict containing the sublayers\n",
    "    do_activation: boolean to turn on non-linear transformation\n",
    "    \n",
    "    Returns\n",
    "    =======\n",
    "    x: layer output \n",
    "    \"\"\"\n",
    "    try:\n",
    "        x=sublayers['lin_trans'](x)\n",
    "        x=sublayers['norm'](x)\n",
    "        if do_activation is True: # use activation only for debugging when no combinator is used\n",
    "            x=sublayers['activation'](x)\n",
    "    except:\n",
    "        print(\"link_sublayer_decoder failed\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinator custom layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinatorLayer(Layer):\n",
    "    \n",
    "    def __init__(self, combinator, **kwargs):# kwargs is not used here\n",
    "        self.combinator = combinator\n",
    "        super(CombinatorLayer, self).__init__(**kwargs) # need to be called this way even without using it\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.len_layer = input_shape[0][1] # extract the layer length from the input (length of lat = langth of ver)\n",
    "        self.b0 = self.add_weight(name='b0', \n",
    "                                      shape=(1,self.len_layer),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "        self.w_0z = self.add_weight(name='w_0z_lat', \n",
    "                                      shape=(1,self.len_layer),\n",
    "                                      initializer='ones',\n",
    "                                      trainable=True)\n",
    "        self.w_0u = self.add_weight(name='w_0u_ver', \n",
    "                                      shape=(1,self.len_layer),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "        self.w_0zu = self.add_weight(name='w_0zu', \n",
    "                                      shape=(1,self.len_layer),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "        self.b1 = self.add_weight(name='b1', \n",
    "                                      shape=(1,self.len_layer),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "        self.w_1z = self.add_weight(name='w_1z_lat', \n",
    "                                      shape=(1,self.len_layer),\n",
    "                                      initializer='ones',\n",
    "                                      trainable=True)\n",
    "        self.w_1u = self.add_weight(name='w_1u_ver', \n",
    "                                      shape=(1,self.len_layer),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "        self.w_1zu = self.add_weight(name='w_1zu', \n",
    "                                      shape=(1,self.len_layer),\n",
    "                                      initializer='zeros',\n",
    "                                      trainable=True)\n",
    "        self.w_sig = self.add_weight(name='w_sig', \n",
    "                                      shape=(1,self.len_layer),\n",
    "                                      initializer='ones',\n",
    "                                      trainable=True)\n",
    "        super(CombinatorLayer, self).build(input_shape)  \n",
    "\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        #print(inputs[0])\n",
    "        # inputs is a list of two layers, each of length self.len_layer\n",
    "        lat = inputs[0]\n",
    "        ver = inputs[1]\n",
    "        # Choose among various combinator types\n",
    "        if self.combinator=='linear':\n",
    "            return lat * self.w_0z + ver * self.w_0u + self.b0 # assuming broadcasting on the batch size\n",
    "        elif self.combinator=='vanilla':\n",
    "            return self.b0+self.w_0z*lat+self.w_0u*ver+self.w_0zu*lat*ver+ \\\n",
    "                   self.w_sig*K.sigmoid(self.b1+self.w_1z*lat+self.w_1u*ver+self.w_1zu*lat*ver)\n",
    "        else:\n",
    "            raise ValueError('Invalid combinator name')\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting the ladder network\n",
    "Here we call the functions that we defined above in order to construct a specific network architecture. The following steps are performed:\n",
    "1. We specify: \n",
    "    - the number of layers, \n",
    "    - their sizes, \n",
    "    - the amount of noise for the corrupted encoder, \n",
    "    - the type of combinator \n",
    "    - and the recon-loss weights. \n",
    "2. We create the encoder layers:\n",
    "    - define the  input images\n",
    "    - build each encoder layer out of its sublayers: Here the weights are initialized and therefore it must be common to clean and corrupted encoder IN ORDER TO ENSURE SHARED WEIGHTS\n",
    "    - link the corrupted encoder layers\n",
    "    - link the clean encoder layers\n",
    "        - and the recon-loss weights. \n",
    "3. We create the decoder layers:\n",
    "    - build each decoder layer out of its sublayers\n",
    "    - link the decoder layers using the combinator to combine input from the corrupted encoder\n",
    "\n",
    "The output we obtain is contained in the dict decoded_compined, as well as sidepath_clean, which will be used to calculate the recon loss in the next step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## select combiner: 'none','linear', 'vanilla'\n",
    "my_combinator = 'vanilla'\n",
    "\n",
    "## Define the architecture\n",
    "##########################################\n",
    "Layer_dim = [784,128,32]\n",
    "depth = len(Layer_dim)\n",
    "stddev = 0.05         # std of noise for corrupted encoder\n",
    "w_rl = [1.0, 1.0, 1.0]# reconstruction loss weights -- at the moment global variables (can adapt to be input to the layer constructor)\n",
    "no_classes = 10\n",
    "\n",
    "## Create the clean and corrupted encoders\n",
    "##########################################\n",
    "# Input layer: define a generic input image \n",
    "input_img = Input(shape=(Layer_dim[0],),name = 'input_img')\n",
    "\n",
    "# Build encoder sublayers: generic for clean and noisy encoder\n",
    "# NOTE:  \n",
    "# Building the encoder layers only once but linking them twice ensures that the same weights are used by the AE and the clean encoder \n",
    "# Here we provide the set of layer types that could be included in the model\n",
    "encoder_layers = {} # a dictionary of dictionaries. The dictionary keys are the layer numbers (as in paper)\n",
    "for i in range(1,depth): # loop over all encoder levels (not including the input image)\n",
    "    encoder_layers[i] = build_encoder_layer(Layer_dim[i],str(i))\n",
    "\n",
    "\n",
    "# Corrupt input and link noisy encoder (for DAE)\n",
    "corrupted_img  = GaussianNoise(stddev,name='corrupt_img')(input_img)\n",
    "\n",
    "encoded_corr = {} #  a dictionary holding all corrupted encoder levels. each level contains sublayers as specified by the linking function.\n",
    "encoded_corr[0] = corrupted_img\n",
    "sidepath_corr = {}\n",
    "sidepath_corr[0] = corrupted_img\n",
    "for key in sorted(encoder_layers.keys()):\n",
    "    encoded_corr[key],sidepath_corr[key] = link_sublayer_corr_encoder(encoded_corr[key-1],encoder_layers[key])\n",
    "    \n",
    "# Link the clean encoder (for supervised channel)\n",
    "encoded_clean={} #  a dictionary holding all clean encoder levels. each level contains sublayers as specified by the linking function.\n",
    "encoded_clean[0]=input_img\n",
    "sidepath_clean={}\n",
    "sidepath_clean[0]=input_img\n",
    "for key in sorted(encoder_layers.keys()):\n",
    "    encoded_clean[key],sidepath_clean[key] =  link_sublayer_clean_encoder(encoded_clean[key-1],encoder_layers[key])\n",
    "    \n",
    "# channel the output of the clean encoder into the classifier\n",
    "predicted_labels = Dense(10,activation='sigmoid',name='predictor')(encoded_clean[depth-1])\n",
    "\n",
    "## Create the decoder\n",
    "##########################################\n",
    "\n",
    "# Build a decoder\n",
    "decoder_layers = {} # a dictionary of dictionaries. The dictionary keys are the layer numbers (as in paper)\n",
    "for i in range(0,depth-1): # loop over all encoder levels\n",
    "    decoder_layers[i] = build_decoder_layer(Layer_dim[i],str(i),activation_name = 'sigmoid')\n",
    "    \n",
    "# Link the decoder to the corrupted encoder\n",
    "decoded = {} #  a dictionary holding all decoded levels. each level contains sublayers as specified by the linking function. \n",
    "decoded[depth-1] = CustomLayer_Normalization(name='decoded' + str(depth-1) + '/norm')(encoded_corr[depth-1]) # upper decoder layer is normalized upper corrupted encoder layer\n",
    "if my_combinator == 'none': # do not use combiner, but turn on non linearity using activations in the decoder channel\n",
    "    for i in range(depth-1)[::-1]: # gives the series depth-2,depth-3...,0\n",
    "        decoded[i] = link_sublayer_decoder(decoded[i+1],decoder_layers[i])\n",
    "    decoded_combined = decoded\n",
    "else:                # use combiner: decoded is the output of linking w/o activation, then combine with corr encoder and pass on\n",
    "    decoded_combined = {}\n",
    "    decoded_combined[depth-1] = CombinatorLayer(combinator=my_combinator,name='decoded' + str(depth-1) + '/combined')([sidepath_corr[depth-1],decoded[depth-1] ])\n",
    "    for i in range(depth-1)[::-1]: \n",
    "        decoded[i] = link_sublayer_decoder(decoded_combined[i+1],decoder_layers[i],do_activation = False)\n",
    "        decoded_combined[i] = CombinatorLayer(combinator=my_combinator,name='decoded' + str(i) + '/combined')([sidepath_corr[i],decoded[i] ])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: <tf.Tensor 'decoded0/combined/add_6:0' shape=(?, 784) dtype=float32>,\n",
       " 1: <tf.Tensor 'decoded1/combined/add_6:0' shape=(?, 128) dtype=float32>,\n",
       " 2: <tf.Tensor 'decoded2/combined/add_6:0' shape=(?, 32) dtype=float32>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'activation': <keras.layers.core.Activation at 0x12f0b906eb8>,\n",
       "  'batch_norm': <keras.layers.normalization.BatchNormalization at 0x12f0b906ac8>,\n",
       "  'lin_trans': <keras.layers.core.Dense at 0x12f0b9068d0>,\n",
       "  'noise_add': <keras.layers.noise.GaussianNoise at 0x12f0b906a58>,\n",
       "  'norm': <__main__.CustomLayer_Normalization at 0x12f0b906ba8>},\n",
       " 2: {'activation': <keras.layers.core.Activation at 0x12f0b92f6d8>,\n",
       "  'batch_norm': <keras.layers.normalization.BatchNormalization at 0x12f0b92f5c0>,\n",
       "  'lin_trans': <keras.layers.core.Dense at 0x12f0b906c88>,\n",
       "  'noise_add': <keras.layers.noise.GaussianNoise at 0x12f0fc83c18>,\n",
       "  'norm': <__main__.CustomLayer_Normalization at 0x12f0fc83828>}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a custom layer for the reconstruction-loss\n",
    "The goal of the custom layer is to enable the addition of a loss function that depends not only on the model outputs but also on intermediate layers' outputs. For the ladder network these would be the reconstruction losses, which depend on the decoder and clean encoder layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Tensor(\"custom_layer__recon_loss_1/add:0\", shape=(), dtype=float32)\n",
      "1 Tensor(\"custom_layer__recon_loss_1/add_1:0\", shape=(), dtype=float32)\n",
      "2 Tensor(\"custom_layer__recon_loss_1/add_2:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## Define the custom layer\n",
    "#################################################\n",
    "\n",
    "class CustomLayer_ReconLoss(Layer):\n",
    "    def __init__(self, epsilon = 1e-6,combinator = False, **kwargs):\n",
    "        # class constructor\n",
    "        #self.loss_info = loss_info\n",
    "        self.is_placeholder = True\n",
    "        self.output_dim = no_classes # GLOBAL\n",
    "        self.epsilon = epsilon\n",
    "        self.combinator = combinator\n",
    "        super(CustomLayer_ReconLoss, self).__init__(**kwargs)\n",
    "\n",
    "    def reconstruction_loss(self, encoder_list,decoder_list):\n",
    "        # add all reconstruction losses weighted by recon_weights\n",
    "        # note: the binary_crossentropy metric does not automatically average over the batch, \n",
    "        # this is done here by K.mean\n",
    "        \n",
    "        loss = 0\n",
    "        for i in range(len(encoder_list)):\n",
    "            # take decoder mean if no combinator is used, encoder mean if combining\n",
    "            # mean is in any case over the 0 axis = each pixel is averaged over the images in the mini-batch\n",
    "            '''\n",
    "            if self.combinator != 'none':\n",
    "                mean = K.mean(encoder_list[i],axis=0,keepdims=True)\n",
    "                std  = K.std(encoder_list[i],axis=0,keepdims=True)\n",
    "            else:\n",
    "                mean = K.mean(decoder_list[i],axis=0,keepdims=True)\n",
    "                std  = K.std(decoder_list[i],axis=0,keepdims=True)\n",
    "            print(encoder_list[i].shape)\n",
    "            '''\n",
    "            mean = 0\n",
    "            std = 1\n",
    "            #mean = K.mean(decoder_list[i],axis=0,keepdims=True)\n",
    "            #std  = K.std(decoder_list[i],axis=0,keepdims=True)\n",
    "            #mean_enc = K.mean(encoder_list[i],axis=0,keepdims=True)\n",
    "            #std_enc  = K.std(encoder_list[i],axis=0,keepdims=True)\n",
    "            #enc_norm = (encoder_list[i] - mean_enc)/(std_enc + self.epsilon)\n",
    "            dec_norm = (decoder_list[i] - mean)/(std + self.epsilon)\n",
    "            #loss += w_rl[i]*K.mean(K.square(dec_norm - enc_norm))\n",
    "            loss += w_rl[i]*K.mean(K.square(dec_norm - encoder_list[i]))\n",
    "            print(i,loss)    \n",
    "        return loss\n",
    "   \n",
    "    def call(self, inputs):\n",
    "        # inputs is a list of layers needed for the calculation of the reconstruction loss.\n",
    "        # The first layer in the list is the predicted labels.\n",
    "        # The rest of the list must contain pairs of clean encoder and decoder layers, \n",
    "        # that are needed for the reconstruction loss calculation.\n",
    "        # returns: predicted_labels, needed in order to calculate the supervised loss later on. \n",
    "        predicted_labels = inputs[0]   # predicted labels by clean encoder:  the return variable of the call\n",
    "        # call the loss function of the class as it is defined above\n",
    "        loss = self.reconstruction_loss(inputs[1::2],inputs[2::2]) # odd entries are encoder layers, even are decoder.\n",
    "        # add the custom loss to the model loss (defined in the compiler)\n",
    "        self.add_loss(loss, inputs=inputs) \n",
    "        return predicted_labels    \n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0]\n",
    "\n",
    "## Construct the inputs to CustomLayer_ReconLoss\n",
    "#################################################\n",
    "input_to_reconloss=[] # empty list of layers (see above in \"call\")\n",
    "input_to_reconloss.append(predicted_labels) # first element in the list: predicted labels of clean encoder\n",
    "# and the next elements are the sidepath_clean[i] and decoded_combined[i] for each layer i. \n",
    "# NOTE:  the predicted_labels is not used inside the CustomLayer_ReconLoss, but only returned as output. \n",
    "if my_combinator != 'none':\n",
    "    imax = depth\n",
    "else:\n",
    "    imax = depth - 1\n",
    "for i in range(imax): # later on collect from range(depth) :makes sense only after combining the AE legs\n",
    "    # append an encoder and a decoder layer for each ladder level\n",
    "    input_to_reconloss.append(sidepath_clean[i])  # from clean encoder, before BN and non lin\n",
    "    input_to_reconloss.append(decoded_combined[i])\n",
    "    \n",
    "## Call the custom layer\n",
    "#################################################\n",
    "# when calling the CustomLayer_ReconLoss, the returned value of \"call(self, inputs)\" is returned\n",
    "# when building a model with y as an output, the custom loss is automatically added to the loss defined in the compiler\n",
    "output_of_reconloss = CustomLayer_ReconLoss(combinator=my_combinator)(input_to_reconloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'predictor/Sigmoid:0' shape=(?, 10) dtype=float32>,\n",
       " <tf.Tensor 'input_img:0' shape=(?, 784) dtype=float32>,\n",
       " <tf.Tensor 'decoded0/combined/add_6:0' shape=(?, 784) dtype=float32>,\n",
       " <tf.Tensor 'encoder_1/norm_1/truediv:0' shape=(?, 128) dtype=float32>,\n",
       " <tf.Tensor 'decoded1/combined/add_6:0' shape=(?, 128) dtype=float32>,\n",
       " <tf.Tensor 'encoder_2/norm_1/truediv:0' shape=(?, 32) dtype=float32>,\n",
       " <tf.Tensor 'decoded2/combined/add_6:0' shape=(?, 32) dtype=float32>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_to_reconloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the model\n",
    "Construct a model with input_img as the input and y (the custom layer) as an output. when building a model with y as an output, the custom loss is automatically added to the loss defined in the compiler. This enables us to define a custom loss function and also to return the value y which are the predicted labels transferred to the model using the custom layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A model with custom layer with an added loss\n",
    "Important note: the need for a custom layer is only because we would like to add a loss that depends on internal parts of the networks and not only on the network output. In a previous version of the ladder the loss was a sum of supervised and unsupervised losses, where the unsupervised loss was a standard denoising autoencoder loss, without summing over all the internal reconstruction losses. There it was enough to define a model with a single input (input_img) and two outputs (decoded_img and predicted_labels) and assign a loss function per output. No custom layer was needed. However, if the loss depends on layers which are not the output layers of the network, we must define a custom layer just in order to construct the loss and add it to the supervised loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ladder_custom = Model(input_img,output_of_reconloss) # if you replace output_of_reconloss with predicted_labels you get a simple feed forward predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"1715pt\" viewBox=\"0.00 0.00 1548.00 1715.00\" width=\"1548pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 1711)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-1711 1544,-1711 1544,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 1301569104024 -->\n",
       "<g class=\"node\" id=\"node1\"><title>1301569104024</title>\n",
       "<polygon fill=\"none\" points=\"0,-1660.5 0,-1706.5 279,-1706.5 279,-1660.5 0,-1660.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"70\" y=\"-1679.8\">input_img: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"140,-1660.5 140,-1706.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"168\" y=\"-1691.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"140,-1683.5 196,-1683.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"168\" y=\"-1668.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"196,-1660.5 196,-1706.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"237.5\" y=\"-1691.3\">(None, 784)</text>\n",
       "<polyline fill=\"none\" points=\"196,-1683.5 279,-1683.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"237.5\" y=\"-1668.3\">(None, 784)</text>\n",
       "</g>\n",
       "<!-- 1301569104192 -->\n",
       "<g class=\"node\" id=\"node2\"><title>1301569104192</title>\n",
       "<polygon fill=\"none\" points=\"75,-1577.5 75,-1623.5 390,-1623.5 390,-1577.5 75,-1577.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163\" y=\"-1596.8\">corrupt_img: GaussianNoise</text>\n",
       "<polyline fill=\"none\" points=\"251,-1577.5 251,-1623.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279\" y=\"-1608.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"251,-1600.5 307,-1600.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279\" y=\"-1585.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"307,-1577.5 307,-1623.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"348.5\" y=\"-1608.3\">(None, 784)</text>\n",
       "<polyline fill=\"none\" points=\"307,-1600.5 390,-1600.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"348.5\" y=\"-1585.3\">(None, 784)</text>\n",
       "</g>\n",
       "<!-- 1301569104024&#45;&gt;1301569104192 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>1301569104024-&gt;1301569104192</title>\n",
       "<path d=\"M164.913,-1660.37C175.575,-1651.08 188.113,-1640.16 199.476,-1630.26\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"201.876,-1632.81 207.118,-1623.61 197.278,-1627.54 201.876,-1632.81\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301569104080 -->\n",
       "<g class=\"node\" id=\"node3\"><title>1301569104080</title>\n",
       "<polygon fill=\"none\" points=\"87,-1494.5 87,-1540.5 354,-1540.5 354,-1494.5 87,-1494.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"151\" y=\"-1513.8\">encoder_1/lt: Dense</text>\n",
       "<polyline fill=\"none\" points=\"215,-1494.5 215,-1540.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"243\" y=\"-1525.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"215,-1517.5 271,-1517.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"243\" y=\"-1502.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"271,-1494.5 271,-1540.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"312.5\" y=\"-1525.3\">(None, 784)</text>\n",
       "<polyline fill=\"none\" points=\"271,-1517.5 354,-1517.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"312.5\" y=\"-1502.3\">(None, 128)</text>\n",
       "</g>\n",
       "<!-- 1301569104024&#45;&gt;1301569104080 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>1301569104024-&gt;1301569104080</title>\n",
       "<path d=\"M46.5,-1599.5C46.084,-1574.46 60.9051,-1557.15 82.0538,-1545.17\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"83.8279,-1548.2 91.1323,-1540.52 80.6364,-1541.97 83.8279,-1548.2\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301569204464 -->\n",
       "<g class=\"node\" id=\"node22\"><title>1301569204464</title>\n",
       "<polygon fill=\"none\" points=\"629,-0.5 629,-46.5 1540,-46.5 1540,-0.5 629,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"797.5\" y=\"-19.8\">custom_layer__recon_loss_1: CustomLayer_ReconLoss</text>\n",
       "<polyline fill=\"none\" points=\"966,-0.5 966,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"994\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"966,-23.5 1022,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"994\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1022,-0.5 1022,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1281\" y=\"-31.3\">[(None, 10), (None, 784), (None, 784), (None, 128), (None, 128), (None, 32), (None, 32)]</text>\n",
       "<polyline fill=\"none\" points=\"1022,-23.5 1540,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1281\" y=\"-8.3\">(None, 10)</text>\n",
       "</g>\n",
       "<!-- 1301569104024&#45;&gt;1301569204464 -->\n",
       "<g class=\"edge\" id=\"edge33\"><title>1301569104024-&gt;1301569204464</title>\n",
       "<path d=\"M697.5,-354.5C709.884,-350.265 705.375,-338.895 716.5,-332 809.455,-274.394 903.116,-369.495 955.5,-273.5\" fill=\"none\" stroke=\"black\"/>\n",
       "<path d=\"M84.5,-1267.5C92.6841,-1195.07 84.5,-1176.39 84.5,-1103.5 84.5,-1103.5 84.5,-1103.5 84.5,-686.5 84.5,-638.857 74.174,-618.548 103.5,-581 142.499,-531.067 255.452,-581.934 233.5,-522.5\" fill=\"none\" stroke=\"black\"/>\n",
       "<path d=\"M955.5,-271.5C995.834,-197.587 927.567,-152.909 974.5,-83 983.203,-70.0364 995.745,-59.7322 1009.27,-51.6184\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1011.24,-54.5265 1018.27,-46.5969 1007.83,-48.414 1011.24,-54.5265\" stroke=\"black\"/>\n",
       "<path d=\"M46.5,-1599.5C44.4873,-1478.38 51.0173,-1447.56 70.5,-1328 74.7997,-1301.61 81.0189,-1296.01 84.5,-1269.5\" fill=\"none\" stroke=\"black\"/>\n",
       "<path d=\"M89.7882,-1660.46C67.8637,-1647.08 46.895,-1627.51 46.5,-1601.5\" fill=\"none\" stroke=\"black\"/>\n",
       "<path d=\"M233.5,-520.5C216.535,-475.98 218.021,-447.88 252.5,-415 324.681,-346.167 603.125,-388.771 697.5,-356.5\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301569104192&#45;&gt;1301569104080 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>1301569104192-&gt;1301569104080</title>\n",
       "<path d=\"M229.221,-1577.37C228.004,-1569.15 226.597,-1559.66 225.274,-1550.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"228.703,-1549.99 223.775,-1540.61 221.778,-1551.01 228.703,-1549.99\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301672559784 -->\n",
       "<g class=\"node\" id=\"node21\"><title>1301672559784</title>\n",
       "<polygon fill=\"none\" points=\"984,-83.5 984,-129.5 1443,-129.5 1443,-83.5 984,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1102\" y=\"-102.8\">decoded0/combined: CombinatorLayer</text>\n",
       "<polyline fill=\"none\" points=\"1220,-83.5 1220,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1248\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1220,-106.5 1276,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1248\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1276,-83.5 1276,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1359.5\" y=\"-114.3\">[(None, 784), (None, 784)]</text>\n",
       "<polyline fill=\"none\" points=\"1276,-106.5 1443,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1359.5\" y=\"-91.3\">(None, 784)</text>\n",
       "</g>\n",
       "<!-- 1301569104192&#45;&gt;1301672559784 -->\n",
       "<g class=\"edge\" id=\"edge30\"><title>1301569104192-&gt;1301672559784</title>\n",
       "<path d=\"M390.124,-1593.81C713.012,-1580.06 1419.5,-1538.22 1419.5,-1435.5 1419.5,-1435.5 1419.5,-1435.5 1419.5,-271.5 1419.5,-223.857 1432.02,-201.727 1400.5,-166 1388.44,-152.333 1373.24,-141.824 1356.74,-133.75\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1358,-130.478 1347.45,-129.511 1355.09,-136.847 1358,-130.478\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301569104808 -->\n",
       "<g class=\"node\" id=\"node4\"><title>1301569104808</title>\n",
       "<polygon fill=\"none\" points=\"75,-1411.5 75,-1457.5 490,-1457.5 490,-1411.5 75,-1411.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213\" y=\"-1430.8\">encoder_1/norm: CustomLayer_Normalization</text>\n",
       "<polyline fill=\"none\" points=\"351,-1411.5 351,-1457.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"379\" y=\"-1442.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"351,-1434.5 407,-1434.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"379\" y=\"-1419.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"407,-1411.5 407,-1457.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"448.5\" y=\"-1442.3\">(None, 128)</text>\n",
       "<polyline fill=\"none\" points=\"407,-1434.5 490,-1434.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"448.5\" y=\"-1419.3\">(None, 128)</text>\n",
       "</g>\n",
       "<!-- 1301569104080&#45;&gt;1301569104808 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>1301569104080-&gt;1301569104808</title>\n",
       "<path d=\"M237.442,-1494.37C244.208,-1485.53 252.108,-1475.21 259.386,-1465.7\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"262.28,-1467.68 265.579,-1457.61 256.721,-1463.42 262.28,-1467.68\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301569104472 -->\n",
       "<g class=\"node\" id=\"node5\"><title>1301569104472</title>\n",
       "<polygon fill=\"none\" points=\"118.5,-1328.5 118.5,-1374.5 456.5,-1374.5 456.5,-1328.5 118.5,-1328.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-1347.8\">encoder_1/noise: GaussianNoise</text>\n",
       "<polyline fill=\"none\" points=\"317.5,-1328.5 317.5,-1374.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"345.5\" y=\"-1359.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"317.5,-1351.5 373.5,-1351.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"345.5\" y=\"-1336.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"373.5,-1328.5 373.5,-1374.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"415\" y=\"-1359.3\">(None, 128)</text>\n",
       "<polyline fill=\"none\" points=\"373.5,-1351.5 456.5,-1351.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"415\" y=\"-1336.3\">(None, 128)</text>\n",
       "</g>\n",
       "<!-- 1301569104808&#45;&gt;1301569104472 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>1301569104808-&gt;1301569104472</title>\n",
       "<path d=\"M283.866,-1411.37C284.373,-1403.15 284.959,-1393.66 285.511,-1384.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"289.013,-1384.8 286.135,-1374.61 282.026,-1384.37 289.013,-1384.8\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301569104584 -->\n",
       "<g class=\"node\" id=\"node6\"><title>1301569104584</title>\n",
       "<polygon fill=\"none\" points=\"113,-1245.5 113,-1291.5 462,-1291.5 462,-1245.5 113,-1245.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"218\" y=\"-1264.8\">encoder_1/bn: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"323,-1245.5 323,-1291.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"351\" y=\"-1276.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"323,-1268.5 379,-1268.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"351\" y=\"-1253.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"379,-1245.5 379,-1291.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"420.5\" y=\"-1276.3\">(None, 128)</text>\n",
       "<polyline fill=\"none\" points=\"379,-1268.5 462,-1268.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"420.5\" y=\"-1253.3\">(None, 128)</text>\n",
       "</g>\n",
       "<!-- 1301569104808&#45;&gt;1301569104584 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>1301569104808-&gt;1301569104584</title>\n",
       "<path d=\"M84.5,-1350.5C80.9599,-1326.13 92.2601,-1308.91 111.104,-1296.78\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"113,-1299.73 119.942,-1291.73 109.524,-1293.66 113,-1299.73\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301569104808&#45;&gt;1301569204464 -->\n",
       "<g class=\"edge\" id=\"edge35\"><title>1301569104808-&gt;1301569204464</title>\n",
       "<path d=\"M84.5,-1350.5C79.3246,-1314.87 80.4579,-1305.27 84.5,-1269.5\" fill=\"none\" stroke=\"black\"/>\n",
       "<path d=\"M133,-1411.35C107.909,-1399.16 88.5846,-1380.62 84.5,-1352.5\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301569104472&#45;&gt;1301569104584 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>1301569104472-&gt;1301569104584</title>\n",
       "<path d=\"M287.5,-1328.37C287.5,-1320.15 287.5,-1310.66 287.5,-1301.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"291,-1301.61 287.5,-1291.61 284,-1301.61 291,-1301.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301671809544 -->\n",
       "<g class=\"node\" id=\"node17\"><title>1301671809544</title>\n",
       "<polygon fill=\"none\" points=\"726,-332.5 726,-378.5 1185,-378.5 1185,-332.5 726,-332.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"844\" y=\"-351.8\">decoded1/combined: CombinatorLayer</text>\n",
       "<polyline fill=\"none\" points=\"962,-332.5 962,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"990\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"962,-355.5 1018,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"990\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1018,-332.5 1018,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1101.5\" y=\"-363.3\">[(None, 128), (None, 128)]</text>\n",
       "<polyline fill=\"none\" points=\"1018,-355.5 1185,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1101.5\" y=\"-340.3\">(None, 128)</text>\n",
       "</g>\n",
       "<!-- 1301569104472&#45;&gt;1301671809544 -->\n",
       "<g class=\"edge\" id=\"edge25\"><title>1301569104472-&gt;1301671809544</title>\n",
       "<path d=\"M456.864,-1339.74C644.07,-1323.08 919.5,-1282.29 919.5,-1186.5 919.5,-1186.5 919.5,-1186.5 919.5,-520.5 919.5,-473.811 933.592,-421.349 944.142,-388.612\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"947.6,-389.303 947.421,-378.709 940.955,-387.102 947.6,-389.303\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301569105592 -->\n",
       "<g class=\"node\" id=\"node7\"><title>1301569105592</title>\n",
       "<polygon fill=\"none\" points=\"261.5,-1162.5 261.5,-1208.5 579.5,-1208.5 579.5,-1162.5 261.5,-1162.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"351\" y=\"-1181.8\">encoder_1/output: Activation</text>\n",
       "<polyline fill=\"none\" points=\"440.5,-1162.5 440.5,-1208.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"468.5\" y=\"-1193.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"440.5,-1185.5 496.5,-1185.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"468.5\" y=\"-1170.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"496.5,-1162.5 496.5,-1208.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"538\" y=\"-1193.3\">(None, 128)</text>\n",
       "<polyline fill=\"none\" points=\"496.5,-1185.5 579.5,-1185.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"538\" y=\"-1170.3\">(None, 128)</text>\n",
       "</g>\n",
       "<!-- 1301569104584&#45;&gt;1301569105592 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>1301569104584-&gt;1301569105592</title>\n",
       "<path d=\"M323.843,-1245.37C339.824,-1235.63 358.752,-1224.11 375.604,-1213.84\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"377.481,-1216.8 384.201,-1208.61 373.84,-1210.82 377.481,-1216.8\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301569105032 -->\n",
       "<g class=\"node\" id=\"node8\"><title>1301569105032</title>\n",
       "<polygon fill=\"none\" points=\"354,-1079.5 354,-1125.5 621,-1125.5 621,-1079.5 354,-1079.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"418\" y=\"-1098.8\">encoder_2/lt: Dense</text>\n",
       "<polyline fill=\"none\" points=\"482,-1079.5 482,-1125.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"510\" y=\"-1110.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"482,-1102.5 538,-1102.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"510\" y=\"-1087.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"538,-1079.5 538,-1125.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"579.5\" y=\"-1110.3\">(None, 128)</text>\n",
       "<polyline fill=\"none\" points=\"538,-1102.5 621,-1102.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"579.5\" y=\"-1087.3\">(None, 32)</text>\n",
       "</g>\n",
       "<!-- 1301569105592&#45;&gt;1301569105032 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>1301569105592-&gt;1301569105032</title>\n",
       "<path d=\"M438.808,-1162.37C446.194,-1153.44 454.83,-1143 462.761,-1133.41\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"465.537,-1135.54 469.214,-1125.61 460.143,-1131.08 465.537,-1135.54\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301639870504 -->\n",
       "<g class=\"node\" id=\"node9\"><title>1301639870504</title>\n",
       "<polygon fill=\"none\" points=\"350,-996.5 350,-1042.5 759,-1042.5 759,-996.5 350,-996.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"488\" y=\"-1015.8\">encoder_2/norm: CustomLayer_Normalization</text>\n",
       "<polyline fill=\"none\" points=\"626,-996.5 626,-1042.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"654\" y=\"-1027.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"626,-1019.5 682,-1019.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"654\" y=\"-1004.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"682,-996.5 682,-1042.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"720.5\" y=\"-1027.3\">(None, 32)</text>\n",
       "<polyline fill=\"none\" points=\"682,-1019.5 759,-1019.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"720.5\" y=\"-1004.3\">(None, 32)</text>\n",
       "</g>\n",
       "<!-- 1301569105032&#45;&gt;1301639870504 -->\n",
       "<g class=\"edge\" id=\"edge13\"><title>1301569105032-&gt;1301639870504</title>\n",
       "<path d=\"M505.808,-1079.37C513.194,-1070.44 521.83,-1060 529.761,-1050.41\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"532.537,-1052.54 536.214,-1042.61 527.143,-1048.08 532.537,-1052.54\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301639871512 -->\n",
       "<g class=\"node\" id=\"node10\"><title>1301639871512</title>\n",
       "<polygon fill=\"none\" points=\"486.5,-913.5 486.5,-959.5 818.5,-959.5 818.5,-913.5 486.5,-913.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"586\" y=\"-932.8\">encoder_2/noise: GaussianNoise</text>\n",
       "<polyline fill=\"none\" points=\"685.5,-913.5 685.5,-959.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"713.5\" y=\"-944.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"685.5,-936.5 741.5,-936.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"713.5\" y=\"-921.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"741.5,-913.5 741.5,-959.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"780\" y=\"-944.3\">(None, 32)</text>\n",
       "<polyline fill=\"none\" points=\"741.5,-936.5 818.5,-936.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"780\" y=\"-921.3\">(None, 32)</text>\n",
       "</g>\n",
       "<!-- 1301639870504&#45;&gt;1301639871512 -->\n",
       "<g class=\"edge\" id=\"edge15\"><title>1301639870504-&gt;1301639871512</title>\n",
       "<path d=\"M581.279,-996.366C592.514,-987.08 605.727,-976.16 617.701,-966.262\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"620.275,-968.676 625.753,-959.607 615.816,-963.28 620.275,-968.676\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301569271232 -->\n",
       "<g class=\"node\" id=\"node11\"><title>1301569271232</title>\n",
       "<polygon fill=\"none\" points=\"288,-830.5 288,-876.5 631,-876.5 631,-830.5 288,-830.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"393\" y=\"-849.8\">encoder_2/bn: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"498,-830.5 498,-876.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"526\" y=\"-861.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"498,-853.5 554,-853.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"526\" y=\"-838.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"554,-830.5 554,-876.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"592.5\" y=\"-861.3\">(None, 32)</text>\n",
       "<polyline fill=\"none\" points=\"554,-853.5 631,-853.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"592.5\" y=\"-838.3\">(None, 32)</text>\n",
       "</g>\n",
       "<!-- 1301639870504&#45;&gt;1301569271232 -->\n",
       "<g class=\"edge\" id=\"edge17\"><title>1301639870504-&gt;1301569271232</title>\n",
       "<path d=\"M514.069,-996.357C500.405,-986.904 486.378,-974.643 477.5,-960 464.172,-938.017 459.992,-908.979 458.966,-886.934\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"462.459,-886.636 458.689,-876.734 455.462,-886.826 462.459,-886.636\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301639870504&#45;&gt;1301569204464 -->\n",
       "<g class=\"edge\" id=\"edge37\"><title>1301639870504-&gt;1301569204464</title>\n",
       "<path d=\"M730.506,-996.454C773.875,-987.625 812.29,-975.719 827.5,-960 860.63,-925.761 846.5,-902.143 846.5,-854.5 846.5,-854.5 846.5,-854.5 846.5,-686.5 846.5,-638.776 843.064,-625.757 826.5,-581 786.56,-473.076 588.536,-393.508 697.5,-356.5\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301639871512&#45;&gt;1301569271232 -->\n",
       "<g class=\"edge\" id=\"edge16\"><title>1301639871512-&gt;1301569271232</title>\n",
       "<path d=\"M600.017,-913.473C575.767,-903.296 546.798,-891.138 521.48,-880.512\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"522.548,-877.165 511.973,-876.522 519.839,-883.619 522.548,-877.165\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301671809152 -->\n",
       "<g class=\"node\" id=\"node14\"><title>1301671809152</title>\n",
       "<polygon fill=\"none\" points=\"373,-581.5 373,-627.5 818,-627.5 818,-581.5 373,-581.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"491\" y=\"-600.8\">decoded2/combined: CombinatorLayer</text>\n",
       "<polyline fill=\"none\" points=\"609,-581.5 609,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"637\" y=\"-612.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"609,-604.5 665,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"637\" y=\"-589.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"665,-581.5 665,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"741.5\" y=\"-612.3\">[(None, 32), (None, 32)]</text>\n",
       "<polyline fill=\"none\" points=\"665,-604.5 818,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"741.5\" y=\"-589.3\">(None, 32)</text>\n",
       "</g>\n",
       "<!-- 1301639871512&#45;&gt;1301671809152 -->\n",
       "<g class=\"edge\" id=\"edge21\"><title>1301639871512-&gt;1301671809152</title>\n",
       "<path d=\"M661.554,-913.265C679.727,-864.94 715.468,-747.936 673.5,-664 667.528,-652.056 657.829,-641.918 647.268,-633.607\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"649.208,-630.689 639.071,-627.608 645.074,-636.338 649.208,-630.689\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301569271512 -->\n",
       "<g class=\"node\" id=\"node12\"><title>1301569271512</title>\n",
       "<polygon fill=\"none\" points=\"303.5,-747.5 303.5,-793.5 615.5,-793.5 615.5,-747.5 303.5,-747.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"393\" y=\"-766.8\">encoder_2/output: Activation</text>\n",
       "<polyline fill=\"none\" points=\"482.5,-747.5 482.5,-793.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"510.5\" y=\"-778.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"482.5,-770.5 538.5,-770.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"510.5\" y=\"-755.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"538.5,-747.5 538.5,-793.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"577\" y=\"-778.3\">(None, 32)</text>\n",
       "<polyline fill=\"none\" points=\"538.5,-770.5 615.5,-770.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"577\" y=\"-755.3\">(None, 32)</text>\n",
       "</g>\n",
       "<!-- 1301569271232&#45;&gt;1301569271512 -->\n",
       "<g class=\"edge\" id=\"edge18\"><title>1301569271232-&gt;1301569271512</title>\n",
       "<path d=\"M459.5,-830.366C459.5,-822.152 459.5,-812.658 459.5,-803.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"463,-803.607 459.5,-793.607 456,-803.607 463,-803.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301642597936 -->\n",
       "<g class=\"node\" id=\"node13\"><title>1301642597936</title>\n",
       "<polygon fill=\"none\" points=\"260,-664.5 260,-710.5 665,-710.5 665,-664.5 260,-664.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"396\" y=\"-683.8\">decoded2/norm: CustomLayer_Normalization</text>\n",
       "<polyline fill=\"none\" points=\"532,-664.5 532,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"560\" y=\"-695.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"532,-687.5 588,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"560\" y=\"-672.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"588,-664.5 588,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"626.5\" y=\"-695.3\">(None, 32)</text>\n",
       "<polyline fill=\"none\" points=\"588,-687.5 665,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"626.5\" y=\"-672.3\">(None, 32)</text>\n",
       "</g>\n",
       "<!-- 1301569271512&#45;&gt;1301642597936 -->\n",
       "<g class=\"edge\" id=\"edge20\"><title>1301569271512-&gt;1301642597936</title>\n",
       "<path d=\"M460.32,-747.366C460.624,-739.152 460.976,-729.658 461.306,-720.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"464.809,-720.73 461.681,-710.607 457.813,-720.47 464.809,-720.73\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301569104920 -->\n",
       "<g class=\"node\" id=\"node20\"><title>1301569104920</title>\n",
       "<polygon fill=\"none\" points=\"112.5,-581.5 112.5,-627.5 354.5,-627.5 354.5,-581.5 112.5,-581.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"167\" y=\"-600.8\">predictor: Dense</text>\n",
       "<polyline fill=\"none\" points=\"221.5,-581.5 221.5,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249.5\" y=\"-612.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"221.5,-604.5 277.5,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"249.5\" y=\"-589.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"277.5,-581.5 277.5,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"316\" y=\"-612.3\">(None, 32)</text>\n",
       "<polyline fill=\"none\" points=\"277.5,-604.5 354.5,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"316\" y=\"-589.3\">(None, 10)</text>\n",
       "</g>\n",
       "<!-- 1301569271512&#45;&gt;1301569104920 -->\n",
       "<g class=\"edge\" id=\"edge29\"><title>1301569271512-&gt;1301569104920</title>\n",
       "<path d=\"M303.421,-747.679C283.42,-739.015 264.929,-727.162 250.5,-711 232.928,-691.318 229.633,-660.944 230.176,-637.833\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"233.674,-637.945 230.658,-627.789 226.682,-637.61 233.674,-637.945\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301642597936&#45;&gt;1301671809152 -->\n",
       "<g class=\"edge\" id=\"edge22\"><title>1301642597936-&gt;1301671809152</title>\n",
       "<path d=\"M498.843,-664.366C514.824,-654.634 533.752,-643.106 550.604,-632.842\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"552.481,-635.798 559.201,-627.607 548.84,-629.819 552.481,-635.798\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301671585328 -->\n",
       "<g class=\"node\" id=\"node15\"><title>1301671585328</title>\n",
       "<polygon fill=\"none\" points=\"400.5,-498.5 400.5,-544.5 660.5,-544.5 660.5,-498.5 400.5,-498.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"461\" y=\"-517.8\">decoder1/lt: Dense</text>\n",
       "<polyline fill=\"none\" points=\"521.5,-498.5 521.5,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"549.5\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"521.5,-521.5 577.5,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"549.5\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"577.5,-498.5 577.5,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"619\" y=\"-529.3\">(None, 32)</text>\n",
       "<polyline fill=\"none\" points=\"577.5,-521.5 660.5,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"619\" y=\"-506.3\">(None, 128)</text>\n",
       "</g>\n",
       "<!-- 1301671809152&#45;&gt;1301671585328 -->\n",
       "<g class=\"edge\" id=\"edge23\"><title>1301671809152-&gt;1301671585328</title>\n",
       "<path d=\"M577.738,-581.366C570.573,-572.437 562.195,-561.997 554.501,-552.409\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"557.229,-550.216 548.24,-544.607 551.769,-554.597 557.229,-550.216\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301671809152&#45;&gt;1301569204464 -->\n",
       "<g class=\"edge\" id=\"edge38\"><title>1301671809152-&gt;1301569204464</title>\n",
       "<path d=\"M443.405,-581.491C347.884,-565.688 241.275,-543.55 233.5,-522.5\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301671742880 -->\n",
       "<g class=\"node\" id=\"node16\"><title>1301671742880</title>\n",
       "<polygon fill=\"none\" points=\"261.5,-415.5 261.5,-461.5 669.5,-461.5 669.5,-415.5 261.5,-415.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"396\" y=\"-434.8\">decoder1/norm: CustomLayer_Normalization</text>\n",
       "<polyline fill=\"none\" points=\"530.5,-415.5 530.5,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"558.5\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"530.5,-438.5 586.5,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"558.5\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"586.5,-415.5 586.5,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"628\" y=\"-446.3\">(None, 128)</text>\n",
       "<polyline fill=\"none\" points=\"586.5,-438.5 669.5,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"628\" y=\"-423.3\">(None, 128)</text>\n",
       "</g>\n",
       "<!-- 1301671585328&#45;&gt;1301671742880 -->\n",
       "<g class=\"edge\" id=\"edge24\"><title>1301671585328-&gt;1301671742880</title>\n",
       "<path d=\"M512.738,-498.366C505.573,-489.437 497.195,-478.997 489.501,-469.409\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"492.229,-467.216 483.24,-461.607 486.769,-471.597 492.229,-467.216\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301671742880&#45;&gt;1301671809544 -->\n",
       "<g class=\"edge\" id=\"edge26\"><title>1301671742880-&gt;1301671809544</title>\n",
       "<path d=\"M598.747,-415.473C664.789,-404.556 744.619,-391.36 812.004,-380.221\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"812.984,-383.606 822.279,-378.522 811.842,-376.7 812.984,-383.606\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301643786280 -->\n",
       "<g class=\"node\" id=\"node18\"><title>1301643786280</title>\n",
       "<polygon fill=\"none\" points=\"1020.5,-249.5 1020.5,-295.5 1280.5,-295.5 1280.5,-249.5 1020.5,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1081\" y=\"-268.8\">decoder0/lt: Dense</text>\n",
       "<polyline fill=\"none\" points=\"1141.5,-249.5 1141.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1169.5\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1141.5,-272.5 1197.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1169.5\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1197.5,-249.5 1197.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1239\" y=\"-280.3\">(None, 128)</text>\n",
       "<polyline fill=\"none\" points=\"1197.5,-272.5 1280.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1239\" y=\"-257.3\">(None, 784)</text>\n",
       "</g>\n",
       "<!-- 1301671809544&#45;&gt;1301643786280 -->\n",
       "<g class=\"edge\" id=\"edge27\"><title>1301671809544-&gt;1301643786280</title>\n",
       "<path d=\"M1008.53,-332.473C1033.14,-322.251 1062.56,-310.031 1088.22,-299.372\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1089.59,-302.591 1097.48,-295.522 1086.91,-296.126 1089.59,-302.591\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301671809544&#45;&gt;1301569204464 -->\n",
       "<g class=\"edge\" id=\"edge36\"><title>1301671809544-&gt;1301569204464</title>\n",
       "<path d=\"M950.053,-332.469C947.048,-315.334 945.665,-291.522 955.5,-273.5\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301671664944 -->\n",
       "<g class=\"node\" id=\"node19\"><title>1301671664944</title>\n",
       "<polygon fill=\"none\" points=\"983.5,-166.5 983.5,-212.5 1391.5,-212.5 1391.5,-166.5 983.5,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1118\" y=\"-185.8\">decoder0/norm: CustomLayer_Normalization</text>\n",
       "<polyline fill=\"none\" points=\"1252.5,-166.5 1252.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1280.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1252.5,-189.5 1308.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1280.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1308.5,-166.5 1308.5,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1350\" y=\"-197.3\">(None, 784)</text>\n",
       "<polyline fill=\"none\" points=\"1308.5,-189.5 1391.5,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1350\" y=\"-174.3\">(None, 784)</text>\n",
       "</g>\n",
       "<!-- 1301643786280&#45;&gt;1301671664944 -->\n",
       "<g class=\"edge\" id=\"edge28\"><title>1301643786280-&gt;1301671664944</title>\n",
       "<path d=\"M1160.61,-249.366C1164.49,-240.884 1168.98,-231.037 1173.18,-221.853\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1176.43,-223.157 1177.4,-212.607 1170.06,-220.249 1176.43,-223.157\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301671664944&#45;&gt;1301672559784 -->\n",
       "<g class=\"edge\" id=\"edge31\"><title>1301671664944-&gt;1301672559784</title>\n",
       "<path d=\"M1194.6,-166.366C1197.3,-157.973 1200.42,-148.245 1203.34,-139.143\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1206.68,-140.198 1206.4,-129.607 1200.02,-138.059 1206.68,-140.198\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301569104920&#45;&gt;1301569204464 -->\n",
       "<g class=\"edge\" id=\"edge32\"><title>1301569104920-&gt;1301569204464</title>\n",
       "<path d=\"M237.529,-581.462C239.639,-564.75 240.516,-541.496 233.5,-522.5\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1301672559784&#45;&gt;1301569204464 -->\n",
       "<g class=\"edge\" id=\"edge34\"><title>1301672559784-&gt;1301569204464</title>\n",
       "<path d=\"M1178.25,-83.3664C1162.89,-73.723 1144.73,-62.3171 1128.5,-52.1252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1130.04,-48.9605 1119.71,-46.6068 1126.31,-54.8887 1130.04,-48.9605\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ladder_custom.summary()\n",
    "SVG(model_to_dot(ladder_custom,show_shapes=True).create(prog='dot',format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the model\n",
    "In the compiler, supply the loss of the supervised part. The reconstruction loss is added automatically by the model due to the custom layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ladder_custom.compile(optimizer='adadelta', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_img (InputLayer)          (None, 784)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "corrupt_img (GaussianNoise)     (None, 784)          0           input_img[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1/lt (Dense)            (None, 128)          100480      corrupt_img[0][0]                \n",
      "                                                                 input_img[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1/norm (CustomLayer_Nor (None, 128)          0           encoder_1/lt[0][0]               \n",
      "                                                                 encoder_1/lt[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1/noise (GaussianNoise) (None, 128)          0           encoder_1/norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1/bn (BatchNormalizatio (None, 128)          512         encoder_1/noise[0][0]            \n",
      "                                                                 encoder_1/norm[1][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1/output (Activation)   (None, 128)          0           encoder_1/bn[0][0]               \n",
      "                                                                 encoder_1/bn[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2/lt (Dense)            (None, 32)           4128        encoder_1/output[0][0]           \n",
      "                                                                 encoder_1/output[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2/norm (CustomLayer_Nor (None, 32)           0           encoder_2/lt[0][0]               \n",
      "                                                                 encoder_2/lt[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2/noise (GaussianNoise) (None, 32)           0           encoder_2/norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2/bn (BatchNormalizatio (None, 32)           128         encoder_2/noise[0][0]            \n",
      "                                                                 encoder_2/norm[1][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_2/output (Activation)   (None, 32)           0           encoder_2/bn[0][0]               \n",
      "                                                                 encoder_2/bn[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoded2/norm (CustomLayer_Norm (None, 32)           0           encoder_2/output[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoded2/combined (CombinatorLa (None, 32)           288         encoder_2/noise[0][0]            \n",
      "                                                                 decoded2/norm[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1/lt (Dense)             (None, 128)          4224        decoded2/combined[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder1/norm (CustomLayer_Norm (None, 128)          0           decoder1/lt[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoded1/combined (CombinatorLa (None, 128)          1152        encoder_1/noise[0][0]            \n",
      "                                                                 decoder1/norm[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder0/lt (Dense)             (None, 784)          101136      decoded1/combined[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "decoder0/norm (CustomLayer_Norm (None, 784)          0           decoder0/lt[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "predictor (Dense)               (None, 10)           330         encoder_2/output[1][0]           \n",
      "__________________________________________________________________________________________________\n",
      "decoded0/combined (CombinatorLa (None, 784)          7056        corrupt_img[0][0]                \n",
      "                                                                 decoder0/norm[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "custom_layer__recon_loss_1 (Cus (None, 10)           0           predictor[0][0]                  \n",
      "                                                                 input_img[0][0]                  \n",
      "                                                                 decoded0/combined[0][0]          \n",
      "                                                                 encoder_1/norm[1][0]             \n",
      "                                                                 decoded1/combined[0][0]          \n",
      "                                                                 encoder_2/norm[1][0]             \n",
      "                                                                 decoded2/combined[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 219,434\n",
      "Trainable params: 219,114\n",
      "Non-trainable params: 320\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ladder_custom.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "The model output, output_of_reconloss, are the predicted labels. The loss function, however, containes contributions from the autoencoder. This is why the network is trained to reconstruct (DAE) and classify (clean encoder) simultaneously, even though this cannot be seen from the arguments of the fit below ( (train_x, train_y) looks like a supervised classification only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 27s 448us/step - loss: 0.5357 - val_loss: 0.1209\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 26s 432us/step - loss: 0.1120 - val_loss: 0.0909\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 26s 431us/step - loss: 0.0801 - val_loss: 0.0809\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 29s 487us/step - loss: 0.0649 - val_loss: 0.0736\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 33s 544us/step - loss: 0.0520 - val_loss: 0.0738\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 31s 520us/step - loss: 0.0453 - val_loss: 0.0722\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 32s 538us/step - loss: 0.0370 - val_loss: 0.0713\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 34s 559us/step - loss: 0.0330 - val_loss: 0.0724\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 28s 463us/step - loss: 0.0302 - val_loss: 0.0705\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 27s 457us/step - loss: 0.0276 - val_loss: 0.0799\n"
     ]
    }
   ],
   "source": [
    "TrainLadder = ladder_custom.fit(x_train,y_train,\n",
    "                epochs=10,\n",
    "                batch_size=100,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting and plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encode and decode some digits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A layer is an object which has a well defined number of outputs. The input is not specified upon definition of the layer, but only upon \"linking\", i.e when the layer received a specific input. Only after linking, the weight tensor is defined and can then be trained. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predicting\n",
    "After training the network we obtain a set of linked layers that already contain the trained weights. For example, \"decoded_combined[0]\" stands for the output of the decoder which is linked to the input input_img, via a set of specific weights. We can now construct a new model that uses the weights for prediction. \n",
    "\n",
    "After constructing the model we can perform a prediction giving it x_test as an input, and obtaining the decoded image as an output. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build the model for prediction\n",
    "ladder_for_prediction = Model(input_img,[decoded_combined[0],predicted_labels])\n",
    "# output the decoded images from the decoder channel and the predicted labels from the clean encoder channel\n",
    "[decoded_imgs,pred_labels] = ladder_for_prediction.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and std of decoded : 0.133, 0.302\n",
      "Mean and std of original: 0.131, 0.301\n",
      "Accuracy: 97.74 %\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABZYAAACLCAYAAADyHszlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12f18aa0dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "origmean,origstd=(np.mean(x_train)),np.mean(np.std(x_train,axis=1))\n",
    "decodmean,decodstd=(np.mean(decoded_imgs)),np.mean(np.std(decoded_imgs,axis=1))\n",
    "accuracy=np.mean(np.argmax(pred_labels,axis=1)==y_test_num)*100\n",
    "print(\"Mean and std of decoded : %.3f, %.3f\"%(decodmean,decodstd))\n",
    "print(\"Mean and std of original: %.3f, %.3f\"%(origmean,origstd))\n",
    "print(\"Accuracy: %.2f %%\"%accuracy)\n",
    "\n",
    "\n",
    "n = 20  # how many digits we will display\n",
    "plt.figure(figsize=(20, 2))\n",
    "indices=np.arange(len(x_test))\n",
    "np.random.shuffle(indices)\n",
    "# pick randomly n images out of the test set, reconstruct and display them\n",
    "for i,j in enumerate(indices[:n]):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    if np.argmax(pred_labels[j]) == np.argmax(y_test[j]) :\n",
    "        ax.imshow(x_test[j].reshape(28, 28),cmap=plt.cm.gray)\n",
    "        # display predicted label\n",
    "        ax.text(0,28,np.argmax(pred_labels[j]),fontsize=24,color='yellow')\n",
    "    else:\n",
    "        ax.imshow(x_test[j].reshape(28, 28),cmap=plt.cm.gray_r)\n",
    "        ax.text(0,28,np.argmax(pred_labels[j]),fontsize=24,color='red')\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[j].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    \n",
    "plt.tight_layout()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis = {}\n",
    "analysis['accuracy'] = accuracy\n",
    "#analysis['training'] = TrainLadder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_obj(analysis,'ladder_sketch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def savefile(filename):\n",
    "    if theNotebook is None:\n",
    "        print (\"Run the cell starting with %%javascript \")\n",
    "    else:\n",
    "        os.system(\"jupyter nbconvert --to script %s --stdout > %s\"%(theNotebook,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theNotebook=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefile(\"gug.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ladder_custom.save('Model_ladder_sketch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "989px",
    "left": "0px",
    "right": "1184.36px",
    "top": "107px",
    "width": "223px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
