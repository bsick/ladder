{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code content\n",
    "Denoising autoencoder and prediction encoder with shared weights. \n",
    "Method: model with two outputs and a loss function per output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.4.0',\n",
       " sys.version_info(major=3, minor=6, micro=3, releaselevel='final', serial=0))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# additional imports of python modules\n",
    "# python module imports needed in customized functions:\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imgplot\n",
    "import time\n",
    "import pandas as pd\n",
    "#tf.set_random_seed(1)\n",
    "#np.random.seed(1)\n",
    "import sys\n",
    "tf.__version__, sys.version_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "#from keras.datasets import mnist\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "#from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "#from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data read-in\n",
    "Load small external MNIST data set when for working local on windows"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "fullpath = 'C:\\\\Users\\\\gorn\\\\Documents\\\\Documents\\\\WeiterBildung\\\\Machine-Learning\\\\DeepLearning\\\\01-Beate\\\\'\n",
    "\n",
    "# upload mnist_4000.pkl.gz which we have used in the DL course to home\n",
    "# To be compatible with python3 and python2\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:\n",
    "    import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open(fullpath + 'mnist_4000.pkl.gz', 'rb') as f:\n",
    "    if sys.version_info.major > 2:\n",
    "        (X,y) = pickle.load(f, encoding='latin1')\n",
    "    else:\n",
    "        (X,y) = pickle.load(f)\n",
    "PIXELS = len(X[0,0,0,:])\n",
    "\n",
    "# if images are not flatten (like in mnist) we need first to flatten them\n",
    "# now flatten images for fc ladder\n",
    "\n",
    "X = X.reshape([4000, 784])\n",
    "#X = X/255 # is already normalized\n",
    "\n",
    "print(\"small data before split X.shape\", X.shape)\n",
    "print(\"small data before  y.shape\", y.shape) \n",
    "\n",
    "x_train = X[0:3000]\n",
    "y_train = y[0:3000]\n",
    "x_test = X[3000:4000]\n",
    "y_test = y[3000:4000]\n",
    "\n",
    "\n",
    "print(\"small data x_train.shape:\", x_train.shape)\n",
    "print(\"small data y_train.shape:\",y_train.shape)\n",
    "print(\"small data x_test.shape:\",x_test.shape)\n",
    "print(\"small data y_test.shape:\",y_test.shape)\n",
    "\n",
    "num_class= len(np.unique(y))\n",
    "print(\"num_class:\",num_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data from keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "#import numpy as np\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will normalize all values between 0 and 1 and we will flatten the 28x28 images into vectors of size 784."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## corrupt images with noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise_factor = 0.0 # set to zero to go back to clean images\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef my_noise(input_layer, sd, scope):\\n    with tf.variable_scope(scope) as v_scope:\\n        noise = tf.random_normal(shape=tf.shape(input_layer), mean=0.0, stddev=sd, dtype=tf.float32) \\n        return input_layer + noise\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def my_noise(input_layer, sd, scope):\n",
    "    with tf.variable_scope(scope) as v_scope:\n",
    "        noise = tf.random_normal(shape=tf.shape(input_layer), mean=0.0, stddev=sd, dtype=tf.float32) \n",
    "        return input_layer + noise\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder example\n",
    "from https://blog.keras.io/building-autoencoders-in-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, GaussianNoise, BatchNormalization, Activation\n",
    "from keras.models import Model\n",
    "\n",
    "# this is the size of our encoded representations\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "stddev = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_encoder_layer(encoding_dim_,layer_id,stddev_=0.05):\n",
    "    \"\"\"\n",
    "    Create the layers\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    \n",
    "    encoding_dim_:int\n",
    "        number of perceptons \n",
    "    layer_id: string\n",
    "        part of the name\n",
    "    stddev: double\n",
    "        standard deviation of the Gaussion noise layer\n",
    "        \n",
    "    Returns\n",
    "    =======\n",
    "    \n",
    "    x,y: I don't know what this is\n",
    "    \n",
    "    \"\"\"\n",
    "    sublayers={}\n",
    "    s_id = 'encoder_' + layer_id + '/'\n",
    "    sublayers['lin_trans']=Dense(encoding_dim_,activation = None,name=s_id + 'lt')\n",
    "    sublayers['noise_add']=GaussianNoise(stddev_,name=s_id + 'noise')\n",
    "    sublayers['batch_norm']=BatchNormalization(name=s_id + 'bn')\n",
    "    sublayers['activation']=Activation('relu',name=s_id + 'output')\n",
    "    return sublayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def link_sublayer_ae(x,sublayers):\n",
    "    \"\"\"\n",
    "    Link the sublayers for the autoencoder\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    x: input for the first sublayer\n",
    "    \n",
    "    sublayers: dict containing the sublayers\n",
    "    \n",
    "    \"\"\"\n",
    "    try:\n",
    "        x=sublayers['lin_trans'](x)\n",
    "        y=sublayers['noise_add'](x)\n",
    "        x=sublayers['batch_norm'](y)\n",
    "        x=sublayers['activation'](x)\n",
    "    except:\n",
    "        print(\"Something failed\")\n",
    "    return x,y\n",
    "\n",
    "def link_sublayer_supervised(x,sublayers):\n",
    "    \"\"\"\n",
    "    Link the sublayers for the supervised approach\n",
    "    \n",
    "    Parameters\n",
    "    ==========\n",
    "    x: input for the first sublayer\n",
    "    \n",
    "    sublayers: dict containing the sublayers\n",
    "    \n",
    "    \"\"\"\n",
    "    try:\n",
    "        y=sublayers['lin_trans'](x)\n",
    "        x=sublayers['batch_norm'](y)\n",
    "        x=sublayers['activation'](x)\n",
    "    except:\n",
    "        print(\"Something failed\")\n",
    "    return x,y\n",
    "\n",
    "def decoding_layer(input_layer,layer_id,decoding_dim_,activation_name):\n",
    "    decoded_ = Dense(decoding_dim_,activation = activation_name,name = 'decoder_' + layer_id + '/output')(input_layer)\n",
    "    return decoded_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoding_dim = 128\n",
    "\n",
    "## Create the clean and corrupted encoders\n",
    "##########################################\n",
    "# Input layer\n",
    "input_img = Input(shape=(784,),name = 'input_img')\n",
    "# Build encoder sublayers\n",
    "encoder_layers={}\n",
    "encoder_layers['1']=build_encoder_layer(encoding_dim,'1')\n",
    "# NOTE:  Building the encoder layers only once but linking them twice ensures that the same weights are used by the AE and the clean encoder\n",
    "# Corrupt input and link them\n",
    "corrupted_img          = GaussianNoise(stddev,name=\"corrupt_input\")(input_img)\n",
    "encoded,sidepath_ae    = link_sublayer_ae(corrupted_img,encoder_layers['1'])\n",
    "# Link the clean encoder \n",
    "sv_encoded,sidepath_sv = link_sublayer_supervised(input_img,encoder_layers['1'])\n",
    "# channel the clean encoder output into the classifier\n",
    "predicted_labels = Dense(10,activation='sigmoid',name='predictor')(sv_encoded)\n",
    "\n",
    "## Create the decoder\n",
    "##########################################\n",
    "# Build a decoder\n",
    "decoder_layers={}\n",
    "decoder_layers['1']=Dense(784, activation='sigmoid',name='decoded_image')\n",
    "# link the decoder to the corrupted encoder\n",
    "decoded=decoder_layers['1'](encoded)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model A: one input with two outputs\n",
    "Train a model with a denoising AE and a clean encoder with shared weights. In the compiler we define two loss functions. This construction ensures that each loss function acts  on one output. NOTE: the loss function does not use the model inputs, but only the outputs and the  target outputs (y_pred and y_true). The true output of an AE are the original images and the true outputs for the supervised loss are the true labels. These are given when fitting, using the losses defined in the compilation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_img (InputLayer)          (None, 784)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "corrupt_input (GaussianNoise)   (None, 784)          0           input_img[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1/lt (Dense)            (None, 128)          100480      corrupt_input[0][0]              \n",
      "                                                                 input_img[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1/noise (GaussianNoise) (None, 128)          0           encoder_1/lt[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1/bn (BatchNormalizatio (None, 128)          512         encoder_1/noise[0][0]            \n",
      "                                                                 encoder_1/lt[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoder_1/output (Activation)   (None, 128)          0           encoder_1/bn[0][0]               \n",
      "                                                                 encoder_1/bn[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoded_image (Dense)           (None, 784)          101136      encoder_1/output[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "predictor (Dense)               (None, 10)           1290        encoder_1/output[1][0]           \n",
      "==================================================================================================\n",
      "Total params: 203,418\n",
      "Trainable params: 203,162\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ladder = Model([input_img],[decoded,predicted_labels])\n",
    "ladder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot model A\n",
    "the clean and the corrupted encoders share the same weights. The corrupted channel is then decoded and the clean one is used for supervised classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"483pt\" viewBox=\"0.00 0.00 299.00 483.00\" width=\"299pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 479)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-479 295,-479 295,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 2802830721656 -->\n",
       "<g class=\"node\" id=\"node1\"><title>2802830721656</title>\n",
       "<polygon fill=\"none\" points=\"93.5,-438.5 93.5,-474.5 233.5,-474.5 233.5,-438.5 93.5,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163.5\" y=\"-452.8\">input_img: InputLayer</text>\n",
       "</g>\n",
       "<!-- 2802893897456 -->\n",
       "<g class=\"node\" id=\"node2\"><title>2802893897456</title>\n",
       "<polygon fill=\"none\" points=\"12,-365.5 12,-401.5 195,-401.5 195,-365.5 12,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103.5\" y=\"-379.8\">corrupt_input: GaussianNoise</text>\n",
       "</g>\n",
       "<!-- 2802830721656&#45;&gt;2802893897456 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>2802830721656-&gt;2802893897456</title>\n",
       "<path d=\"M148.976,-438.313C141.606,-429.592 132.52,-418.84 124.412,-409.246\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"127.018,-406.908 117.891,-401.529 121.672,-411.426 127.018,-406.908\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2802895114080 -->\n",
       "<g class=\"node\" id=\"node3\"><title>2802895114080</title>\n",
       "<polygon fill=\"none\" points=\"99.5,-292.5 99.5,-328.5 227.5,-328.5 227.5,-292.5 99.5,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163.5\" y=\"-306.8\">encoder_1/lt: Dense</text>\n",
       "</g>\n",
       "<!-- 2802830721656&#45;&gt;2802895114080 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>2802830721656-&gt;2802895114080</title>\n",
       "<path d=\"M181.244,-438.457C190.075,-428.723 199.84,-415.742 204.5,-402 209.781,-386.427 209.781,-380.573 204.5,-365 200.969,-354.586 194.505,-344.609 187.739,-336.151\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"190.398,-333.876 181.244,-328.543 185.074,-338.421 190.398,-333.876\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2802893897456&#45;&gt;2802895114080 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>2802893897456-&gt;2802895114080</title>\n",
       "<path d=\"M118.024,-365.313C125.394,-356.592 134.48,-345.84 142.588,-336.246\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"145.328,-338.426 149.109,-328.529 139.982,-333.908 145.328,-338.426\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2802893896672 -->\n",
       "<g class=\"node\" id=\"node4\"><title>2802893896672</title>\n",
       "<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 199,-255.5 199,-219.5 0,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"99.5\" y=\"-233.8\">encoder_1/noise: GaussianNoise</text>\n",
       "</g>\n",
       "<!-- 2802895114080&#45;&gt;2802893896672 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>2802895114080-&gt;2802893896672</title>\n",
       "<path d=\"M148.007,-292.313C140.068,-283.505 130.261,-272.625 121.547,-262.958\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"124.145,-260.613 114.85,-255.529 118.946,-265.3 124.145,-260.613\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2802893894936 -->\n",
       "<g class=\"node\" id=\"node5\"><title>2802893894936</title>\n",
       "<polygon fill=\"none\" points=\"58.5,-146.5 58.5,-182.5 268.5,-182.5 268.5,-146.5 58.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163.5\" y=\"-160.8\">encoder_1/bn: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 2802895114080&#45;&gt;2802893894936 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>2802895114080-&gt;2802893894936</title>\n",
       "<path d=\"M183.411,-292.305C192.97,-282.714 203.427,-269.911 208.5,-256 214.133,-240.551 214.133,-234.449 208.5,-219 204.656,-208.458 197.719,-198.553 190.425,-190.199\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"192.797,-187.611 183.411,-182.695 187.683,-192.391 192.797,-187.611\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2802893896672&#45;&gt;2802893894936 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>2802893896672-&gt;2802893894936</title>\n",
       "<path d=\"M114.993,-219.313C122.932,-210.505 132.739,-199.625 141.453,-189.958\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"144.054,-192.3 148.15,-182.529 138.855,-187.613 144.054,-192.3\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2802830688440 -->\n",
       "<g class=\"node\" id=\"node6\"><title>2802830688440</title>\n",
       "<polygon fill=\"none\" points=\"74,-73.5 74,-109.5 253,-109.5 253,-73.5 74,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163.5\" y=\"-87.8\">encoder_1/output: Activation</text>\n",
       "</g>\n",
       "<!-- 2802893894936&#45;&gt;2802830688440 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>2802893894936-&gt;2802830688440</title>\n",
       "<path d=\"M163.5,-146.313C163.5,-138.289 163.5,-128.547 163.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"167,-119.529 163.5,-109.529 160,-119.529 167,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2802901802960 -->\n",
       "<g class=\"node\" id=\"node7\"><title>2802901802960</title>\n",
       "<polygon fill=\"none\" points=\"17.5,-0.5 17.5,-36.5 163.5,-36.5 163.5,-0.5 17.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"90.5\" y=\"-14.8\">decoded_image: Dense</text>\n",
       "</g>\n",
       "<!-- 2802830688440&#45;&gt;2802901802960 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>2802830688440-&gt;2802901802960</title>\n",
       "<path d=\"M145.829,-73.3129C136.683,-64.4174 125.365,-53.4094 115.353,-43.6717\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"117.617,-40.992 108.009,-36.5288 112.737,-46.0101 117.617,-40.992\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2802764593976 -->\n",
       "<g class=\"node\" id=\"node8\"><title>2802764593976</title>\n",
       "<polygon fill=\"none\" points=\"182,-0.5 182,-36.5 291,-36.5 291,-0.5 182,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"236.5\" y=\"-14.8\">predictor: Dense</text>\n",
       "</g>\n",
       "<!-- 2802830688440&#45;&gt;2802764593976 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>2802830688440-&gt;2802764593976</title>\n",
       "<path d=\"M181.171,-73.3129C190.317,-64.4174 201.635,-53.4094 211.647,-43.6717\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"214.263,-46.0101 218.991,-36.5288 209.383,-40.992 214.263,-46.0101\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(ladder).create(prog='dot',format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and fit model A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the compiler defines two loss functions: a binary loss for the unsupervised decoding of the corrupted images. A categorical cross-entropy for the supervised classification using the clean encoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ladder.compile(optimizer='adadelta', loss=['binary_crossentropy','categorical_crossentropy'],loss_weights=[1.0,1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.4325 - decoded_image_loss: 0.1080 - predictor_loss: 0.3245 - val_loss: 0.2796 - val_decoded_image_loss: 0.1054 - val_predictor_loss: 0.1742\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 14s 227us/step - loss: 0.2607 - decoded_image_loss: 0.1080 - predictor_loss: 0.1527 - val_loss: 0.2402 - val_decoded_image_loss: 0.1031 - val_predictor_loss: 0.1370\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 0.2200 - decoded_image_loss: 0.1060 - predictor_loss: 0.1139 - val_loss: 0.2299 - val_decoded_image_loss: 0.1008 - val_predictor_loss: 0.1291\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.1964 - decoded_image_loss: 0.1040 - predictor_loss: 0.0924 - val_loss: 0.2094 - val_decoded_image_loss: 0.0996 - val_predictor_loss: 0.1098\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.1801 - decoded_image_loss: 0.1023 - predictor_loss: 0.0778 - val_loss: 0.1964 - val_decoded_image_loss: 0.0980 - val_predictor_loss: 0.0984\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.1662 - decoded_image_loss: 0.1009 - predictor_loss: 0.0653 - val_loss: 0.1937 - val_decoded_image_loss: 0.0964 - val_predictor_loss: 0.0973\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.1580 - decoded_image_loss: 0.0995 - predictor_loss: 0.0584 - val_loss: 0.1883 - val_decoded_image_loss: 0.0950 - val_predictor_loss: 0.0933\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 8s 142us/step - loss: 0.1487 - decoded_image_loss: 0.0983 - predictor_loss: 0.0503 - val_loss: 0.1798 - val_decoded_image_loss: 0.0940 - val_predictor_loss: 0.0858\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.1420 - decoded_image_loss: 0.0973 - predictor_loss: 0.0447 - val_loss: 0.1851 - val_decoded_image_loss: 0.0929 - val_predictor_loss: 0.0922\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.1363 - decoded_image_loss: 0.0965 - predictor_loss: 0.0398 - val_loss: 0.1816 - val_decoded_image_loss: 0.0923 - val_predictor_loss: 0.0894\n"
     ]
    }
   ],
   "source": [
    "info=ladder.fit(x_train,[x_train,y_train],\n",
    "                epochs=10,\n",
    "                batch_size=100,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test,[x_test,y_test]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting and plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encode and decode some digits\n",
    "note that we take them from the *test* set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  use ladder to predict\n",
    "the ladder has two outputs\n",
    "1. decoded images of the denoising autoencoder ==> display them as digit images\n",
    "2. predicted digits of the clean encoder ==> take the max of the softmax to predict a digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[decoded_imgs,encoder_output] = ladder.predict(x_test)\n",
    "# use Matplotlib (don't ask)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    \n",
    "plt.show()\n",
    "for i in range(n):\n",
    "    print('predicted digit:',np.argmax(encoder_output[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "540px",
    "left": "0px",
    "right": "1184.36px",
    "top": "106px",
    "width": "134px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
